\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Introduction to Econometrics with R},
            pdfauthor={Florian Oswald and Jean-Marc Robin},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\newcommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Introduction to Econometrics with R}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Florian Oswald and Jean-Marc Robin}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2018-08-27}

\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{tcolorbox}
\newenvironment{note}{\begin{tcolorbox}[colback=blue!5!white,colframe=blue!75!black,title=\textbf{Note:}]}{\end{tcolorbox}}
\newenvironment{warning}{\begin{tcolorbox}[colback=orange!5!white,colframe=orange,title=\textbf{Warning!}]}{\end{tcolorbox}}
\newenvironment{tip}{\begin{tcolorbox}[colback=green!5!white,colframe=green,title=\textbf{Tip:}]}{\end{tcolorbox}}

\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Example}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{Syllabus}\label{syllabus}
\addcontentsline{toc}{chapter}{Syllabus}

\begin{figure}
\centering
\includegraphics{ScPo.jpg}
\caption{}
\end{figure}

Welcome to Introductory Econometrics for 2nd year undergraduates at
ScPo! On this page we outline the course and present the Syllabus. As of
today, this is still \textbf{work in progress}!

\subsection*{Objective}\label{objective}
\addcontentsline{toc}{subsection}{Objective}

This course aims to teach you the basics of data analysis needed in a
Social Sciences oriented University like SciencesPo. We purposefully
start at a level that assumes no prior knowledge about statistics
whatsoever. Our objective is to have you understand and be able to
interpret linear regression analysis. We will not rely on maths and
statistics, but practical learning in order to teach the main concepts.

\subsection*{Syllabus and Requirements}\label{syllabus-and-requirements}
\addcontentsline{toc}{subsection}{Syllabus and Requirements}

You can find the topics we want to go over in the left panel of this
page. The later chapters are optional and depend on the speed with which
we will proceed eventually. Chapters 1-4 are the core material of the
course.

The only requirement is that \textbf{you bring your own personal
computer} to each session. We will be using the free statistical
computing language \href{https://www.r-project.org}{\texttt{R}} very
intensively. Before coming to the first session, please install
\texttt{R} and \texttt{RStudio} as explained at the beginning of chapter
\ref{R-intro}.

\subsection*{Course Structure}\label{course-structure}
\addcontentsline{toc}{subsection}{Course Structure}

This course is taught in several different groups across various
campuses of SciencesPo. All groups will go over the same material, do
the same exercises, and will have the same assessments.

Groups meet once per week for 2 hours. The main purpose of the weekly
meetings is to clarify any questions, and to work together through
tutorials. The little theory we need will be covered in this book, and
\textbf{you are expected to read through this in your own time} before
coming to class.

\subsection*{This Book and Other
Material}\label{this-book-and-other-material}
\addcontentsline{toc}{subsection}{This Book and Other Material}

What you are looking at is an online textbook. You can therefore look at
it in your browser (as you are doing just now), on your mobile phone or
tablet, but you can also download it as a \texttt{pdf} file or as an
\texttt{epub} file for your ebook-reader. We don't have any ambition to
actually produce and publish a \emph{book} for now, so you should just
see this as a way to disseminate our lecture notes to you. The second
part of course material next to the book is an extensive suite of
tutorials and interactive demonstrations, which are all contained in the
\texttt{R} package that builds this book (and which you installed by
issuing the above commands).

\subsection*{Open Source}\label{open-source}
\addcontentsline{toc}{subsection}{Open Source}

The book and all other content for this course are hosted under an open
source license on github. You can contribute to the book by just
clicking on the appropriate \emph{edit} symbol in the top bar of this
page. Other teachers who want to use our material can freely do so,
observing the terms of the license on the
\href{https://github.com/ScPoEcon/ScPoEconometrics}{github repository}.

\subsection*{Assessments}\label{assessments}
\addcontentsline{toc}{subsection}{Assessments}

We will assess participation in class and conduct a final exam.

\subsection*{Team}\label{team}
\addcontentsline{toc}{subsection}{Team}

tbc

\subsection*{Communication}\label{communication}
\addcontentsline{toc}{subsection}{Communication}

We will communicate exclusively on our
\href{https://econometrics-scpo.slack.com}{\texttt{slack}} app. You will
get an invitation email to join in due course.

\chapter{\texorpdfstring{Introduction to
\texttt{R}}{Introduction to R}}\label{R-intro}

\section{Getting Started}\label{getting-started}

\texttt{R} is both a programming language and software environment for
statistical computing, which is \emph{free} and \emph{open-source}. To
get started, you will need to install two pieces of software:

\begin{itemize}
\tightlist
\item
  \href{https://www.r-project.org}{\texttt{R}, the actual programming
  language.}

  \begin{itemize}
  \tightlist
  \item
    Chose your operating system, and select the most recent version,
    3.5.0.
  \end{itemize}
\item
  \href{http://www.rstudio.com/}{RStudio, an excellent IDE for working
  with \texttt{R}.}

  \begin{itemize}
  \tightlist
  \item
    Note, you must have \texttt{R} installed to use RStudio. RStudio is
    simply an interface used to interact with \texttt{R}.
  \end{itemize}
\end{itemize}

The popularity of \texttt{R} is on the rise, and everyday it becomes a
better tool for statistical analysis. It even generated this book! (A
skill you will learn in this course.) There are many good resources for
learning \texttt{R}.

The following few chapters will serve as a whirlwind introduction to
\texttt{R}. They are by no means meant to be a complete reference for
the \texttt{R} language, but simply an introduction to the basics that
we will need along the way. Several of the more important topics will be
re-stressed as they are actually needed for analyses.

This introductory \texttt{R} chapter may feel like an overwhelming
amount of information. You are not expected to pick up everything the
first time through. You should try all of the code from this chapter,
then return to it a number of times as you return to the concepts when
performing analyses. We present the bare basics in this chapter, some
more details are in chapter \ref{R-advanced}.

\section{Starting R and RStudio}\label{starting-r-and-rstudio}

A key difference for you to understand is that between \texttt{R}, the
actual programming language, and RStudio which is a software that allows
you to efficiently and easily work with the R language.

The best way to appreciate the value of RStudio is to start using R
\emph{without} RStudio. To do this, click on the R application that you
should have downloaded on your computer (see above). You've just opened
the R \textbf{console} which allows you to start typing code right after
the red \texttt{\textgreater{}} sign. Try typing \texttt{2\ +\ 2} or
\texttt{print("Your\ Name")} and hit the return key. And \emph{voilÃ },
your first R commands!

Typing each command after the other is however not very convenient, and
we would like to be able to write all the lines of code beforehand and
then run all of them in one go. We can do this by writing
\textbf{scripts}, and for this we will need tools like RStudio!

Open RStudio by clicking on the RStudio application on your computer,
and notice how different (and prettier!) the whole environment is from
the basic R console -- which you can still find and use in the bottom
panel of RStudio. The upper-left panel is a space for you to write
scripts -- that is to say many lines of codes which you can run when you
choose to. To run a line of code, simply highlight it and hit
\texttt{Command} + \texttt{Return}.

RStudio has a large number of useful keyboard shortcuts. A list of these
can be found using a keyboard shortcut -- the keyboard shortcut to rule
them all:

\begin{itemize}
\tightlist
\item
  On Windows: \texttt{Alt} + \texttt{Shift} + \texttt{K}
\item
  On Mac: \texttt{Option} + \texttt{Shift} + \texttt{K}
\end{itemize}

The RStudio team has developed
\href{https://www.rstudio.com/resources/cheatsheets/}{a number of
``cheatsheets''} for working with both \texttt{R} and RStudio.
\href{http://www.rstudio.com/wp-content/uploads/2016/05/base-r.pdf}{This
particular cheatseet for Base \texttt{R}} will summarize many of the
concepts in this document.

When programming, it is often a good practice to follow a style guide.
(Where do spaces go? Tabs or spaces? Underscores or CamelCase when
naming variables?) No style guide is ``correct'' but it helps to be
aware of what others do. The more import thing is to be consistent
within your own code.

\begin{itemize}
\tightlist
\item
  \href{http://adv-r.had.co.nz/Style.html}{Hadley Wickham Style Guide}
  from \href{http://adv-r.had.co.nz/}{Advanced \texttt{R}}
\item
  \href{https://google.github.io/styleguide/Rguide.xml}{Google Style
  Guide}
\end{itemize}

For this course, our main deviation from these two guides is the use of
\texttt{=} in place of \texttt{\textless{}-}. For all practical
purposes, you should think \texttt{=} whenever you see
\texttt{\textless{}-}.

\section{Basic Calculations}\label{basic-calculations}

To get started, we'll use \texttt{R} like a simple calculator. Run the
following code either directly from the R console, or in RStudio by
writting them in a script and running them using \texttt{Command} +
\texttt{Return}.

\subsubsection*{Addition, Subtraction, Multiplication and
Division}\label{addition-subtraction-multiplication-and-division}
\addcontentsline{toc}{subsubsection}{Addition, Subtraction,
Multiplication and Division}

\begin{longtable}[]{@{}ccc@{}}
\toprule
Math & \texttt{R} code & Result\tabularnewline
\midrule
\endhead
\(3 + 2\) & \texttt{3\ +\ 2} & 5\tabularnewline
\(3 - 2\) & \texttt{3\ -\ 2} & 1\tabularnewline
\(3 \cdot2\) & \texttt{3\ *\ 2} & 6\tabularnewline
\(3 / 2\) & \texttt{3\ /\ 2} & 1.5\tabularnewline
\bottomrule
\end{longtable}

\subsubsection*{Exponents}\label{exponents}
\addcontentsline{toc}{subsubsection}{Exponents}

\begin{longtable}[]{@{}ccc@{}}
\toprule
Math & \texttt{R} code & Result\tabularnewline
\midrule
\endhead
\(3^2\) & \texttt{3\ \^{}\ 2} & 9\tabularnewline
\(2^{(-3)}\) & \texttt{2\ \^{}\ (-3)} & 0.125\tabularnewline
\(100^{1/2}\) & \texttt{100\ \^{}\ (1\ /\ 2)} & 10\tabularnewline
\(\sqrt{100}\) & \texttt{sqrt(100)} & 10\tabularnewline
\bottomrule
\end{longtable}

\subsubsection*{Mathematical Constants}\label{mathematical-constants}
\addcontentsline{toc}{subsubsection}{Mathematical Constants}

\begin{longtable}[]{@{}ccc@{}}
\toprule
Math & \texttt{R} code & Result\tabularnewline
\midrule
\endhead
\(\pi\) & \texttt{pi} & 3.1415927\tabularnewline
\(e\) & \texttt{exp(1)} & 2.7182818\tabularnewline
\bottomrule
\end{longtable}

\subsubsection*{Logarithms}\label{logarithms}
\addcontentsline{toc}{subsubsection}{Logarithms}

Note that we will use \(\ln\) and \(\log\) interchangeably to mean the
natural logarithm. There is no \texttt{ln()} in \texttt{R}, instead it
uses \texttt{log()} to mean the natural logarithm.

\begin{longtable}[]{@{}ccc@{}}
\toprule
Math & \texttt{R} code & Result\tabularnewline
\midrule
\endhead
\(\log(e)\) & \texttt{log(exp(1))} & 1\tabularnewline
\(\log_{10}(1000)\) & \texttt{log10(1000)} & 3\tabularnewline
\(\log_{2}(8)\) & \texttt{log2(8)} & 3\tabularnewline
\(\log_{4}(16)\) & \texttt{log(16,\ base\ =\ 4)} & 2\tabularnewline
\bottomrule
\end{longtable}

\subsubsection*{Trigonometry}\label{trigonometry}
\addcontentsline{toc}{subsubsection}{Trigonometry}

\begin{longtable}[]{@{}ccc@{}}
\toprule
Math & \texttt{R} code & Result\tabularnewline
\midrule
\endhead
\(\sin(\pi / 2)\) & \texttt{sin(pi\ /\ 2)} & 1\tabularnewline
\(\cos(0)\) & \texttt{cos(0)} & 1\tabularnewline
\bottomrule
\end{longtable}

\section{Getting Help}\label{getting-help}

In using \texttt{R} as a calculator, we have seen a number of functions:
\texttt{sqrt()}, \texttt{exp()}, \texttt{log()} and \texttt{sin()}. To
get documentation about a function in \texttt{R}, simply put a question
mark in front of the function name, or call the function
\texttt{help(function)} and RStudio will display the documentation, for
example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?log}
\NormalTok{?sin}
\NormalTok{?paste}
\NormalTok{?lm}
\KeywordTok{help}\NormalTok{(lm)   }\CommentTok{# help() is equivalent}
\KeywordTok{help}\NormalTok{(ggplot,}\DataTypeTok{package=}\StringTok{"ggplot2"}\NormalTok{)  }\CommentTok{# show help from a certain package}
\end{Highlighting}
\end{Shaded}

Frequently one of the most difficult things to do when learning
\texttt{R} is asking for help. First, you need to decide to ask for
help, then you need to know \emph{how} to ask for help. Your very first
line of defense should be to Google your error message or a short
description of your issue. (The ability to solve problems using this
method is quickly becoming an extremely valuable skill.) If that fails,
and it eventually will, you should ask for help. There are a number of
things you should include when emailing an instructor, or posting to a
help website such as \href{https://stackoverflow.com}{Stack Overflow}.

\begin{itemize}
\tightlist
\item
  Describe what you expect the code to do.
\item
  State the end goal you are trying to achieve. (Sometimes what you
  expect the code to do, is not what you want to actually do.)
\item
  Provide the full text of any errors you have received.
\item
  Provide enough code to recreate the error. Often for the purpose of
  this course, you could simply post your entire \texttt{.R} script or
  \texttt{.Rmd} to \texttt{slack}.
\item
  Sometimes it is also helpful to include a screenshot of your entire
  RStudio window when the error occurs.
\end{itemize}

If you follow these steps, you will get your issue resolved much
quicker, and possibly learn more in the process. Do not be discouraged
by running into errors and difficulties when learning \texttt{R}. (Or
any other technical skill.) It is simply part of the learning process.

\section{Installing Packages}\label{installing-packages}

\texttt{R} comes with a number of built-in functions and datasets, but
one of the main strengths of \texttt{R} as an open-source project is its
package system. Packages add additional functions and data. Frequently
if you want to do something in \texttt{R}, and it is not available by
default, there is a good chance that there is a package that will
fulfill your needs.

To install a package, use the \texttt{install.packages()} function.
Think of this as buying a recipe book from the store, bringing it home,
and putting it on your shelf (i.e.~into your library):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Once a package is installed, it must be loaded into your current
\texttt{R} session before being used. Think of this as taking the book
off of the shelf and opening it up to read.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

Once you close \texttt{R}, all the packages are closed and put back on
the imaginary shelf. The next time you open \texttt{R}, you do not have
to install the package again, but you do have to load any packages you
intend to use by invoking \texttt{library()}.

\section{Data Types}\label{data-types}

\texttt{R} has a number of basic \emph{data types}. While \texttt{R} is
not a \emph{strongly typed language} (i.e.~you can be agnostic about
types most of the times), it is useful to know what data types are
available to you:

\begin{itemize}
\tightlist
\item
  Numeric

  \begin{itemize}
  \tightlist
  \item
    Also known as Double. The default type when dealing with numbers.
  \item
    Examples: \texttt{1}, \texttt{1.0}, \texttt{42.5}
  \end{itemize}
\item
  Integer

  \begin{itemize}
  \tightlist
  \item
    Examples: \texttt{1L}, \texttt{2L}, \texttt{42L}
  \end{itemize}
\item
  Complex

  \begin{itemize}
  \tightlist
  \item
    Example: \texttt{4\ +\ 2i}
  \end{itemize}
\item
  Logical

  \begin{itemize}
  \tightlist
  \item
    Two possible values: \texttt{TRUE} and \texttt{FALSE}
  \item
    You can also use \texttt{T} and \texttt{F}, but this is \emph{not}
    recommended.
  \item
    \texttt{NA} is also considered logical.
  \end{itemize}
\item
  Character

  \begin{itemize}
  \tightlist
  \item
    Examples: \texttt{"a"}, \texttt{"Statistics"},
    \texttt{"1\ plus\ 2."}
  \end{itemize}
\item
  Categorical or \texttt{factor}

  \begin{itemize}
  \tightlist
  \item
    A mixture of integer and character. A \texttt{factor} variable
    assigns a label to a numeric value.
  \item
    For example \texttt{factor(x=c(0,1),labels=c("male","female"))}
    assigns the string \emph{male} to the numeric values \texttt{0}, and
    the string \emph{female} to the value \texttt{1}.
  \end{itemize}
\end{itemize}

\section{Data Structures}\label{data-structures}

\texttt{R} also has a number of basic data \emph{structures}. A data
structure is either homogeneous (all elements are of the same data type)
or heterogeneous (elements can be of more than one data type).

\begin{longtable}[]{@{}ccc@{}}
\toprule
Dimension & \textbf{Homogeneous} & \textbf{Heterogeneous}\tabularnewline
\midrule
\endhead
1 & Vector & List\tabularnewline
2 & Matrix & Data Frame\tabularnewline
3+ & Array & nested Lists\tabularnewline
\bottomrule
\end{longtable}

\subsection{Vectors}\label{vectors}

Many operations in \texttt{R} make heavy use of \textbf{vectors}.
Vectors in \texttt{R} are indexed starting at \texttt{1}. That is what
the \texttt{{[}1{]}} in the output is indicating, that the first element
of the row being displayed is the first element of the vector. Larger
vectors will start additional rows with something like \texttt{{[}7{]}}
where \texttt{7} is the index of the first element of that row.

Possibly the most common way to create a vector in \texttt{R} is using
the \texttt{c()} function, which is short for ``combine''. As the name
suggests, it combines a list of elements separated by commas. {[}you
should type all of those examples into your \texttt{R} console!!{]}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 5 7 8 9
\end{verbatim}

Here \texttt{R} simply outputs this vector. If we would like to store
this vector in a \textbf{variable} we can do so with the
\textbf{assignment} operator \texttt{=}. In this case the variable
\texttt{x} now holds the vector we just created, and we can access the
vector by typing \texttt{x}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 5 7 8 9
\end{verbatim}

As an aside, there is a long history of the assignment operator in
\texttt{R}, partially due to the keys available on the
\href{https://twitter.com/kwbroman/status/747829864091127809}{keyboards
of the creators of the \texttt{S} language.} (Which preceded
\texttt{R}.) For simplicity we will use \texttt{=}, but know that often
you will see \texttt{\textless{}-} as the assignment operator.

Because vectors must contain elements that are all the same type,
\texttt{R} will automatically \textbf{coerce} (i.e.~convert) to a single
type when attempting to create a vector that combines multiple types.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\DecValTok{42}\NormalTok{, }\StringTok{"Statistics"}\NormalTok{, }\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "42"         "Statistics" "TRUE"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\DecValTok{42}\NormalTok{, }\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 42  1
\end{verbatim}

Frequently you may wish to create a vector based on a sequence of
numbers. The quickest and easiest way to do this is with the \texttt{:}
operator, which creates a sequence of integers between two specified
integers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{y =} \DecValTok{1}\OperatorTok{:}\DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
##  [18]  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34
##  [35]  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
##  [52]  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68
##  [69]  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85
##  [86]  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100
\end{verbatim}

Here we see \texttt{R} labeling the rows after the first since this is a
large vector. Also, we see that by putting parentheses around the
assignment, \texttt{R} both stores the vector in a variable called
\texttt{y} and automatically outputs \texttt{y} to the console.

Note that scalars do not exists in \texttt{R}. They are simply vectors
of length \texttt{1}.

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

If we want to create a sequence that isn't limited to integers and
increasing by 1 at a time, we can use the \texttt{seq()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \FloatTok{1.5}\NormalTok{, }\DataTypeTok{to =} \FloatTok{4.2}\NormalTok{, }\DataTypeTok{by =} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.0 3.1
## [18] 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.0 4.1 4.2
\end{verbatim}

We will discuss functions in detail later, but note here that the input
labels \texttt{from}, \texttt{to}, and \texttt{by} are optional.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{seq}\NormalTok{(}\FloatTok{1.5}\NormalTok{, }\FloatTok{4.2}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 3.0 3.1
## [18] 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 4.0 4.1 4.2
\end{verbatim}

Another common operation to create a vector is \texttt{rep()}, which can
repeat a single value a number of times.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rep}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\DataTypeTok{times =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "A" "A" "A" "A" "A" "A" "A" "A" "A" "A"
\end{verbatim}

The \texttt{rep()} function can be used to repeat a vector some number
of times.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rep}\NormalTok{(x, }\DataTypeTok{times =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9
\end{verbatim}

We have now seen four different ways to create vectors:

\begin{itemize}
\tightlist
\item
  \texttt{c()}
\item
  \texttt{:}
\item
  \texttt{seq()}
\item
  \texttt{rep()}
\end{itemize}

So far we have mostly used them in isolation, but they are often used
together.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(x, }\KeywordTok{rep}\NormalTok{(}\KeywordTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DecValTok{3}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{), }\DecValTok{42}\NormalTok{, }\DecValTok{2}\OperatorTok{:}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  3  5  7  8  9  1  3  5  7  9  1  3  5  7  9  1  3  5  7  9  1  2
## [24]  3 42  2  3  4
\end{verbatim}

The length of a vector can be obtained with the \texttt{length()}
function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\subsubsection{Task 1}\label{task-1}

Let's try this out!

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a vector of five ones, i.e. \texttt{{[}1,1,1,1,1{]}}
\item
  Notice that the colon operator \texttt{a:b} is just short for
  \emph{construct a sequence \textbf{from} \texttt{a} \textbf{to}
  \texttt{b}}. Create a vector the counts down from 10 to 0, i.e.~it
  looks like \texttt{{[}10,9,8,7,6,5,4,3,2,1,0{]}}!
\item
  the \texttt{rep} function takes additional arguments \texttt{times}
  (as above), and \texttt{each}, which tells you how often \emph{each
  element} should be repeated (as opposed to the entire input vector).
  Use \texttt{rep} to create a vector that looks like this:
  \texttt{{[}1\ 1\ 1\ 2\ 2\ 2\ 3\ 3\ 3\ 1\ 1\ 1\ 2\ 2\ 2\ 3\ 3\ 3{]}}
\end{enumerate}

\subsubsection{Subsetting}\label{subsetting}

To subset a vector, i.e.~to choose only some elements of it, we use
square brackets, \texttt{{[}{]}}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 5 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

We see that \texttt{x{[}1{]}} returns the first element, and
\texttt{x{[}3{]}} returns the third element.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\OperatorTok{-}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 5 7 8 9
\end{verbatim}

We can also exclude certain indexes, in this case the second element.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 5 7
\end{verbatim}

Lastly we see that we can subset based on a vector of indices.

All of the above are subsetting a vector using a vector of indexes.
(Remember a single number is still a vector.) We could instead use a
vector of logical values.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{)}
\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[z]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 3 7 8
\end{verbatim}

\subsection{Vectorization}\label{vectorization}

One of the biggest strengths of \texttt{R} is its use of vectorized
operations. This means, operations which work on - and are optimized for
- entire vectors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{10}  \CommentTok{# a vector}
\NormalTok{x }\OperatorTok{+}\StringTok{ }\DecValTok{1}     \CommentTok{# add scalar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  2  3  4  5  6  7  8  9 10 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{x     }\CommentTok{# multiply all elements by 2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  2  4  6  8 10 12 14 16 18 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \OperatorTok{^}\StringTok{ }\NormalTok{x     }\CommentTok{# take 2 to the x as exponents}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]    2    4    8   16   32   64  128  256  512 1024
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(x)   }\CommentTok{# compute the square root of all elements in x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751
##  [8] 2.828427 3.000000 3.162278
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(x)    }\CommentTok{# take the natural log of all elements in x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.0000000 0.6931472 1.0986123 1.3862944 1.6094379 1.7917595 1.9459101
##  [8] 2.0794415 2.1972246 2.3025851
\end{verbatim}

We see that when a function like \texttt{log()} is called on a vector
\texttt{x}, a vector is returned which has applied the function to each
element of the vector \texttt{x}.

\subsection{Logical Operators}\label{logical-operators}

\begin{longtable}[]{@{}lccc@{}}
\toprule
Operator & Summary & Example & Result\tabularnewline
\midrule
\endhead
\texttt{x\ \textless{}\ y} & \texttt{x} less than \texttt{y} &
\texttt{3\ \textless{}\ 42} & TRUE\tabularnewline
\texttt{x\ \textgreater{}\ y} & \texttt{x} greater than \texttt{y} &
\texttt{3\ \textgreater{}\ 42} & FALSE\tabularnewline
\texttt{x\ \textless{}=\ y} & \texttt{x} less than or equal to
\texttt{y} & \texttt{3\ \textless{}=\ 42} & TRUE\tabularnewline
\texttt{x\ \textgreater{}=\ y} & \texttt{x} greater than or equal to
\texttt{y} & \texttt{3\ \textgreater{}=\ 42} & FALSE\tabularnewline
\texttt{x\ ==\ y} & \texttt{x}equal to \texttt{y} & \texttt{3\ ==\ 42} &
FALSE\tabularnewline
\texttt{x\ !=\ y} & \texttt{x} not equal to \texttt{y} &
\texttt{3\ !=\ 42} & TRUE\tabularnewline
\texttt{!x} & not \texttt{x} & \texttt{!(3\ \textgreater{}\ 42)} &
TRUE\tabularnewline
\texttt{x\ \textbar{}\ y} & \texttt{x} or \texttt{y} &
\texttt{(3\ \textgreater{}\ 42)\ \textbar{}\ TRUE} & TRUE\tabularnewline
\texttt{x\ \&\ y} & \texttt{x} and \texttt{y} &
\texttt{(3\ \textless{}\ 4)\ \&\ (\ 42\ \textgreater{}\ 13)} &
TRUE\tabularnewline
\bottomrule
\end{longtable}

In \texttt{R}, logical operators are vectorized.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{>}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{<}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE FALSE FALSE FALSE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{==}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE  TRUE FALSE FALSE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{!=}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE FALSE  TRUE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{==}\StringTok{ }\DecValTok{3} \OperatorTok{&}\StringTok{ }\NormalTok{x }\OperatorTok{!=}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE FALSE FALSE FALSE FALSE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{==}\StringTok{ }\DecValTok{3} \OperatorTok{|}\StringTok{ }\NormalTok{x }\OperatorTok{!=}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE TRUE TRUE TRUE TRUE TRUE
\end{verbatim}

This is extremely useful for subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[x }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[x }\OperatorTok{!=}\StringTok{ }\DecValTok{3}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 5 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.numeric}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0 0 1 1 1 1
\end{verbatim}

Here we see that using the \texttt{sum()} function on a vector of
logical \texttt{TRUE} and \texttt{FALSE} values that is the result of
\texttt{x\ \textgreater{}\ 3} results in a numeric result. \texttt{R} is
first automatically coercing the logical to numeric where \texttt{TRUE}
is \texttt{1} and \texttt{FALSE} is \texttt{0}. This coercion from
logical to numeric happens for most mathematical operations.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# which(condition of x) returns true/false  }
\CommentTok{# each index of x where condition is true}
\KeywordTok{which}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 4 5 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x[}\KeywordTok{which}\NormalTok{(x }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{max}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{which}\NormalTok{(x }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{which.max}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\subsubsection{Task 2}\label{task-2}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a vector filled with 10 numbers drawn from the uniform
  distribution (hint: use function \texttt{runif}) and store them in
  \texttt{x}.
\item
  Using logical subsetting as above, get all the elements of \texttt{x}
  which are larger than 0.5, and store them in \texttt{y}.
\item
  using the function \texttt{which}, store the \emph{indices} of all the
  elements of \texttt{x} which are larger than 0.5 in \texttt{iy}.
\item
  Check that \texttt{y} and \texttt{x{[}iy{]}} are identical.
\end{enumerate}

\subsection{Matrices}\label{matrices}

\texttt{R} can also be used for \textbf{matrix} calculations. Matrices
have rows and columns containing a single data type. In a matrix, the
order of rows and columns is important. (This is not true of \emph{data
frames}, which we will see later.)

Matrices can be created using the \texttt{matrix} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{9}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4 5 6 7 8 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(x, }\DataTypeTok{nrow =} \DecValTok{3}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{)}
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

Notice here that \texttt{R} is case sensitive (\texttt{x} vs
\texttt{X}).

By default the \texttt{matrix} function fills your data into the matrix
column by column. But we can also tell \texttt{R} to fill rows instead:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(x, }\DataTypeTok{nrow =} \DecValTok{3}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{, }\DataTypeTok{byrow =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    2    3
## [2,]    4    5    6
## [3,]    7    8    9
\end{verbatim}

We can also create a matrix of a specified dimension where every element
is the same, in this case \texttt{0}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Z =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4]
## [1,]    0    0    0    0
## [2,]    0    0    0    0
\end{verbatim}

Like vectors, matrices can be subsetted using square brackets,
\texttt{{[}{]}}. However, since matrices are two-dimensional, we need to
specify both a row and a column when subsetting.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X[}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

Here we accessed the element in the first row and the second column. We
could also subset an entire row or column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X[}\DecValTok{1}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 4 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X[, }\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 5 6
\end{verbatim}

We can also use vectors to subset more than one row or column at a time.
Here we subset to the first and third column of the second row.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 8
\end{verbatim}

Matrices can also be created by combining vectors as columns, using
\texttt{cbind}, or combining vectors as rows, using \texttt{rbind}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{9}
\KeywordTok{rev}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9 8 7 6 5 4 3 2 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 1 1 1 1 1 1 1 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rbind}\NormalTok{(x, }\KeywordTok{rev}\NormalTok{(x), }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
## x    1    2    3    4    5    6    7    8    9
##      9    8    7    6    5    4    3    2    1
##      1    1    1    1    1    1    1    1    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cbind}\NormalTok{(}\DataTypeTok{col_1 =}\NormalTok{ x, }\DataTypeTok{col_2 =} \KeywordTok{rev}\NormalTok{(x), }\DataTypeTok{col_3 =} \KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       col_1 col_2 col_3
##  [1,]     1     9     1
##  [2,]     2     8     1
##  [3,]     3     7     1
##  [4,]     4     6     1
##  [5,]     5     5     1
##  [6,]     6     4     1
##  [7,]     7     3     1
##  [8,]     8     2     1
##  [9,]     9     1     1
\end{verbatim}

When using \texttt{rbind} and \texttt{cbind} you can specify
``argument'' names that will be used as column names.

\texttt{R} can then be used to perform matrix calculations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{9}
\NormalTok{y =}\StringTok{ }\DecValTok{9}\OperatorTok{:}\DecValTok{1}
\NormalTok{X =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(x, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{Y =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(y, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    4    7
## [2,]    2    5    8
## [3,]    3    6    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    9    6    3
## [2,]    8    5    2
## [3,]    7    4    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{+}\StringTok{ }\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]   10   10   10
## [2,]   10   10   10
## [3,]   10   10   10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{-}\StringTok{ }\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]   -8   -2    4
## [2,]   -6    0    6
## [3,]   -4    2    8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{*}\StringTok{ }\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    9   24   21
## [2,]   16   25   16
## [3,]   21   24    9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{/}\StringTok{ }\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]      [,2]     [,3]
## [1,] 0.1111111 0.6666667 2.333333
## [2,] 0.2500000 1.0000000 4.000000
## [3,] 0.4285714 1.5000000 9.000000
\end{verbatim}

Note that \texttt{X\ *\ Y} is \textbf{not} matrix multiplication. It is
\emph{element by element} multiplication. (Same for \texttt{X\ /\ Y}).
Matrix multiplication uses \texttt{\%*\%}. Other matrix functions
include \texttt{t()} which gives the transpose of a matrix and
\texttt{solve()} which returns the inverse of a square matrix if it is
invertible.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OperatorTok{%*%}\StringTok{ }\NormalTok{Y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]   90   54   18
## [2,]  114   69   24
## [3,]  138   84   30
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    2    3
## [2,]    4    5    6
## [3,]    7    8    9
\end{verbatim}

\subsection{Arrays}\label{arrays}

A vector is a one-dimensional array. A matrix is a two-dimensional
array. In \texttt{R} you can create arrays of arbitrary dimensionality
\texttt{N}. Here is how:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{16}
\NormalTok{d3 =}\StringTok{ }\KeywordTok{array}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ d,}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{d4 =}\StringTok{ }\KeywordTok{array}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ d,}\DataTypeTok{dim =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{))  }\CommentTok{# will recycle 1:16}
\NormalTok{d3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 1
## 
##      [,1] [,2]
## [1,]    1    5
## [2,]    2    6
## [3,]    3    7
## [4,]    4    8
## 
## , , 2
## 
##      [,1] [,2]
## [1,]    9   13
## [2,]   10   14
## [3,]   11   15
## [4,]   12   16
\end{verbatim}

You can see that \texttt{d3} are simply \emph{two} (4,2) matrices laid
on top of each other, as if there were \emph{two pages}. Similary,
\texttt{d4} would have two pages, and another 3 registers in a fourth
dimension. And so on. You can subset an array like you would a vector or
a matrix, taking care to index each dimension:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d3[ ,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]  }\CommentTok{# all elements from col 1, page 1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d3[}\DecValTok{2}\OperatorTok{:}\DecValTok{3}\NormalTok{, , ]  }\CommentTok{# rows 2:3 from all pages}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 1
## 
##      [,1] [,2]
## [1,]    2    6
## [2,]    3    7
## 
## , , 2
## 
##      [,1] [,2]
## [1,]   10   14
## [2,]   11   15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d3[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{, ]  }\CommentTok{# row 2, col 2 from both pages.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  6 14
\end{verbatim}

\subsubsection{Task 3}\label{task-3}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create a vector containing \texttt{1,2,3,4,5} called v.
\item
  Create a (2,5) matrix \texttt{m} containing the data
  \texttt{1,2,3,4,5,6,7,8,9,10}. The first row should be
  \texttt{1,2,3,4,5}.
\item
  Perform matrix multiplication of \texttt{m} with \texttt{v}. Use the
  command \texttt{\%*\%}. What dimension does the output have?
\item
  Why does \texttt{v\ \%*\%\ m} not work?
\end{enumerate}

\subsection{Lists}\label{lists}

A list is a one-dimensional \emph{heterogeneous} data structure. So it
is indexed like a vector with a single integer value (or with a name),
but each element can contain an element of any type. Lists are similar
to a python or julia \texttt{Dict} object. Many \texttt{R} structures
and outputs are lists themselves. Lists are extremely useful and
versatile objects, so make sure you understand their useage:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# creation without fieldnames}
\KeywordTok{list}\NormalTok{(}\DecValTok{42}\NormalTok{, }\StringTok{"Hello"}\NormalTok{, }\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 42
## 
## [[2]]
## [1] "Hello"
## 
## [[3]]
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# creation with fieldnames}
\NormalTok{ex_list =}\StringTok{ }\KeywordTok{list}\NormalTok{(}
  \DataTypeTok{a =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{),}
  \DataTypeTok{b =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{c =} \StringTok{"Hello!"}\NormalTok{,}
  \DataTypeTok{d =} \ControlFlowTok{function}\NormalTok{(}\DataTypeTok{arg =} \DecValTok{42}\NormalTok{) \{}\KeywordTok{print}\NormalTok{(}\StringTok{"Hello World!"}\NormalTok{)\},}
  \DataTypeTok{e =} \KeywordTok{diag}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Lists can be subset using two syntaxes, the \texttt{\$} operator, and
square brackets \texttt{{[}{]}}. The \texttt{\$} operator returns a
named \textbf{element} of a list. The \texttt{{[}{]}} syntax returns a
\textbf{list}, while the \texttt{{[}{[}{]}{]}} returns an
\textbf{element} of a list.

\begin{itemize}
\tightlist
\item
  \texttt{ex\_list{[}1{]}} returns a list contain the first element.
\item
  \texttt{ex\_list{[}{[}1{]}{]}} returns the first element of the list,
  in this case, a vector.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# subsetting}
\NormalTok{ex_list}\OperatorTok{$}\NormalTok{e}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $a
## [1] 1 2 3 4
## 
## $b
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $a
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[}\KeywordTok{c}\NormalTok{(}\StringTok{"e"}\NormalTok{, }\StringTok{"a"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $e
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1
## 
## $a
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[}\StringTok{"e"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $e
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list[[}\StringTok{"e"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list}\OperatorTok{$}\NormalTok{d}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function(arg = 42) {print("Hello World!")}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ex_list}\OperatorTok{$}\KeywordTok{d}\NormalTok{(}\DataTypeTok{arg =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Hello World!"
\end{verbatim}

\subsubsection{Task 4}\label{task-4}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Copy and paste the above code for \texttt{ex\_list} into your R
  session. Remember that \texttt{list} can hold any kind of \texttt{R}
  object. Like\ldots{}another list! So, create a new list
  \texttt{new\_list} that has two fields: a first field called ``this''
  with string content \texttt{"is\ awesome"}, and a second field called
  ``ex\_list'' that contains \texttt{ex\_list}.
\item
  Accessing members is like in a plain list, just with several layers
  now. Get the element \texttt{c} from \texttt{ex\_list} in
  \texttt{new\_list}!
\item
  Compose a new string out of the first element in \texttt{new\_list},
  the element under label \texttt{this}. Use the function \texttt{paste}
  to print \texttt{R\ is\ awesome} to your screen.
\end{enumerate}

\subsection{Data Frames}\label{dataframes}

We have previously seen vectors and matrices for storing data as we
introduced \texttt{R}. We will now introduce a \textbf{data frame} which
will be the most common way that we store and interact with data in this
course. A \texttt{data.frame} is similar to a python
\texttt{pandas.dataframe} or a julia \texttt{DataFrame}. (But the
\texttt{R} version was the first! :-) )

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_data =}\StringTok{ }\KeywordTok{data.frame}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{),}
                          \DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\StringTok{"Hello"}\NormalTok{, }\DecValTok{9}\NormalTok{), }\StringTok{"Goodbye"}\NormalTok{),}
                          \DataTypeTok{z =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\OtherTok{TRUE}\NormalTok{, }\OtherTok{FALSE}\NormalTok{), }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Unlike a matrix, which can be thought of as a vector rearranged into
rows and columns, a data frame is not required to have the same data
type for each element. A data frame is a \textbf{list} of vectors, and
each vector has a \emph{name}. So, each vector must contain the same
data type, but the different vectors can store different data types.
Note, however, that all vectors must have \textbf{the same length}
(differently from a \texttt{list})!

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    x       y     z
## 1  1   Hello  TRUE
## 2  3   Hello FALSE
## 3  5   Hello  TRUE
## 4  7   Hello FALSE
## 5  9   Hello  TRUE
## 6  1   Hello FALSE
## 7  3   Hello  TRUE
## 8  5   Hello FALSE
## 9  7   Hello  TRUE
## 10 9 Goodbye FALSE
\end{verbatim}

Unlike a list which has more flexibility, the elements of a data frame
must all be vectors. Again, we access any given column with the
\texttt{\$} operator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_data}\OperatorTok{$}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 3 5 7 9 1 3 5 7 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all.equal}\NormalTok{(}\KeywordTok{length}\NormalTok{(example_data}\OperatorTok{$}\NormalTok{x),}
          \KeywordTok{length}\NormalTok{(example_data}\OperatorTok{$}\NormalTok{y),}
          \KeywordTok{length}\NormalTok{(example_data}\OperatorTok{$}\NormalTok{z))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    10 obs. of  3 variables:
##  $ x: num  1 3 5 7 9 1 3 5 7 9
##  $ y: Factor w/ 2 levels "Goodbye","Hello": 2 2 2 2 2 2 2 2 2 1
##  $ z: logi  TRUE FALSE TRUE FALSE TRUE FALSE ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ncol}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "x" "y" "z"
\end{verbatim}

The \texttt{data.frame()} function above is one way to create a data
frame. We can also import data from various file types in into
\texttt{R}, as well as use data stored in packages.

To read this data into \texttt{R}, we would use the \texttt{read\_csv()}
function from the \texttt{readr} package. Note that \texttt{R} has a
built in function \texttt{read.csv()} that operates very similarly. The
\texttt{readr} function \texttt{read\_csv()} has a number of advantages.
For example, it is much faster reading larger data.
\href{https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html}{It
also uses the \texttt{tibble} package to read the data as a tibble.}
\textbf{A \texttt{tibble} is simply a data frame that prints with
sanity.} Notice in the output below that we are given additional
information such as dimension and variable type.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readr)  }\CommentTok{# you need `install.packages("readr")` once!}
\NormalTok{path =}\StringTok{ }\KeywordTok{system.file}\NormalTok{(}\DataTypeTok{package=}\StringTok{"ScPoEconometrics"}\NormalTok{,}\StringTok{"datasets"}\NormalTok{,}\StringTok{"example-data.csv"}\NormalTok{)}
\NormalTok{example_data_from_disk =}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(path)}
\end{Highlighting}
\end{Shaded}

This particular line of code assumes that you installed the associated R
package to this book, hence you have this dataset stored on your
computer at
\texttt{system.file(package\ =\ "ScPoEconometrics","datasets","example-data.csv")}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_data_from_disk}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##        x y       z    
##    <int> <chr>   <lgl>
##  1     1 Hello   TRUE 
##  2     3 Hello   FALSE
##  3     5 Hello   TRUE 
##  4     7 Hello   FALSE
##  5     9 Hello   TRUE 
##  6     1 Hello   FALSE
##  7     3 Hello   TRUE 
##  8     5 Hello   FALSE
##  9     7 Hello   TRUE 
## 10     9 Goodbye FALSE
\end{verbatim}

The \texttt{as\_tibble()} function can be used to coerce a regular data
frame to a tibble.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tibble)}
\NormalTok{example_data =}\StringTok{ }\KeywordTok{as_tibble}\NormalTok{(example_data)}
\NormalTok{example_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##        x y       z    
##    <dbl> <fct>   <lgl>
##  1     1 Hello   TRUE 
##  2     3 Hello   FALSE
##  3     5 Hello   TRUE 
##  4     7 Hello   FALSE
##  5     9 Hello   TRUE 
##  6     1 Hello   FALSE
##  7     3 Hello   TRUE 
##  8     5 Hello   FALSE
##  9     7 Hello   TRUE 
## 10     9 Goodbye FALSE
\end{verbatim}

Alternatively, we could use the ``Import Dataset'' feature in RStudio
which can be found in the environment window. (By default, the top-right
pane of RStudio.) Once completed, this process will automatically
generate the code to import a file. The resulting code will be shown in
the console window. In recent versions of RStudio, \texttt{read\_csv()}
is used by default, thus reading in a tibble.

Earlier we looked at installing packages, in particular the
\texttt{ggplot2} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

Inside the \texttt{ggplot2} package is a dataset called \texttt{mpg}. By
loading the package using the \texttt{library()} function, we can now
access \texttt{mpg}.

When using data from inside a package, there are three things we would
generally like to do:

\begin{itemize}
\tightlist
\item
  Look at the raw data.
\item
  Understand the data. (Where did it come from? What are the variables?
  Etc.)
\item
  Visualize the data.
\end{itemize}

To look at the data, we have two useful commands: \texttt{head()} and
\texttt{str()}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{data}\NormalTok{(mpg)  }\CommentTok{# load dataset `mpg` from `ggplot2` package}
\KeywordTok{head}\NormalTok{(mpg, }\DataTypeTok{n =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 11
##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    cla~
##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <ch>
##  1 audi         a4      1.8  1999     4 auto~ f        18    29 p     com~
##  2 audi         a4      1.8  1999     4 manu~ f        21    29 p     com~
##  3 audi         a4      2    2008     4 manu~ f        20    31 p     com~
##  4 audi         a4      2    2008     4 auto~ f        21    30 p     com~
##  5 audi         a4      2.8  1999     6 auto~ f        16    26 p     com~
##  6 audi         a4      2.8  1999     6 manu~ f        18    26 p     com~
##  7 audi         a4      3.1  2008     6 auto~ f        18    27 p     com~
##  8 audi         a4 q~   1.8  1999     4 manu~ 4        18    26 p     com~
##  9 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     com~
## 10 audi         a4 q~   2    2008     4 manu~ 4        20    28 p     com~
\end{verbatim}

The function \texttt{head()} will display the first \texttt{n}
observations of the data frame. The \texttt{head()} function was more
useful before tibbles. Notice that \texttt{mpg} is a tibble already, so
the output from \texttt{head()} indicates there are only \texttt{10}
observations. Note that this applies to \texttt{head(mpg,\ n\ =\ 10)}
and not \texttt{mpg} itself. Also note that tibbles print a limited
number of rows and columns by default. The last line of the printed
output indicates with rows and columns were omitted.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mpg}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 234 x 11
##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    cla~
##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <ch>
##  1 audi         a4      1.8  1999     4 auto~ f        18    29 p     com~
##  2 audi         a4      1.8  1999     4 manu~ f        21    29 p     com~
##  3 audi         a4      2    2008     4 manu~ f        20    31 p     com~
##  4 audi         a4      2    2008     4 auto~ f        21    30 p     com~
##  5 audi         a4      2.8  1999     6 auto~ f        16    26 p     com~
##  6 audi         a4      2.8  1999     6 manu~ f        18    26 p     com~
##  7 audi         a4      3.1  2008     6 auto~ f        18    27 p     com~
##  8 audi         a4 q~   1.8  1999     4 manu~ 4        18    26 p     com~
##  9 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     com~
## 10 audi         a4 q~   2    2008     4 manu~ 4        20    28 p     com~
## # ... with 224 more rows
\end{verbatim}

The function \texttt{str()} will display the ``structure'' of the data
frame. It will display the number of \textbf{observations} and
\textbf{variables}, list the variables, give the type of each variable,
and show some elements of each variable. This information can also be
found in the ``Environment'' window in RStudio.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'tbl_df', 'tbl' and 'data.frame':    234 obs. of  11 variables:
##  $ manufacturer: chr  "audi" "audi" "audi" "audi" ...
##  $ model       : chr  "a4" "a4" "a4" "a4" ...
##  $ displ       : num  1.8 1.8 2 2 2.8 2.8 3.1 1.8 1.8 2 ...
##  $ year        : int  1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 ...
##  $ cyl         : int  4 4 4 4 6 6 6 4 4 4 ...
##  $ trans       : chr  "auto(l5)" "manual(m5)" "manual(m6)" "auto(av)" ...
##  $ drv         : chr  "f" "f" "f" "f" ...
##  $ cty         : int  18 21 20 21 16 18 18 18 16 20 ...
##  $ hwy         : int  29 29 31 30 26 26 27 26 25 28 ...
##  $ fl          : chr  "p" "p" "p" "p" ...
##  $ class       : chr  "compact" "compact" "compact" "compact" ...
\end{verbatim}

In this dataset an observation is for a particular model-year of a car,
and the variables describe attributes of the car, for example its
highway fuel efficiency.

To understand more about the data set, we use the \texttt{?} operator to
pull up the documentation for the data.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?mpg}
\end{Highlighting}
\end{Shaded}

\texttt{R} has a number of functions for quickly working with and
extracting basic information from data frames. To quickly obtain a
vector of the variable names, we use the \texttt{names()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "manufacturer" "model"        "displ"        "year"        
##  [5] "cyl"          "trans"        "drv"          "cty"         
##  [9] "hwy"          "fl"           "class"
\end{verbatim}

To access one of the variables \textbf{as a vector}, we use the
\texttt{\$} operator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mpg}\OperatorTok{$}\NormalTok{year}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] 1999 1999 2008 2008 1999 1999 2008 1999 1999 2008 2008 1999 1999 2008
##  [15] 2008 1999 2008 2008 2008 2008 2008 1999 2008 1999 1999 2008 2008 2008
##  [29] 2008 2008 1999 1999 1999 2008 1999 2008 2008 1999 1999 1999 1999 2008
##  [43] 2008 2008 1999 1999 2008 2008 2008 2008 1999 1999 2008 2008 2008 1999
##  [57] 1999 1999 2008 2008 2008 1999 2008 1999 2008 2008 2008 2008 2008 2008
##  [71] 1999 1999 2008 1999 1999 1999 2008 1999 1999 1999 2008 2008 1999 1999
##  [85] 1999 1999 1999 2008 1999 2008 1999 1999 2008 2008 1999 1999 2008 2008
##  [99] 2008 1999 1999 1999 1999 1999 2008 2008 2008 2008 1999 1999 2008 2008
## [113] 1999 1999 2008 1999 1999 2008 2008 2008 2008 2008 2008 2008 1999 1999
## [127] 2008 2008 2008 2008 1999 2008 2008 1999 1999 1999 2008 1999 2008 2008
## [141] 1999 1999 1999 2008 2008 2008 2008 1999 1999 2008 1999 1999 2008 2008
## [155] 1999 1999 1999 2008 2008 1999 1999 2008 2008 2008 2008 1999 1999 1999
## [169] 1999 2008 2008 2008 2008 1999 1999 1999 1999 2008 2008 1999 1999 2008
## [183] 2008 1999 1999 2008 1999 1999 2008 2008 1999 1999 2008 1999 1999 1999
## [197] 2008 2008 1999 2008 1999 1999 2008 1999 1999 2008 2008 1999 1999 2008
## [211] 2008 1999 1999 1999 1999 2008 2008 2008 2008 1999 1999 1999 1999 1999
## [225] 1999 2008 2008 1999 1999 2008 2008 1999 1999 2008
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mpg}\OperatorTok{$}\NormalTok{hwy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] 29 29 31 30 26 26 27 26 25 28 27 25 25 25 25 24 25 23 20 15 20 17 17
##  [24] 26 23 26 25 24 19 14 15 17 27 30 26 29 26 24 24 22 22 24 24 17 22 21
##  [47] 23 23 19 18 17 17 19 19 12 17 15 17 17 12 17 16 18 15 16 12 17 17 16
##  [70] 12 15 16 17 15 17 17 18 17 19 17 19 19 17 17 17 16 16 17 15 17 26 25
##  [93] 26 24 21 22 23 22 20 33 32 32 29 32 34 36 36 29 26 27 30 31 26 26 28
## [116] 26 29 28 27 24 24 24 22 19 20 17 12 19 18 14 15 18 18 15 17 16 18 17
## [139] 19 19 17 29 27 31 32 27 26 26 25 25 17 17 20 18 26 26 27 28 25 25 24
## [162] 27 25 26 23 26 26 26 26 25 27 25 27 20 20 19 17 20 17 29 27 31 31 26
## [185] 26 28 27 29 31 31 26 26 27 30 33 35 37 35 15 18 20 20 22 17 19 18 20
## [208] 29 26 29 29 24 44 29 26 29 29 29 29 23 24 44 41 29 26 28 29 29 29 28
## [231] 29 26 26 26
\end{verbatim}

We can use the \texttt{dim()}, \texttt{nrow()} and \texttt{ncol()}
functions to obtain information about the dimension of the data frame.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 234  11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 234
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ncol}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 11
\end{verbatim}

Here \texttt{nrow()} is also the number of observations, which in most
cases is the \emph{sample size}.

Subsetting data frames can work much like subsetting matrices using
square brackets, \texttt{{[}\ ,\ {]}}. Here, we find fuel efficient
vehicles earning over 35 miles per gallon and only display
\texttt{manufacturer}, \texttt{model} and \texttt{year}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# mpg[row condition, col condition]}
\NormalTok{mpg[mpg}\OperatorTok{$}\NormalTok{hwy }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"manufacturer"}\NormalTok{, }\StringTok{"model"}\NormalTok{, }\StringTok{"year"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   manufacturer model       year
##   <chr>        <chr>      <int>
## 1 honda        civic       2008
## 2 honda        civic       2008
## 3 toyota       corolla     2008
## 4 volkswagen   jetta       1999
## 5 volkswagen   new beetle  1999
## 6 volkswagen   new beetle  1999
\end{verbatim}

An alternative would be to use the \texttt{subset()} function, which has
a much more readable syntax.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{subset}\NormalTok{(mpg, }\DataTypeTok{subset =}\NormalTok{ hwy }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{, }\DataTypeTok{select =} \KeywordTok{c}\NormalTok{(}\StringTok{"manufacturer"}\NormalTok{, }\StringTok{"model"}\NormalTok{, }\StringTok{"year"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Lastly, we could use the \texttt{filter} and \texttt{select} functions
from the \texttt{dplyr} package which introduces the \emph{pipe
operator} \texttt{\%\textgreater{}\%} from the \texttt{magrittr}
package. A \emph{pipe} is a concept from the Unix world, where it means
to take the output of some command, and pass it on to another command.
This way, one can construct a \emph{pipeline} of commands. We will see
more of this in chapter \ref{sum}. For additional info on the pipe
operator in R, you might be interested
\href{https://www.datacamp.com/community/tutorials/pipe-r-tutorial}{in
this tutorial}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{mpg }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(hwy }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(manufacturer, model, year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   manufacturer model       year
##   <chr>        <chr>      <int>
## 1 honda        civic       2008
## 2 honda        civic       2008
## 3 toyota       corolla     2008
## 4 volkswagen   jetta       1999
## 5 volkswagen   new beetle  1999
## 6 volkswagen   new beetle  1999
\end{verbatim}

Note that the above syntax is equivalent to the following pipe-free
command (which is much harder to read!):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{select}\NormalTok{(}\KeywordTok{filter}\NormalTok{(mpg, hwy }\OperatorTok{>}\StringTok{ }\DecValTok{35}\NormalTok{), manufacturer, model, year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   manufacturer model       year
##   <chr>        <chr>      <int>
## 1 honda        civic       2008
## 2 honda        civic       2008
## 3 toyota       corolla     2008
## 4 volkswagen   jetta       1999
## 5 volkswagen   new beetle  1999
## 6 volkswagen   new beetle  1999
\end{verbatim}

All three (four?) approaches produce the same results. Which you use
will be largely based on a given situation as well as your preference.

\subsubsection{Task 5}\label{task-5}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Make sure to have the \texttt{mpg} dataset loaded by typing
  \texttt{data(mpg)} (and \texttt{library(ggplot2)} if you haven't!).
  Use the \texttt{table} function to find out how many cars were built
  by \emph{mercury}?
\item
  What is the average year the audi's were built in this dataset? Use
  the function \texttt{mean} on the subset of column \texttt{year} that
  corresponds to \texttt{audi}. (Be careful: subsetting a
  \texttt{tibble} returns a \texttt{tibble} (and not a vector)!. so get
  the \texttt{year} column after you have subset the \texttt{tibble}.)
\item
  Use the \texttt{dplyr} piping syntax from above first with
  \texttt{group\_by} and then with
  \texttt{summarise(newvar=your\_expression)} to find the mean
  \texttt{year} by all manufacturers (i.e.~same as previous task, but
  for all manufacturers. don't write a loop!).
\end{enumerate}

\section{Programming Basics}\label{programming-basics}

\subsection{Control Flow}\label{control-flow}

In \texttt{R}, the if/else syntax is:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ (}\DataTypeTok{condition =} \OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{  some R code}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{  more R code}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

For example,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{1}
\NormalTok{y =}\StringTok{ }\DecValTok{3}
\ControlFlowTok{if}\NormalTok{ (x }\OperatorTok{>}\StringTok{ }\NormalTok{y) \{}
\NormalTok{  z =}\StringTok{ }\NormalTok{x }\OperatorTok{*}\StringTok{ }\NormalTok{y}
  \KeywordTok{print}\NormalTok{(}\StringTok{"x is larger than y"}\NormalTok{)}
\NormalTok{\} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{  z =}\StringTok{ }\NormalTok{x }\OperatorTok{+}\StringTok{ }\DecValTok{5} \OperatorTok{*}\StringTok{ }\NormalTok{y}
  \KeywordTok{print}\NormalTok{(}\StringTok{"x is less than or equal to y"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "x is less than or equal to y"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16
\end{verbatim}

\texttt{R} also has a special function \texttt{ifelse()} which is very
useful. It returns one of two specified values based on a conditional
statement.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ifelse}\NormalTok{(}\DecValTok{4} \OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\textbf{For Loops}

Now a \texttt{for} loop example,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\DecValTok{11}\OperatorTok{:}\DecValTok{15}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{) \{}
\NormalTok{  x[i] =}\StringTok{ }\NormalTok{x[i] }\OperatorTok{+}\StringTok{ }\NormalTok{i}
\NormalTok{\}}

\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12 14 16 18 20
\end{verbatim}

\subsection{Functions}\label{functions}

So far we have been using functions, but haven't actually discussed some
of their details.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{function_name}\NormalTok{(}\DataTypeTok{arg1 =} \DecValTok{10}\NormalTok{, }\DataTypeTok{arg2 =} \DecValTok{20}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To use a function, you simply type its name, followed by an open
parenthesis, then specify values of its arguments, then finish with a
closing parenthesis.

An \textbf{argument} is a variable which is used in the body of the
function. Specifying the values of the arguments is essentially
providing the inputs to the function.

We can also write our own functions in \texttt{R}. For example, we often
like to ``standardize'' variables, that is, subtracting the sample mean,
and dividing by the sample standard deviation.

\[
z = \frac{x - \bar{x}}{s}
\]

In \texttt{R} we would write a function to do this. When writing a
function, there are three thing you must do.

\begin{itemize}
\tightlist
\item
  Give the function a name. Preferably something that is short, but
  descriptive.
\item
  Specify the arguments using \texttt{function()}
\item
  Write the body of the function within curly braces, \texttt{\{\}}.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardize =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  m =}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)}
\NormalTok{  std =}\StringTok{ }\KeywordTok{sd}\NormalTok{(x)}
\NormalTok{  result =}\StringTok{ }\NormalTok{(x }\OperatorTok{-}\StringTok{ }\NormalTok{m) }\OperatorTok{/}\StringTok{ }\NormalTok{std}
\NormalTok{  result}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here the name of the function is \texttt{standardize}, and the function
has a single argument \texttt{x} which is used in the body of function.
Note that the output of the final line of the body is what is returned
by the function. In this case the function returns the vector stored in
the variable \texttt{result}.

To test our function, we will take a random sample of size
\texttt{n\ =\ 10} from a normal distribution with a mean of \texttt{2}
and a standard deviation of \texttt{5}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DataTypeTok{test_sample =} \KeywordTok{rnorm}\NormalTok{(}\DataTypeTok{n =} \DecValTok{10}\NormalTok{, }\DataTypeTok{mean =} \DecValTok{2}\NormalTok{, }\DataTypeTok{sd =} \DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1.6897124 13.7302919 -1.8040249 -0.3607487  1.5113347 14.0037230
##  [7]  3.7270884 -9.2420370  5.8421369 -1.7430820
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{standardize}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ test_sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] -0.1471060  1.5466831 -0.6385818 -0.4355513 -0.1721990  1.5851475
##  [7]  0.1394986 -1.6849121  0.4370296 -0.6300087
\end{verbatim}

This function could be written much more succinctly, simply performing
all the operations on one line and immediately returning the result,
without storing any of the intermediate results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardize =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  (x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)) }\OperatorTok{/}\StringTok{ }\KeywordTok{sd}\NormalTok{(x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

When specifying arguments, you can provide default arguments.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{power_of_num =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(num, }\DataTypeTok{power =} \DecValTok{2}\NormalTok{) \{}
\NormalTok{  num }\OperatorTok{^}\StringTok{ }\NormalTok{power}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Let's look at a number of ways that we could run this function to
perform the operation \texttt{10\^{}2} resulting in \texttt{100}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DataTypeTok{num =} \DecValTok{10}\NormalTok{, }\DataTypeTok{power =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DataTypeTok{power =} \DecValTok{2}\NormalTok{, }\DataTypeTok{num =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

Note that without using the argument names, the order matters. The
following code will not evaluate to the same output as the previous
example.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1024
\end{verbatim}

Also, the following line of code would produce an error since arguments
without a default value must be specified.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{power_of_num}\NormalTok{(}\DataTypeTok{power =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

To further illustrate a function with a default argument, we will write
a function that calculates sample variance two ways.

By default, the function will calculate the unbiased estimate of
\(\sigma^2\), which we will call \(s^2\).

\[
s^2 = \frac{1}{n - 1}\sum_{i=1}^{n}(x - \bar{x})^2
\]

It will also have the ability to return the biased estimate (based on
maximum likelihood) which we will call \(\hat{\sigma}^2\).

\[
\hat{\sigma}^2 = \frac{1}{n}\sum_{i=1}^{n}(x - \bar{x})^2
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get_var =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, }\DataTypeTok{biased =} \OtherTok{FALSE}\NormalTok{) \{}
\NormalTok{  n =}\StringTok{ }\KeywordTok{length}\NormalTok{(x) }\OperatorTok{-}\StringTok{ }\DecValTok{1} \OperatorTok{*}\StringTok{ }\OperatorTok{!}\NormalTok{biased}
\NormalTok{  (}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{n) }\OperatorTok{*}\StringTok{ }\KeywordTok{sum}\NormalTok{((x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get_var}\NormalTok{(test_sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50.53312
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get_var}\NormalTok{(test_sample, }\DataTypeTok{biased =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50.53312
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{var}\NormalTok{(test_sample)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50.53312
\end{verbatim}

We see the function is working as expected, and when returning the
unbiased estimate it matches \texttt{R}'s built in function
\texttt{var()}. Finally, let's examine the biased estimate of
\(\sigma^2\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{get_var}\NormalTok{(test_sample, }\DataTypeTok{biased =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 45.47981
\end{verbatim}

\chapter{Working With Data}\label{sum}

In this chapter we will first learn some basic concepts that help
summarizing data. Then, we will tackle a real-world task and read,
clean, and summarize data from the web.

\section{Summary Statistics}\label{summary-statistics}

\texttt{R} has built in functions for a large number of summary
statistics. For numeric variables, we can summarize data by looking at
their center and spread, for example. \emph{Make sure to have loaded the
\texttt{ggplot2} library to be able to access the \texttt{mpg} dataset
as introduced in section \ref{dataframes}.}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\end{Highlighting}
\end{Shaded}

\subsection*{Central Tendency}\label{central-tendency}
\addcontentsline{toc}{subsection}{Central Tendency}

Suppose we want to know the \emph{mean} and \emph{median} of all the
values stored in the \texttt{data.frame} column \texttt{mpg\$cty}:

\begin{longtable}[]{@{}ccc@{}}
\toprule
Measure & \texttt{R} & Result\tabularnewline
\midrule
\endhead
Mean & \texttt{mean(mpg\$cty)} & 16.8589744\tabularnewline
Median & \texttt{median(mpg\$cty)} & 17\tabularnewline
\bottomrule
\end{longtable}

\subsection*{Spread}\label{spread}
\addcontentsline{toc}{subsection}{Spread}

How do the values in that column \emph{vary}? How far \emph{spread out}
are they?

\begin{longtable}[]{@{}ccc@{}}
\toprule
Measure & \texttt{R} & Result\tabularnewline
\midrule
\endhead
Variance & \texttt{var(mpg\$cty)} & 18.1130736\tabularnewline
Standard Deviation & \texttt{sd(mpg\$cty)} & 4.2559457\tabularnewline
IQR & \texttt{IQR(mpg\$cty)} & 5\tabularnewline
Minimum & \texttt{min(mpg\$cty)} & 9\tabularnewline
Maximum & \texttt{max(mpg\$cty)} & 35\tabularnewline
Range & \texttt{range(mpg\$cty)} & 9, 35\tabularnewline
\bottomrule
\end{longtable}

\subsection*{Categorical}\label{categorical}
\addcontentsline{toc}{subsection}{Categorical}

For categorical variables, counts and percentages can be used for
summary.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{drv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##   4   f   r 
## 103 106  25
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{drv) }\OperatorTok{/}\StringTok{ }\KeywordTok{nrow}\NormalTok{(mpg)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##         4         f         r 
## 0.4401709 0.4529915 0.1068376
\end{verbatim}

\section{Plotting}\label{plotting}

Now that we have some data to work with, and we have learned about the
data at the most basic level, our next tasks will be to visualize it.
Often, a proper visualization can illuminate features of the data that
can inform further analysis.

We will look at four methods of visualizing data by using the basic
\texttt{plot} facilities built-in with \texttt{R}:

\begin{itemize}
\tightlist
\item
  Histograms
\item
  Barplots
\item
  Boxplots
\item
  Scatterplots
\end{itemize}

\subsection{Histograms}\label{histograms}

When visualizing a single numerical variable, a \textbf{histogram} is
useful. It summarizes the \emph{distribution} of values in a vector. In
\texttt{R} you create one using the \texttt{hist()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{cty)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-79-1.pdf}

The histogram function has a number of parameters which can be changed
to make our plot look much nicer. Use the \texttt{?} operator to read
the documentation for the \texttt{hist()} to see a full list of these
parameters.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{hist}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{cty,}
     \DataTypeTok{xlab   =} \StringTok{"Miles Per Gallon (City)"}\NormalTok{,}
     \DataTypeTok{main   =} \StringTok{"Histogram of MPG (City)"}\NormalTok{, }\CommentTok{# main title}
     \DataTypeTok{breaks =} \DecValTok{12}\NormalTok{,   }\CommentTok{# how many breaks?}
     \DataTypeTok{col    =} \StringTok{"red"}\NormalTok{,}
     \DataTypeTok{border =} \StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-80-1.pdf}

Importantly, you should always be sure to label your axes and give the
plot a title. The argument \texttt{breaks} is specific to
\texttt{hist()}. Entering an integer will give a suggestion to
\texttt{R} for how many bars to use for the histogram. By default
\texttt{R} will attempt to intelligently guess a good number of
\texttt{breaks}, but as we can see here, it is sometimes useful to
modify this yourself.

\subsection{Barplots}\label{barplots}

Somewhat similar to a histogram, a barplot can provide a visual summary
of a categorical variable, or a numeric variable with a finite number of
values, like a ranking from 1 to 10.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{barplot}\NormalTok{(}\KeywordTok{table}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{drv))}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-81-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{barplot}\NormalTok{(}\KeywordTok{table}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{drv),}
        \DataTypeTok{xlab   =} \StringTok{"Drivetrain (f = FWD, r = RWD, 4 = 4WD)"}\NormalTok{,}
        \DataTypeTok{ylab   =} \StringTok{"Frequency"}\NormalTok{,}
        \DataTypeTok{main   =} \StringTok{"Drivetrains"}\NormalTok{,}
        \DataTypeTok{col    =} \StringTok{"dodgerblue"}\NormalTok{,}
        \DataTypeTok{border =} \StringTok{"darkorange"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-82-1.pdf}

\subsection{Boxplots}\label{boxplots}

To visualize the relationship between a numerical and categorical
variable, once could use a \textbf{boxplot}. In the \texttt{mpg}
dataset, the \texttt{drv} variable takes a small, finite number of
values. A car can only be front wheel drive, 4 wheel drive, or rear
wheel drive.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{unique}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{drv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "f" "4" "r"
\end{verbatim}

First note that we can use a single boxplot as an alternative to a
histogram for visualizing a single numerical variable. To do so in
\texttt{R}, we use the \texttt{boxplot()} function. The box shows the
\emph{interquartile range}, the solid line in the middle is the value of
the median, the wiskers show 1.5 times the interquartile range, and the
dots are outliers.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(mpg}\OperatorTok{$}\NormalTok{hwy)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-84-1.pdf}

However, more often we will use boxplots to compare a numerical variable
for different values of a categorical variable.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(hwy }\OperatorTok{~}\StringTok{ }\NormalTok{drv, }\DataTypeTok{data =}\NormalTok{ mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-85-1.pdf}

Here used the \texttt{boxplot()} command to create side-by-side
boxplots. However, since we are now dealing with two variables, the
syntax has changed. The \texttt{R} syntax
\texttt{hwy\ \textasciitilde{}\ drv,\ data\ =\ mpg} reads ``Plot the
\texttt{hwy} variable against the \texttt{drv} variable using the
dataset \texttt{mpg}.'' We see the use of a \texttt{\textasciitilde{}}
(which specifies a formula) and also a \texttt{data\ =} argument. This
will be a syntax that is common to many functions we will use in this
course.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{boxplot}\NormalTok{(hwy }\OperatorTok{~}\StringTok{ }\NormalTok{drv, }\DataTypeTok{data =}\NormalTok{ mpg,}
     \DataTypeTok{xlab   =} \StringTok{"Drivetrain (f = FWD, r = RWD, 4 = 4WD)"}\NormalTok{,}
     \DataTypeTok{ylab   =} \StringTok{"Miles Per Gallon (Highway)"}\NormalTok{,}
     \DataTypeTok{main   =} \StringTok{"MPG (Highway) vs Drivetrain"}\NormalTok{,}
     \DataTypeTok{pch    =} \DecValTok{20}\NormalTok{,}
     \DataTypeTok{cex    =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{col    =} \StringTok{"darkorange"}\NormalTok{,}
     \DataTypeTok{border =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-86-1.pdf}

Again, \texttt{boxplot()} has a number of additional arguments which
have the ability to make our plot more visually appealing.

\subsection{Scatterplots}\label{scatterplots}

Lastly, to visualize the relationship between two numeric variables we
will use a \textbf{scatterplot}. This can be done with the
\texttt{plot()} function and the \texttt{\textasciitilde{}} syntax we
just used with a boxplot. (The function \texttt{plot()} can also be used
more generally; see the documentation for details.)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(hwy }\OperatorTok{~}\StringTok{ }\NormalTok{displ, }\DataTypeTok{data =}\NormalTok{ mpg)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-87-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(hwy }\OperatorTok{~}\StringTok{ }\NormalTok{displ, }\DataTypeTok{data =}\NormalTok{ mpg,}
     \DataTypeTok{xlab =} \StringTok{"Engine Displacement (in Liters)"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Miles Per Gallon (Highway)"}\NormalTok{,}
     \DataTypeTok{main =} \StringTok{"MPG (Highway) vs Engine Displacement"}\NormalTok{,}
     \DataTypeTok{pch  =} \DecValTok{20}\NormalTok{,}
     \DataTypeTok{cex  =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{col  =} \StringTok{"dodgerblue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-88-1.pdf}

\subsection{\texorpdfstring{\texttt{ggplot}}{ggplot}}\label{ggplot}

All of the above plots could also have been generated using the
\texttt{ggplot} function from the already loaded \texttt{ggplot2}
package. Which function you use is up to you, but sometimes a plot is
easier to build in base R (like in the \texttt{boxplot} example maybe),
sometimes the other way around.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ mpg,}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{displ,}\DataTypeTok{y=}\NormalTok{hwy)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-89-1.pdf}

\texttt{ggplot} is impossible to describe in brief terms, so please look
at \href{http://ggplot2.tidyverse.org}{the package's website} which
provides excellent guidance. We will from time to time use ggplot in
this book, so try to familiarize yourself with it. Let's quickly
demonstrate how one could customize that first plot:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ mpg, }\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{displ,}\DataTypeTok{y=}\NormalTok{hwy)) }\OperatorTok{+}\StringTok{   }\CommentTok{# ggplot() makes base plot}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{color=}\StringTok{"blue"}\NormalTok{,}\DataTypeTok{size=}\DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{     }\CommentTok{# how to show x and y?}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Miles Per Gallon (Highway)"}\NormalTok{) }\OperatorTok{+}\StringTok{  }\CommentTok{# name of y axis}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{name=}\StringTok{"Engine Displacement (in Liters)"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\CommentTok{# x axis}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}\StringTok{    }\CommentTok{# change the background}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"MPG (Highway) vs Engine Displacement"}\NormalTok{)   }\CommentTok{# add a title}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-90-1.pdf}

\section{Summarizing Two Variables}\label{summarize-two}

We often are interested in how two (or more!) variables are related to
each other. The core concepts here are \emph{covariance} and
\emph{correlation}. Let's generate some data on \texttt{x} and
\texttt{y} and plot them against each other:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/x-y-corr-1} 

}

\caption{How are $x$ and $y$ related?}\label{fig:x-y-corr}
\end{figure}

Taking as example the data in this plot, the concepts \emph{covariance}
and \emph{correlation} relate to the following type of question:

\begin{note}
Given we observe value of something like \(x=2\), say, can we expect a
high or a low value of \texttt{y}, on average? Something like \(y=2\) or
rather something like \(y=-2\)?
\end{note}

 The answer to this type of question can be addressed by computing the
covariance of both variables:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cov}\NormalTok{(x,y)  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.041195
\end{verbatim}

Here, this gives a positive number, 1.04, indicating that as one
variable lies above it's average, the other one does as well. In other
words, it indicates a \textbf{positive relationship}. What is less
clear, however, how to interpret the magnitude of 1.04. Is that a
\emph{strong} or a \emph{weak} positive association?

In fact, we cannot tell. This is because the covariance is measured in
the same units as the data, and those units often differ between both
variables. There is a better measure available to us though, the
\textbf{correlation}, which is obtained by \emph{standardizing} each
variable. By \emph{standardizing} a variable \(x\) one means to divide
\(x\) by its standard deviation \(\sigma_x\):

\[
z = \frac{x}{\sigma_x}
\]

The \emph{correlation coefficient} between \(x\) and \(y\), commonly
denoted \(r_{x,y}\), is then defined as

\[
r_{x,y} = \frac{cov(x,y)}{\sigma_x \sigma_y},
\]

and we get rid of the units problem. In \texttt{R}, you can call
directly

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cor}\NormalTok{(x,y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9142495
\end{verbatim}

Now this is better. Given that the correlation has to lie in \([-1,1]\),
a value of 0.91 is indicative of a rather strong positive relationship
for the data in figure \ref{fig:x-y-corr}

\section{\texorpdfstring{The
\texttt{tidyverse}}{The tidyverse}}\label{the-tidyverse}

\href{http://hadley.nz}{Hadley Wickham} is the author of R packages
\texttt{ggplot2} and also of \texttt{dplyr} (and also a myriad of
others). With \texttt{ggplot2} he pioneered what he calls the
\emph{grammar of graphics} (hence, \texttt{gg}). Grammar in the sense
that there are \textbf{nouns} and \textbf{verbs} and a \textbf{syntax},
i.e.~rules of how nouns and verbs are to be put together to construct an
understandable sentence. He has extended the \emph{grammar} idea into
various other packages. The \texttt{tidyverse} package is a collection
of those packages.

\texttt{tidy} data is data where:

\begin{itemize}
\tightlist
\item
  Each variable is a column
\item
  Each observation is a row
\item
  Each value is a cell
\end{itemize}

Fair enough, you might say, that is a regular spreadsheet. And you are
right! However, data comes to us \emph{not} tidy most of the times, and
we first need to clean, or \texttt{tidy}, it up. Once it's in
\texttt{tidy} format, we can use the tools in the \texttt{tidyverse}
with great efficiency to analyse the data and stop worrying about which
tool to use.

\subsection{Tidy Example: Importing Excel
Data}\label{tidy-example-importing-excel-data}

The data we will look at is from
\href{http://ec.europa.eu/eurostat/data/database}{Eurostat} on
demography and migration. You should download the data yourself (click
on previous link, then drill down to \emph{database by themes
\textgreater{} Population and social conditions \textgreater{} Demograph
and migration \textgreater{} Population change - Demographic balance and
crude rates at national level (demo\_gind)}).

Once downloaded, we can read the data with the function
\texttt{read\_excel} from the package
\href{http://readxl.tidyverse.org}{\texttt{readxl}}, again part of the
\texttt{tidyverse} suite.

It's important to know how the data is organized in the spreadsheet.
Open the file with Excel to see:

\begin{itemize}
\tightlist
\item
  There is a heading which we don't need.
\item
  There are 5 rows with info that we don't need.
\item
  There is one table per variable (total population, males, females,
  etc)
\item
  Each table has one row for each country, and one column for each year.
\item
  As such, this data is \textbf{not tidy}.
\end{itemize}

Now we will read the first chunk of data, from the first table:
\emph{total population}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(readxl)  }\CommentTok{# load the library}


\CommentTok{# Notice that if you installed the R package of this book,}
\CommentTok{# you have the .xls data file already at }
\CommentTok{# `system.file(package="ScPoEconometrics",}
\CommentTok{#                        "datasets","demo_gind.xls")`}
\CommentTok{# otherwise:}
\CommentTok{# * download the file to your computer}
\CommentTok{# * change the argument `path` to where you downloaded it}
\CommentTok{# you may want to change your working directory with `setwd("your/directory")}
\CommentTok{# or in RStudio by clicking Session > Set Working Directory}

\CommentTok{# total population in raw format}
\NormalTok{tot_pop_raw =}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}
                \DataTypeTok{path =} \KeywordTok{system.file}\NormalTok{(}\DataTypeTok{package=}\StringTok{"ScPoEconometrics"}\NormalTok{,}
                                    \StringTok{"datasets"}\NormalTok{,}\StringTok{"demo_gind.xls"}\NormalTok{), }
                \DataTypeTok{sheet=}\StringTok{"Data"}\NormalTok{, }\CommentTok{# which sheet}
                \DataTypeTok{range=}\StringTok{"A9:K68"}\NormalTok{)  }\CommentTok{# which excel cell range to read}
\KeywordTok{names}\NormalTok{(tot_pop_raw)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "Country"}   \CommentTok{# lets rename the first column}
\NormalTok{tot_pop_raw}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 59 x 11
##    Country `2008` `2009` `2010` `2011` `2012` `2013` `2014` `2015` `2016`
##    <chr>   <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr> 
##  1 Europe~ 50029~ 50209~ 50317~ 50296~ 50404~ 50516~ 50701~ 50854~ 51027~
##  2 Europe~ 43872~ 44004~ 44066~ 43994~ 44055~ 44125~ 44266~ 44366~ 44489~
##  3 Europe~ 49598~ 49778~ 49886~ 49867~ 49977~ 50090~ 50276~ 50431~ 50608~
##  4 Euro a~ 33309~ 33447~ 33526~ 33457~ 33528~ 33604~ 33754~ 33856~ 33988~
##  5 Euro a~ 32988~ 33128~ 33212~ 33152~ 33228~ 33307~ 33459~ 33563~ 33699~
##  6 Belgium 10666~ 10753~ 10839~ 11000~ 11075~ 11137~ 11180~ 11237~ 11311~
##  7 Bulgar~ 75180~ 74671~ 74217~ 73694~ 73272~ 72845~ 72456~ 72021~ 71537~
##  8 Czech ~ 10343~ 10425~ 10462~ 10486~ 10505~ 10516~ 10512~ 10538~ 10553~
##  9 Denmark 54757~ 55114~ 55347~ 55606~ 55805~ 56026~ 56272~ 56597~ 57072~
## 10 German~ 82217~ 82002~ 81802~ 80222~ 80327~ 80523~ 80767~ 81197~ 82175~
## # ... with 49 more rows, and 1 more variable: `2017` <chr>
\end{verbatim}

This shows a \texttt{tibble}, which we encountered already in
\ref{dataframes}. The column names are \texttt{Country,2008,2009,...},
and the rows are numbered \texttt{1,2,3,...}. Notice, in particular,
that \emph{all} columns seem to be of type
\texttt{\textless{}chr\textgreater{}}, i.e.~characters - a string, not a
number! We'll have to fix that, as this is clearly numeric data.

\subsubsection{\texorpdfstring{\texttt{tidyr}}{tidyr}}\label{tidyr}

In the previous \texttt{tibble}, each year is a column name (like
\texttt{2008}) instead of all years being collected in one column
\texttt{year}. We really would like to have several rows for each
Country, one row per year. We want to \texttt{gather()} all years into a
new column to tidy this up - and here is how:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  specify which columns are to be gathered: in our case, all years (note
  that \texttt{paste(2008:2017)} produces a vector like
  \texttt{{[}"2008",\ "2009",\ "2010",...{]}})
\item
  say what those columns should be gathered into, i.e.~what is the
  \emph{key} for those values: we'll call it \texttt{year}.
\item
  Finally, what is the name of the new resulting column, containing the
  \emph{value} from each cell: let's call it \texttt{counts}.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyr)   }\CommentTok{# for the gather function}
\NormalTok{tot_pop =}\StringTok{ }\KeywordTok{gather}\NormalTok{(tot_pop_raw, }\KeywordTok{paste}\NormalTok{(}\DecValTok{2008}\OperatorTok{:}\DecValTok{2017}\NormalTok{),}\DataTypeTok{key=}\StringTok{"year"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"counts"}\NormalTok{)}
\NormalTok{tot_pop}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 590 x 3
##    Country                                          year  counts   
##    <chr>                                            <chr> <chr>    
##  1 European Union (current composition)             2008  500297033
##  2 European Union (without United Kingdom)          2008  438725386
##  3 European Union (before the accession of Croatia) 2008  495985066
##  4 Euro area (19 countries)                         2008  333096775
##  5 Euro area (18 countries)                         2008  329884170
##  6 Belgium                                          2008  10666866 
##  7 Bulgaria                                         2008  7518002  
##  8 Czech Republic                                   2008  10343422 
##  9 Denmark                                          2008  5475791  
## 10 Germany (until 1990 former territory of the FRG) 2008  82217837 
## # ... with 580 more rows
\end{verbatim}

That's better! However, \texttt{counts} is still \texttt{chr}! Let's
convert it to a number:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tot_pop}\OperatorTok{$}\NormalTok{counts =}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(tot_pop}\OperatorTok{$}\NormalTok{counts)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: NAs introduced by coercion
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tot_pop}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 590 x 3
##    Country                                          year     counts
##    <chr>                                            <chr>     <int>
##  1 European Union (current composition)             2008  500297033
##  2 European Union (without United Kingdom)          2008  438725386
##  3 European Union (before the accession of Croatia) 2008  495985066
##  4 Euro area (19 countries)                         2008  333096775
##  5 Euro area (18 countries)                         2008  329884170
##  6 Belgium                                          2008   10666866
##  7 Bulgaria                                         2008    7518002
##  8 Czech Republic                                   2008   10343422
##  9 Denmark                                          2008    5475791
## 10 Germany (until 1990 former territory of the FRG) 2008   82217837
## # ... with 580 more rows
\end{verbatim}

Now you can see that column \texttt{counts} is indeed \texttt{int},
i.e.~an integer number, and we are fine. The
\texttt{Warning:\ NAs\ introduced\ by\ coercion} means that \texttt{R}
converted some values to \texttt{NA}, because it couldn't convert them
into \texttt{numeric}. More below!

\subsubsection{\texorpdfstring{\texttt{dplyr}}{dplyr}}\label{dplyr}

\begin{quote}
The \href{http://r4ds.had.co.nz/transform.html}{transform} chapter of
Hadley Wickham's book is a great place to read up more on using
\texttt{dplyr}.
\end{quote}

We already saw the \texttt{dplyr} package in action in chapter
\ref{dataframes}, but now we go further. With \texttt{dplyr} you can do
the following operations on \texttt{data.frame}s and \texttt{tibble}s:

\begin{itemize}
\tightlist
\item
  Choose observations based on a certain value: \texttt{filter()}
\item
  Reorder rows: \texttt{arrange()}
\item
  Select variables by name: \texttt{select()}
\item
  Create new variables out of existing ones: \texttt{mutate()}
\item
  Summarise variables: \texttt{summarise()}
\end{itemize}

All of those verbs can be used with \texttt{group\_by()}, where we apply
the respective operation on a \emph{group} of the dataframe/tibble. For
example, on our \texttt{tot\_pop} tibble we will now

\begin{itemize}
\tightlist
\item
  filter
\item
  mutate
\item
  and plot the resulting values
\end{itemize}

Let's get a plot of the populations of France, the UK and Italy over
time, in terms of millions of people. We will make use of the
\texttt{piping} syntax of \texttt{dplyr} as already mentioned in section
\ref{dataframes}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)  }\CommentTok{# for %>%, filter, mutate, ...}
\CommentTok{# 1. take the data.frame `tot_pop`}
\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 2. pipe it into the filter function}
\StringTok{  }\CommentTok{# filter on Country being one of "France","United Kingdom" or "Italy"}
\StringTok{  }\KeywordTok{filter}\NormalTok{(Country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"France"}\NormalTok{,}\StringTok{"United Kingdom"}\NormalTok{,}\StringTok{"Italy"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 3. pipe the result into the mutate function}
\StringTok{  }\CommentTok{# create a new column called millions}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{millions =}\NormalTok{ counts }\OperatorTok{/}\StringTok{ }\FloatTok{1e6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 4. pipe the result into ggplot to make a plot}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{year,}\DataTypeTok{y=}\NormalTok{millions,}\DataTypeTok{color=}\NormalTok{Country,}\DataTypeTok{group=}\NormalTok{Country)) }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{size=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/gather-plot-1.pdf}

\subsubsection*{\texorpdfstring{Arrange a
\texttt{tibble}}{Arrange a tibble}}\label{arrange-a-tibble}
\addcontentsline{toc}{subsubsection}{Arrange a \texttt{tibble}}

\begin{itemize}
\tightlist
\item
  What are the top/bottom 5 most populated areas?
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{top5 =}\StringTok{ }\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(counts)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# arrange in descending order of col `counts`}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\DecValTok{5}\NormalTok{)}

\NormalTok{bottom5 =}\StringTok{ }\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(counts)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\NormalTok{)}
\CommentTok{# let's see top 5}
\NormalTok{top5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 3
##   Country                                                   year    counts
##   <chr>                                                     <chr>    <int>
## 1 European Economic Area (EU28  - current composition, plu~ 2017    5.17e8
## 2 European Economic Area (EU28  - current composition, plu~ 2016    5.16e8
## 3 European Economic Area (EU28  - current composition, plu~ 2015    5.14e8
## 4 European Economic Area (EU27 -  before the accession of ~ 2017    5.13e8
## 5 European Economic Area (EU28  - current composition, plu~ 2014    5.12e8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# and bottom 5}
\NormalTok{bottom5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 3
##   Country    year  counts
##   <chr>      <chr>  <int>
## 1 San Marino 2015   32789
## 2 San Marino 2014   32520
## 3 San Marino 2008   32054
## 4 San Marino 2011   31863
## 5 San Marino 2009   31269
\end{verbatim}

Now this is not exactly what we wanted. It's always the same country in
both top and bottom, because there are multiple years per country. Let's
compute average population over the last 5 years and rank according to
that:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{topbottom =}\StringTok{ }\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Country) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{>}\StringTok{ }\DecValTok{2012}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{mean_count =} \KeywordTok{mean}\NormalTok{(counts)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(mean_count))}

\NormalTok{top5 =}\StringTok{ }\NormalTok{topbottom }\OperatorTok{%>%}\StringTok{ }\KeywordTok{top_n}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\NormalTok{bottom5 =}\StringTok{ }\NormalTok{topbottom }\OperatorTok{%>%}\StringTok{ }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\NormalTok{)}
\NormalTok{top5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   Country                                                       mean_count
##   <chr>                                                              <dbl>
## 1 European Economic Area (EU28  - current composition, plus IS~ 514029320 
## 2 European Economic Area (EU27 -  before the accession of Croa~ 509813491.
## 3 European Union (current composition)                          508502858.
## 4 European Union (before the accession of Croatia)              504287028.
## 5 European Union (without United Kingdom)                       443638309.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bottom5}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   Country       mean_count
##   <chr>              <dbl>
## 1 Luxembourg       563319.
## 2 Malta            440467.
## 3 Iceland          329501.
## 4 Liechtenstein     37353 
## 5 San Marino        33014.
\end{verbatim}

That's better!

\subsubsection*{\texorpdfstring{Look for \texttt{NA}s in a
\texttt{tibble}}{Look for NAs in a tibble}}\label{look-for-nas-in-a-tibble}
\addcontentsline{toc}{subsubsection}{Look for \texttt{NA}s in a
\texttt{tibble}}

Sometimes data is \emph{missing}, and \texttt{R} represents it with the
special value \texttt{NA} (not available). It is good to know where in
our dataset we are going to encounter any missing values, so the task
here is: let's produce a table that has three columns:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the names of countries with missing data
\item
  how many years of data are missing for each of those
\item
  and the actual years that are missing
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{missings =}\StringTok{ }\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(counts)) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# is.na(x) returns TRUE if x is NA}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(Country) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{n_missing =} \KeywordTok{n}\NormalTok{(),}\DataTypeTok{years =} \KeywordTok{paste}\NormalTok{(year,}\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{))}
\NormalTok{knitr}\OperatorTok{:::}\KeywordTok{kable}\NormalTok{(missings)  }\CommentTok{# knitr:::kable makes a nice table}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{l|r|l}
\hline
Country & n\_missing & years\\
\hline
Albania & 2 & 2010, 2012\\
\hline
Andorra & 2 & 2014, 2015\\
\hline
Armenia & 1 & 2014\\
\hline
France (metropolitan) & 4 & 2014, 2015, 2016, 2017\\
\hline
Georgia & 1 & 2013\\
\hline
Monaco & 7 & 2008, 2009, 2010, 2011, 2012, 2013, 2014\\
\hline
Russia & 4 & 2013, 2015, 2016, 2017\\
\hline
San Marino & 1 & 2010\\
\hline
\end{tabular}

\subsubsection*{Males and Females}\label{males-and-females}
\addcontentsline{toc}{subsubsection}{Males and Females}

Let's look at the numbers by male and female population. They are in the
same xls file, but at different cell ranges. Also, I just realised that
the special character \texttt{:} indicates \emph{missing} data. We can
feed that to \texttt{read\_excel} and that will spare us the need to
convert data types afterwards. Let's see:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females_raw =}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}
                \DataTypeTok{path =} \KeywordTok{system.file}\NormalTok{(}\DataTypeTok{package=}\StringTok{"ScPoEconometrics"}\NormalTok{,}
                                    \StringTok{"datasets"}\NormalTok{,}\StringTok{"demo_gind.xls"}\NormalTok{), }
                \DataTypeTok{sheet=}\StringTok{"Data"}\NormalTok{, }\CommentTok{# which sheet}
                \DataTypeTok{range=}\StringTok{"A141:K200"}\NormalTok{,  }\CommentTok{# which excel cell range to read}
                \DataTypeTok{na=}\StringTok{":"}\NormalTok{ )   }\CommentTok{# missing data indicator}
\KeywordTok{names}\NormalTok{(females_raw)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "Country"}   \CommentTok{# lets rename the first column}
\NormalTok{females_raw}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 59 x 11
##    Country `2008` `2009` `2010` `2011` `2012` `2013` `2014` `2015` `2016`
##    <chr>    <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>  <dbl>
##  1 Europe~ 2.56e8 2.57e8 2.58e8 2.58e8 2.58e8 2.59e8 2.60e8 2.60e8 2.61e8
##  2 Europe~ 2.25e8 2.26e8 2.26e8 2.26e8 2.26e8 2.26e8 2.27e8 2.27e8 2.28e8
##  3 Europe~ 2.54e8 2.55e8 2.55e8 2.56e8 2.56e8 2.57e8 2.57e8 2.58e8 2.59e8
##  4 Euro a~ 1.71e8 1.71e8 1.72e8 1.72e8 1.72e8 1.72e8 1.73e8 1.73e8 1.74e8
##  5 Euro a~ 1.69e8 1.70e8 1.70e8 1.70e8 1.70e8 1.71e8 1.71e8 1.72e8 1.72e8
##  6 Belgium 5.44e6 5.48e6 5.53e6 5.60e6 5.64e6 5.67e6 5.69e6 5.71e6 5.74e6
##  7 Bulgar~ 3.86e6 3.83e6 3.81e6 3.78e6 3.76e6 3.74e6 3.72e6 3.70e6 3.68e6
##  8 Czech ~ 5.28e6 5.31e6 5.33e6 5.34e6 5.35e6 5.35e6 5.35e6 5.36e6 5.37e6
##  9 Denmark 2.76e6 2.78e6 2.79e6 2.80e6 2.81e6 2.82e6 2.83e6 2.85e6 2.87e6
## 10 German~ 4.19e7 4.18e7 4.17e7 4.11e7 4.11e7 4.11e7 4.12e7 4.14e7 4.17e7
## # ... with 49 more rows, and 1 more variable: `2017` <dbl>
\end{verbatim}

You can see that \texttt{R} now correctly read the numbers as such,
after we told it that the \texttt{:} character has the special
\emph{missing} meaning: before, it \emph{coerced} the entire
\texttt{2008} column (for example) to be of type \texttt{chr} after it
hit the first \texttt{:}. We had to manually convert the column back to
\texttt{numeric}, in the process automatically coercing the \texttt{:}s
into \texttt{NA}. Now we addressed that issue directly. Let's also get
the male data in the same way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{males_raw =}\StringTok{ }\KeywordTok{read_excel}\NormalTok{(}
                \DataTypeTok{path =} \KeywordTok{system.file}\NormalTok{(}\DataTypeTok{package=}\StringTok{"ScPoEconometrics"}\NormalTok{,}
                                    \StringTok{"datasets"}\NormalTok{,}\StringTok{"demo_gind.xls"}\NormalTok{), }
                \DataTypeTok{sheet=}\StringTok{"Data"}\NormalTok{, }\CommentTok{# which sheet}
                \DataTypeTok{range=}\StringTok{"A75:K134"}\NormalTok{,  }\CommentTok{# which excel cell range to read}
                \DataTypeTok{na=}\StringTok{":"}\NormalTok{ )   }\CommentTok{# missing data indicator}
\KeywordTok{names}\NormalTok{(males_raw)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "Country"}   \CommentTok{# lets rename the first column}
\end{Highlighting}
\end{Shaded}

Next step was to \texttt{tidy} up this data, just as before:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females =}\StringTok{ }\KeywordTok{gather}\NormalTok{(females_raw, }\KeywordTok{paste}\NormalTok{(}\DecValTok{2008}\OperatorTok{:}\DecValTok{2017}\NormalTok{),}\DataTypeTok{key=}\StringTok{"year"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"counts"}\NormalTok{)}
\NormalTok{males =}\StringTok{ }\KeywordTok{gather}\NormalTok{(males_raw, }\KeywordTok{paste}\NormalTok{(}\DecValTok{2008}\OperatorTok{:}\DecValTok{2017}\NormalTok{),}\DataTypeTok{key=}\StringTok{"year"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"counts"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's try to tweak our above plot to show the same data in two separate
panels: one for males and one for females. This is easiest to do with
\texttt{ggplot} if we have all the data in one single
\texttt{data.frame} (or \texttt{tibble}), and marked with a \emph{group
identifier}. Let's first add this to both datasets, and then let's just
combine both into one:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{females}\OperatorTok{$}\NormalTok{sex =}\StringTok{ "female"}
\NormalTok{males}\OperatorTok{$}\NormalTok{sex =}\StringTok{ "male"}
\NormalTok{sexes =}\StringTok{ }\KeywordTok{rbind}\NormalTok{(males,females)   }\CommentTok{# "row bind" 2 data.frames}
\NormalTok{sexes}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1,180 x 4
##    Country                                          year     counts sex  
##    <chr>                                            <chr>     <dbl> <chr>
##  1 European Union (current composition)             2008  243990548 male 
##  2 European Union (without United Kingdom)          2008  213826199 male 
##  3 European Union (before the accession of Croatia) 2008  241913560 male 
##  4 Euro area (19 countries)                         2008  162516883 male 
##  5 Euro area (18 countries)                         2008  161029464 male 
##  6 Belgium                                          2008    5224309 male 
##  7 Bulgaria                                         2008    3660367 male 
##  8 Czech Republic                                   2008    5065117 male 
##  9 Denmark                                          2008    2712666 male 
## 10 Germany (until 1990 former territory of the FRG) 2008   40274292 male 
## # ... with 1,170 more rows
\end{verbatim}

Now that we have all the data nice and \texttt{tidy} in a
\texttt{data.frame}, this is a very small change to our previous
plotting code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sexes }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(Country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"France"}\NormalTok{,}\StringTok{"United Kingdom"}\NormalTok{,}\StringTok{"Italy"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{millions =}\NormalTok{ counts }\OperatorTok{/}\StringTok{ }\FloatTok{1e6}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\KeywordTok{as.Date}\NormalTok{(year,}\DataTypeTok{format=}\StringTok{"%Y"}\NormalTok{),  }\CommentTok{# convert to `Date`}
                       \DataTypeTok{y=}\NormalTok{millions,}\DataTypeTok{colour=}\NormalTok{Country,}\DataTypeTok{group=}\NormalTok{Country)) }\OperatorTok{+}\StringTok{ }
\StringTok{      }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_date}\NormalTok{(}\DataTypeTok{name =} \StringTok{"year"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\CommentTok{# rename x axis}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{sex)   }\CommentTok{# make two panels, splitting by groups `sex`}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/psexes-1.pdf}

\subsubsection*{Always Compare to Germany
:-)}\label{always-compare-to-germany--}
\addcontentsline{toc}{subsubsection}{Always Compare to Germany :-)}

How do our three countries compare with respect to the biggest country
in the EU in terms of population? What \emph{fraction} of Germany does
the French population make in any given year, for example?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# remember that the pipe operator %>% takes the }
\CommentTok{# result of the previous operation and passes it}
\CommentTok{# as the *first* argument to the next function call}
\NormalTok{merge_GER <-}\StringTok{ }\NormalTok{tot_pop }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 1. subset to countries of interest}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    Country }\OperatorTok{%in%}\StringTok{ }
\StringTok{      }\KeywordTok{c}\NormalTok{(}\StringTok{"France"}\NormalTok{,}
        \StringTok{"United Kingdom"}\NormalTok{,}
        \StringTok{"Italy"}\NormalTok{)}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 2. group data by year}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 3. add GER's count as new column *by year*}
\StringTok{  }\KeywordTok{left_join}\NormalTok{(}
    \CommentTok{# Germany only}
    \KeywordTok{filter}\NormalTok{(tot_pop,}
\NormalTok{           Country }\OperatorTok{%in%}\StringTok{ "Germany including former GDR"}\NormalTok{),}
    \CommentTok{# join back in `by year`}
    \DataTypeTok{by=}\StringTok{"year"}\NormalTok{)}
\NormalTok{merge_GER}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 30 x 5
## # Groups:   year [?]
##    Country.x      year  counts.x Country.y                    counts.y
##    <chr>          <chr>    <int> <chr>                           <int>
##  1 France         2008  64007193 Germany including former GDR 82217837
##  2 Italy          2008  58652875 Germany including former GDR 82217837
##  3 United Kingdom 2008  61571647 Germany including former GDR 82217837
##  4 France         2009  64350226 Germany including former GDR 82002356
##  5 Italy          2009  59000586 Germany including former GDR 82002356
##  6 United Kingdom 2009  62042343 Germany including former GDR 82002356
##  7 France         2010  64658856 Germany including former GDR 81802257
##  8 Italy          2010  59190143 Germany including former GDR 81802257
##  9 United Kingdom 2010  62510197 Germany including former GDR 81802257
## 10 France         2011  64978721 Germany including former GDR 80222065
## # ... with 20 more rows
\end{verbatim}

Here you see that the merge (or join) operation labelled \texttt{col.x}
and \texttt{col.y} if both datasets contained a column called
\texttt{col}. Now let's continue to compute what proportion of german
population each country amounts to:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(merge_GER)[}\DecValTok{1}\NormalTok{] <-}\StringTok{ "Country"}
\NormalTok{merge_GER }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prop_GER =} \DecValTok{100} \OperatorTok{*}\StringTok{ }\NormalTok{counts.x }\OperatorTok{/}\StringTok{ }\NormalTok{counts.y) }\OperatorTok{%>%}
\StringTok{  }\CommentTok{# 5. plot}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} 
           \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year,}
               \DataTypeTok{y =}\NormalTok{ prop_GER,}
               \DataTypeTok{color =}\NormalTok{ Country,}
               \DataTypeTok{group =}\NormalTok{ Country)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\DataTypeTok{size=}\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\StringTok{"percent of German population"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()  }\CommentTok{# new theme for a change?}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-100-1.pdf}

\chapter{Linear Regression}\label{linreg}

\section{Data on Cars}\label{data-on-cars}

We will look at the built-in \texttt{cars} dataset. Let's get a view of
this by just typing \texttt{View(cars)} in Rstudio. You can see
something like this:

\begin{verbatim}
##   speed dist
## 1     4    2
## 2     4   10
## 3     7    4
## 4     7   22
## 5     8   16
## 6     9   10
\end{verbatim}

We have a \texttt{data.frame} with two columns: \texttt{speed} and
\texttt{dist}. Type \texttt{help(cars)} to find out more about the
dataset. There you could read that

\begin{quote}
The data give the speed of cars (mph) and the distances taken to stop
(ft).
\end{quote}

It's good practice to know the extent of a dataset. You could just type

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(cars)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 50  2
\end{verbatim}

to find out that we have 50 rows and 2 columns. A central question that
we want to ask now is the following:

\subsection{\texorpdfstring{How are \texttt{speed} and \texttt{dist}
related?}{How are speed and dist related?}}\label{how-are-speed-and-dist-related}

The simplest way to start is to plot the data. Remembering that we view
each row of a data.frame as an observation, we could just label one axis
of a graph \texttt{speed}, and the other one \texttt{dist}, and go
through our table above row by row. We just have to read off the x/y
coordinates and mark them in the graph. In \texttt{R}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(dist }\OperatorTok{~}\StringTok{ }\NormalTok{speed, }\DataTypeTok{data =}\NormalTok{ cars,}
     \DataTypeTok{xlab =} \StringTok{"Speed (in Miles Per Hour)"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Stopping Distance (in Feet)"}\NormalTok{,}
     \DataTypeTok{main =} \StringTok{"Stopping Distance vs Speed"}\NormalTok{,}
     \DataTypeTok{pch  =} \DecValTok{20}\NormalTok{,}
     \DataTypeTok{cex  =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{col  =} \StringTok{"red"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-103-1.pdf}

Here, each dot represents one observation. In this case, one particular
measurement \texttt{speed} and \texttt{dist} for a car. Now, again:

\begin{note}
How are \texttt{speed} and \texttt{dist} related? How could one best
\emph{summarize} this relationship?
\end{note}

 One thing we could do, is draw a straight line through this
scatterplot, like so:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(dist }\OperatorTok{~}\StringTok{ }\NormalTok{speed, }\DataTypeTok{data =}\NormalTok{ cars,}
     \DataTypeTok{xlab =} \StringTok{"Speed (in Miles Per Hour)"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Stopping Distance (in Feet)"}\NormalTok{,}
     \DataTypeTok{main =} \StringTok{"Stopping Distance vs Speed"}\NormalTok{,}
     \DataTypeTok{pch  =} \DecValTok{20}\NormalTok{,}
     \DataTypeTok{cex  =} \DecValTok{2}\NormalTok{,}
     \DataTypeTok{col  =} \StringTok{"red"}\NormalTok{)}
\KeywordTok{abline}\NormalTok{(}\DataTypeTok{a =} \DecValTok{60}\NormalTok{,}\DataTypeTok{b =} \DecValTok{0}\NormalTok{,}\DataTypeTok{lw=}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-105-1.pdf}

Now that doesn't seem a particularly \emph{good} way to summarize the
relationship. Clearly, a \emph{better} line would be not be flat, but
have a \emph{slope}, i.e.~go upwards:

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-106-1.pdf}

That is slightly better. However, the line seems at too high a level -
the point at which it crosses the y-axis is called the \emph{intercept};
and it's too high. We just learned how to represent a \emph{line},
i.e.~with two numbers called \emph{intercept} and \emph{slope}. So how
to choose the \textbf{best} line?

\subsection{Choosing the Best Line}\label{choosing-the-best-line}

Suppose we have the following set of 9 observations on \texttt{x} and
\texttt{y}, and we put the \emph{best} straight line into it, that we
can think of. It looks like this:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/line-arrows-1} 

}

\caption{The best line and its errors}\label{fig:line-arrows}
\end{figure}

The red arrows indicate the \textbf{distance} of the line to each point
and we call them \emph{errors} or \emph{residuals}, often written with
the symbol \(\varepsilon\). An upward pointing arrow indicates a
positive value of a particular \(\varepsilon_i\), and vice versa for
downward pointing arrows. The name \emph{residual} comes from the way we
write an equation for this relationship between two particular values
\((y_i,x_i)\) belonging to observation \(i\):

\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \label{eq:abline}
\]

Here \(\beta_0\) is the intercept, and \(\beta_1\) is the slope of our
line, and \(\varepsilon_i\) is the value of the arrow (i.e.~a positive
or negative number) indicating the distance between the actual \(y_i\)
and what is predicted by our line. In other words, \(\varepsilon_i\) is
what is left to be explained on top of the line
\(\beta_0 + \beta_1 x_i\), hence, it's a residual to explain \(y_i\).
Now, back to our claim that this is the \emph{best} line. What exactly
characterizes the best line?

\begin{warning}
The best line minimizes the sum of \textbf{squared residuals}, i.e.~it
minimizes the SSR:
\[ \varepsilon_1^2 + \dots + \varepsilon_N^2 = \sum_{i=1}^N \varepsilon_i^2 \equiv \text{SSR}\]
\end{warning}

 Wait a moment, why \emph{squared} residuals? This is easy to
understand: suppose that instead, we wanted to just make the \emph{sum}
of the arrows in figure \ref{fig:line-arrows} as small as possible (that
is, no squares). Choosing our line to make this number small would not
give a particularly good representation of the data -- given that errors
of opposite sign and equal magnitude offset, we could have very long
arrows (but of opposite signs), and a poor resulting line. Squaring each
error avoids this (because now negative errors get positive values!) We
illustrate this in figure \ref{fig:line-squares}. This is the same data
as in figure \ref{fig:line-arrows}, but instead of arrows of length
\(\varepsilon_i\) for each observation \(i\), now we draw a square with
side \(\varepsilon_i\), i.e.~an area of \(\varepsilon_i^2\). You will
see in the practical sessions that choosing a different line to this one
will increase the sum of squares.

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/line-squares-1} 

}

\caption{The best line and its SQUARED errors}\label{fig:line-squares}
\end{figure}

\subsection{Ordinary Least Squares (OLS)
Coefficients}\label{ordinary-least-squares-ols-coefficients}

The method to estimate \(\beta_0\) and \(\beta_1\) we illustrated above
is called \emph{Ordinary Least Squares}, or OLS. There is a connection
between the estimate for \(\beta_1\) - denoted \(\hat{\beta}_1\) - in
equation \eqref{eq:abline} and the \emph{covariance} of \(y\) and \(x\) -
remember how we defined this in section \ref{summarize-two}. In the
simple case shown in equation \eqref{eq:abline}, the relationship is

\[
\hat{\beta}_1 = \frac{cov(x,y)}{var(x)}.  \label{eq:beta1hat}
\] i.e.~the estimate of the slope coefficient is the covariance between
\(x\) and \(y\) divided by the variance of \(x\). Similarly, the
estimate for the intercept is given by

\[
\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}.  \label{eq:beta0hat}
\]

where \(\bar{z}\) denotes the sample mean of variable \(z\).

\subsection{Correlation, Covariance and
Linearity}\label{correlation-covariance-and-linearity}

It is important to keep in mind that Correlation and Covariance relate
to a \emph{linear} relationship between \texttt{x} and \texttt{y}. Given
how the regression line is estimated by OLS (see just above), you can
see that the regression line inherits this property from the Covariance.
A famous exercise by Francis Anscombe (1973) illustrates this by
constructing 4 different datasets which all have identical
\textbf{linear} statistics: mean, variance, correlation and regression
line \emph{are identical}. However, the usefulness of the statistics to
describe the relationship in the data is not clear.

\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-110-1.pdf}

The important lesson from this example is the following:

\begin{warning}
Always \textbf{visually inspect} your data, and don't rely exclusively
on summary statistics like \emph{mean, variance, correlation and
regression line}. All of those assume a \textbf{linear} relationship
between the variables in your data.
\end{warning}

\subsection{Non-Linear Relationships in
Data}\label{non-linear-relationships-in-data}

Suppose our data now looks like this:

\includegraphics{ScPoEconometrics_files/figure-latex/non-line-cars-1.pdf}

Putting our previous \emph{best line} defined in equation
\eqref{eq:abline} as \(y = \beta_0 + \beta_1 x + u\), we get something
like this:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/non-line-cars-ols-1} 

}

\caption{Best line with non-linear data?}\label{fig:non-line-cars-ols}
\end{figure}

Somehow when looking at \ref{fig:non-line-cars-ols} one is not totally
convinced that the straight line is a good summary of this relationship.
For values \(x\in[50,120]\) the line seems to low, then again too high,
and it completely misses the right boundary. It's easy to address this
shortcoming by including \emph{higher order terms} of an explanatory
variable. We would modify \eqref{eq:abline} to read now

\[
y_i = \beta_0 + \beta_1 x_i + \beta_2 x_i^2 + \varepsilon_i \label{eq:abline2}
\]

This is a special case of \emph{multiple regression}, which we will talk
about in chapter \ref{multiple-reg}. You can see that there are
\emph{multiple} slope coefficients. For now, let's just see how this
performs:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/non-line-cars-ols2-1} 

}

\caption{Better line with non-linear data!}\label{fig:non-line-cars-ols2}
\end{figure}

\section{DGP and Models}\label{dgp-and-models}

When we talk about a \textbf{model} in econometrics, we are making
assumptions about how \(y\) and \(x\) are related in the data. For
example, we have repeatedly seen the following equation,

\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i 
\]

which is a particular kind of model. What \emph{generated} our data, on
the other hand, is an unknown mechanism that we want to investigate:
it's the \textbf{data generating process} (GDP), and our model is our
assumption about how we think the GDP could look like. A natural
question that comes to mind here, is \emph{how to discriminate between
models}, or in other words: which model to choose?

\subsection{\texorpdfstring{Assessing the \emph{Goodness of
Fit}}{Assessing the Goodness of Fit}}\label{assessing-the-goodness-of-fit}

In our simple setup, there exists a convenient measure for how good a
particular statistical model fits the data. It is called \(R^2\)
(\emph{R squared}), also called the \emph{coefficient of determination}.
It is a statistic that makes use of a \emph{benchmark} model, against
which to compare any given model we may have in mind. Suppose we posit
our standard representation of the best line:

\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \label{eq:ssr-mod} 
\]

and let us write down the benchmark model as follows:

\[
y_i = \beta_0 + \varepsilon_i \label{eq:ssr-bench}
\]

As you can see, the benchmark model in \eqref{eq:ssr-bench} is a model
with an intercept only. You will see in one of our \texttt{apps} that
this delivers an estimate of the mean of \(y\). It is a benchmark
because it does not include \emph{any} explanatory variables, so we can
compare against this other models which do in fact contain some \(x\)'s.
Back to our \(R^2\) statistic: there are several equivalent definitions,
and for our present case we will use the following.

\begin{tip}
The \textbf{coefficient of determination} (\emph{R squared}) is defined
by \[R^2 = 1 - \frac{\text{SSR our model}}{\text{SSR benchmark}}.\] In
the simple linear model, we have that \(R^2 \in [0,1]\), where
\(R^2 = 1\) would indicate that our model is a \textbf{very good} fit to
the data, and vice versa for \(R^2 = 0\). You can interpret the value of
\(R^2\) as the fraction of variation in outcome \(y\) that is accounted
for by explanatory variable \(x\).
\end{tip}

 The workings of this statistic are illustrated in the following figure
\ref{fig:r-squared}. There, the left panel is our well-known depiction
of the sum of squared residuals (SSR) of our model
\(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\). The right panel shows
the SSR of \(y_i = \beta_0 + \varepsilon_i\). Ideally, each red square
would be small relative to its blue counterpart, indicating that our
model has a small residual at a given observation.

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/r-squared-1} 

}

\caption{Left panel: SSR from our model. Right panel: SSR from benchmark (mean only) model. $R^2$ compares the size of each red square to each blue square.}\label{fig:r-squared}
\end{figure}

\section{An Example: California Student Test Scores}\label{lm-example1}

Luckily for us, fitting a linear model to some data does not require us
to iteratively find the best intercept and slope manually, as you have
experienced in our \texttt{apps}. As it turns out, \texttt{R} can do
this much more precisely, and very fast!

Let's explore how to do this, using a real life dataset taken from the
\texttt{Ecdat} package which includes many economics-related dataset. In
this example, we will use the \texttt{Caschool}dataset which contains
the average test scores of 420 elementary schools in California along
with some additional information.

\subsection{Loading and exploring
Data}\label{loading-and-exploring-data}

We can explore which variables are included in the dataset using the
\texttt{names()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"Ecdat"}\NormalTok{) }\CommentTok{# Attach the Ecdat library}
\KeywordTok{names}\NormalTok{(Caschool) }\CommentTok{# Display the variables of the Caschool dataset}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "distcod"  "county"   "district" "grspan"   "enrltot"  "teachers"
##  [7] "calwpct"  "mealpct"  "computer" "testscr"  "compstu"  "expnstu" 
## [13] "str"      "avginc"   "elpct"    "readscr"  "mathscr"
\end{verbatim}

For each variable in the dataset, basic summary statistics can be
obtained by calling \texttt{summary()}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(Caschool[, }\KeywordTok{c}\NormalTok{(}\StringTok{"testscr"}\NormalTok{, }\StringTok{"str"}\NormalTok{, }\StringTok{"avginc"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     testscr           str            avginc      
##  Min.   :605.5   Min.   :14.00   Min.   : 5.335  
##  1st Qu.:640.0   1st Qu.:18.58   1st Qu.:10.639  
##  Median :654.5   Median :19.72   Median :13.728  
##  Mean   :654.2   Mean   :19.64   Mean   :15.317  
##  3rd Qu.:666.7   3rd Qu.:20.87   3rd Qu.:17.629  
##  Max.   :706.8   Max.   :25.80   Max.   :55.328
\end{verbatim}

\subsection{Fitting a linear model}\label{fitting-a-linear-model}

Suppose a policymaker is interested in the following linear model:

\[testscr_i = \beta_0 + \beta_1 \times str_i + \epsilon_i\] Where
\((testscr)_i\) is the \emph{average test score} for a given school
\(i\) and \((str)_i\) is the \emph{Student/Teacher Ratio} (i.e.~the
average number of students per teacher) in the same school \(i\). We can
think of \(\beta_0\) and \(\beta_1\) as the intercept and the slope of
the regression line.

The subscript \(i\) indexes all unique elementary schools
(\(i \in \{1, 2, 3, \dots 420\}\)) and \(\epsilon_i\) is the error, or
\emph{residual}, of the regression. (Remember that our procedure for
finding the line of best fit is to minimize the \emph{sum of squared
residuals} (SSR)).

\begin{center}\rule{0.5\linewidth}{\linethickness}\end{center}

At this point you should step back and take a second to think about what
you believe the relation between a school's test scores and
student/teacher ratio will be. Do you believe that, in general, a high
student/teacher ratio will be associated with higher-than-average test
scores for the school? Do you think that the number of students per
teacher will impact results in any way?

Let's find out! As always, we will start by plotting the data to inspect
it visually (don't worry if the syntax doesn't make much sense right
now, we will come back to it very soon):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ testscr }\OperatorTok{~}\StringTok{ }\NormalTok{str,}
     \DataTypeTok{data =}\NormalTok{ Caschool,}
     \DataTypeTok{xlab =} \StringTok{"Student/Teacher Ratio"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Average Test Score"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{21}\NormalTok{, }\DataTypeTok{col =} \StringTok{'blue'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/first-reg0-1} 

}

\caption{Student Teacher Ratio vs Test Scores}\label{fig:first-reg0}
\end{figure}

Can you spot a trend in the data? According to you, what would the line
of best fit look like? Would it be upward or downward slopping? Let's
ask \texttt{R}!

\section{\texorpdfstring{The \texttt{lm()}
function}{The lm() function}}\label{the-lm-function}

We will use the built-in \texttt{lm()} function to estimate the
coefficients \(\beta_0\) and \(\beta_1\) using the data at hand.
\texttt{lm} stands for \emph{linear model}, which is what our
representation in \eqref{eq:abline} amounts to. This function typically
only takes 2 arguments, \texttt{formula} and \texttt{data}:

\texttt{lm(formula,\ data)}

\begin{itemize}
\item
  \texttt{formula} is the description of our model which we want
  \texttt{R} to estimate for us. Its syntax is very simple:
  \texttt{Y\ \textasciitilde{}\ X} (more generally,
  \texttt{DependentVariable\ \textasciitilde{}\ Independent\ Variables}).
  You can think of the tilda operator \texttt{\textasciitilde{}} as the
  equal sign in your model equation. An intercept is included by default
  and so you do not have to ask for it in \texttt{formula}. For example,
  the simple model \(income = \beta_0 + \beta_1 \cdot age\) can be
  written as \texttt{income\ \textasciitilde{}\ age}. You can also ask
  \texttt{R} to estimate a multivariate regression such as
  \(income = \beta_0 + \beta_1 \cdot age + \beta_2 \cdot isWoman\) by
  simply separating all variables on the right-hand side of the equation
  with the \texttt{+} operator, like this :
  \texttt{income\ \textasciitilde{}\ age\ +\ isWoman}. A
  \texttt{formula} can sometimes be written between quotation marks:
  \texttt{"X\ \textasciitilde{}\ Y"}.
\item
  \texttt{data} is simply the \texttt{data.frame} containing the
  variables in the model.
\end{itemize}

In the context of our example, the function call is therefore:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ testscr }\OperatorTok{~}\StringTok{ }\NormalTok{str, }\DataTypeTok{data =}\NormalTok{ Caschool)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = testscr ~ str, data = Caschool)
## 
## Coefficients:
## (Intercept)          str  
##      698.93        -2.28
\end{verbatim}

As we can see, \texttt{R} returns its estimates for the Intercept and
Slope coefficients, \(\hat{\beta_0} =\) 698.93 and \(\hat{\beta_1} =\)
-2.28. The estimated relationship between a school's Student/Teacher
Ratio and its average test results is \textbf{negative}.

Running a linear regression in \texttt{R} is typically a two-steps
process. You first assign the output of the \texttt{lm()} call to an
object and \textbf{then} call a second function (for our purpose, mainly
\texttt{summary()}) on the resulting object. In practice, this looks
like this :

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# assign lm() output to some object `fit_california`}
\NormalTok{fit_california <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ testscr }\OperatorTok{~}\StringTok{ }\NormalTok{str, }\DataTypeTok{data =}\NormalTok{ Caschool)}

\CommentTok{# ask R for the regression summary}
\KeywordTok{summary}\NormalTok{(fit_california) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = testscr ~ str, data = Caschool)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -47.727 -14.251   0.483  12.822  48.540 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 698.9330     9.4675  73.825  < 2e-16 ***
## str          -2.2798     0.4798  -4.751 2.78e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 18.58 on 418 degrees of freedom
## Multiple R-squared:  0.05124,    Adjusted R-squared:  0.04897 
## F-statistic: 22.58 on 1 and 418 DF,  p-value: 2.783e-06
\end{verbatim}

Again, we recognize our intercept and slope estimates from before,
alongside some other numbers and indications. This output is called a
\emph{regression table}, and you will be able to decypher it by the end
of this course. You should be able to find an interpret the \(R^2\)
though: Are we explaining a lot of the variance in \texttt{testscr} with
this simple model, or not?

\subsection{Plotting the regression
line}\label{plotting-the-regression-line}

We can also use our \texttt{lm} fit to draw the regression line on top
of our initial scatterplot, using the following syntax:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ testscr }\OperatorTok{~}\StringTok{ }\NormalTok{str,}
     \DataTypeTok{data =}\NormalTok{ Caschool,}
     \DataTypeTok{xlab =} \StringTok{"Student/Teacher Ratio"}\NormalTok{,}
     \DataTypeTok{ylab =} \StringTok{"Average Test Score"}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{21}\NormalTok{, }\DataTypeTok{col =} \StringTok{'blue'}\NormalTok{)}\CommentTok{# same plot as before}
\KeywordTok{abline}\NormalTok{(fit_california, }\DataTypeTok{col =} \StringTok{'red'}\NormalTok{) }\CommentTok{# add regression line}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/plot-reg1-1} 

}

\caption{Test Scores with Regression Line}\label{fig:plot-reg1}
\end{figure}

As you probably expected, the best line for schools' Student/Teacher
Ratio and its average test results is downward sloping.

Just as a way of showcasing another way to make the above plot, here is
how you could use \texttt{ggplot}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\NormalTok{p <-}\StringTok{ }\KeywordTok{ggplot}\NormalTok{(}\DataTypeTok{mapping =} \KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ str, }\DataTypeTok{y =}\NormalTok{ testscr), }\DataTypeTok{data =}\NormalTok{ Caschool) }\CommentTok{# base plot}
\NormalTok{p <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_point}\NormalTok{() }\CommentTok{# add points}
\NormalTok{p <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{size=}\DecValTok{1}\NormalTok{, }\DataTypeTok{color=}\StringTok{"red"}\NormalTok{) }\CommentTok{# add regression line}
\NormalTok{p <-}\StringTok{ }\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Average Test Score"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{         }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{name =} \StringTok{"Student/Teacher Ratio"}\NormalTok{)}
\NormalTok{p }\OperatorTok{+}\StringTok{ }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}\StringTok{ }\KeywordTok{ggtitle}\NormalTok{(}\StringTok{"Testscores vs Student/Teacher Ratio"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-113-1} \end{center}

The shaded area around the red line shows the width of the 95\%
confidence interval around our estimate of the slope coefficient
\(\beta_1\). We will learn more about it in the next chapter.

\chapter{Standard Errors}\label{std-errors}

In the previous chapter we have seen how the OLS method can produce
estimates about intercept and slope coefficients from data. You have
seen this method at work in \texttt{R} by using the \texttt{lm} function
as well. It is now time to introduce the notion that given that
\(\hat{\beta}_0\) and \(\hat{\beta}_1\) are \emph{estimates} of some
unkown \emph{population parameters}, there is some degree of
\textbf{uncertainty} about their values. An other way to say this is
that we want some indication about the \emph{precision} of those
estimates.

\begin{note}
How \emph{confident} should we be about the estimated values
\(\hat{\beta}_0\) and \(\hat{\beta}_1\)?
\end{note}

 Let's remind ourselves of the example at the end of the previous
chapter, and that we introduced the term \emph{confidence interval},
shown here as the shaded area:

\begin{center}\includegraphics{ScPoEconometrics_files/figure-latex/unnamed-chunk-115-1} \end{center}

The shaded area shows us the region within which the \textbf{true} red
line will lie with 95\% probability. The fact that there is unknown true
line (i.e.~a \emph{true} slope coefficient \(\beta_1\)) that we wish to
uncover from a sample of data should remind you immediately of our first
tutorial. There we wanted to estimate the true population mean from a
sample of data, and we saw that as the sample size \(N\) increased, our
estimate got better and better - fundamentally this is the same idea
here.

\section{\texorpdfstring{What is
\emph{true}?}{What is true?}}\label{what-is-true}

We have a true data-generating process in mind. Let's bring back our
simple model \eqref{eq:abline} from the previous chapter:

\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \label{eq:abline-5}
\]

First, we \emph{assume} that this is the correct represenation of the
DGP, which looks like the above equation. With that assumption in place,
the values \(\beta_0\) and \(\beta_1\) are the \emph{true parameter
values} which generated the data. Notice, that both \(\beta_0\) and
\(\beta_1\) don't have a ``hat'', which is widely used to indicate an
estimate. Now, the fact that our data \((y_i,x_i)\) are a sample from a
larger population means that there will be \emph{sampling variation} in
our estimates \(\hat{\beta}_0\) and \(\hat{\beta}_1\) - exactly like in
the case of the sample mean estimating the population average as
mentioned above.

\section{Experiencing Standard
Errors}\label{experiencing-standard-errors}

We would like to make this point in a purely experiential way, i.e.~we
want you to experience what is going on. We invite you to spend some
time with the following apps, before going into the associated tutorial:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ScPoEconometrics)}
\KeywordTok{launchApp}\NormalTok{(}\StringTok{"standard_errors_simple"}\NormalTok{) }\CommentTok{# start with this}
\KeywordTok{launchApp}\NormalTok{(}\StringTok{"standard_errors_changeN"}\NormalTok{)  }\CommentTok{# then do that}
\KeywordTok{library}\NormalTok{(learnr)   }\CommentTok{# load the learner library}
\KeywordTok{run_tutorial}\NormalTok{(}\StringTok{"standared-errors"}\NormalTok{)   }\CommentTok{# WIP}
\end{Highlighting}
\end{Shaded}

\section{Standard Errors in Theory}\label{standard-errors-in-theory}

The precise formulae for the standard errors of regression coefficients
depend critically on exactly which model we talk about. In other words,
certain assumptions about the underlying DGP give rise to certain
standard error formulas. What we continue to call the \emph{simple
linear regression model} is in fact a list of 5 assumptions. It is time
to spell them out here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The model is linear in parameters. I.e. it looks like
  \eqref{eq:abline-5} above.
\item
  \((y_i,x_i)\) constitute a \emph{random} sample from the underlying
  population: the sample is \emph{representative}.
\item
  The mean of \(\varepsilon\) in \eqref{eq:abline-5} is zero, conditional
  on \(x\). This means that \(\varepsilon\) and \(x\) should not be
  correlated.
\item
\end{enumerate}

In our simple linear regression model the standard errors of the
estimates have the following form

\chapter{Multiple Regression}\label{multiple-reg}

We can extend the discussion from chapter \ref{linreg} to more than one
explanatory variable. For example, suppose that instead of only \(x\) we
now had \(x_1\) and \(x_2\) in order to explain \(y\). Everything we've
learned for the single variable case applies here as well. Instead of a
regression \emph{line}, we now get a regression \emph{plane}, i.e.~an
object representable in 3 dimenions: \((x_1,x_2,y)\). As an example,
suppose we wanted to explain how many \emph{miles per gallon}
(\texttt{mpg}) a car can travel as a function of its \emph{horse power}
(\texttt{hp}) and its \emph{weight} (\texttt{wt}). In other words we
want to estimate the equation

\[
mpg_i = \beta_0 + \beta_1 hp_i + \beta_2 wt_i + \varepsilon_i \label{eq:abline2d}
\] on our built-in dataset of cars (\texttt{mtcars}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{subset}\NormalTok{(mtcars, }\DataTypeTok{select =} \KeywordTok{c}\NormalTok{(mpg,hp,wt))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                      mpg  hp    wt
## Mazda RX4           21.0 110 2.620
## Mazda RX4 Wag       21.0 110 2.875
## Datsun 710          22.8  93 2.320
## Hornet 4 Drive      21.4 110 3.215
## Hornet Sportabout   18.7 175 3.440
## Valiant             18.1 105 3.460
## Duster 360          14.3 245 3.570
## Merc 240D           24.4  62 3.190
## Merc 230            22.8  95 3.150
## Merc 280            19.2 123 3.440
## Merc 280C           17.8 123 3.440
## Merc 450SE          16.4 180 4.070
## Merc 450SL          17.3 180 3.730
## Merc 450SLC         15.2 180 3.780
## Cadillac Fleetwood  10.4 205 5.250
## Lincoln Continental 10.4 215 5.424
## Chrysler Imperial   14.7 230 5.345
## Fiat 128            32.4  66 2.200
## Honda Civic         30.4  52 1.615
## Toyota Corolla      33.9  65 1.835
## Toyota Corona       21.5  97 2.465
## Dodge Challenger    15.5 150 3.520
## AMC Javelin         15.2 150 3.435
## Camaro Z28          13.3 245 3.840
## Pontiac Firebird    19.2 175 3.845
## Fiat X1-9           27.3  66 1.935
## Porsche 914-2       26.0  91 2.140
## Lotus Europa        30.4 113 1.513
## Ford Pantera L      15.8 264 3.170
## Ferrari Dino        19.7 175 2.770
## Maserati Bora       15.0 335 3.570
## Volvo 142E          21.4 109 2.780
\end{verbatim}

How do you think \texttt{hp} and \texttt{wt} will influence how many
miles per gallon of gasoline each of those cars can travel? In other
words, what do you expect the signs of \(\beta_1\) and \(\beta_2\) to
be?

With two explanatory variables as here, it is still possible to
visualize the regression plane, so let's start with this as an answer.
The OLS regression plane through this dataset looks like in figure
\ref{fig:plane3D-reg}:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/plane3D-reg-1} 

}

\caption{Multiple Regression - a plane in 3D. The red lines indicate the residual for each observation.}\label{fig:plane3D-reg}
\end{figure}

This visualization shows a couple of things: the data are shown with red
points, the grey plane is the one resulting from OLS estimation of
equation \eqref{eq:abline2d}, and the red lines show the size of the error
between estimated plane and observed data. You should realize that this
is exactly the same story as told in figure \ref{fig:line-arrows} - just
in three dimensions!

We can see from this plot that cars with more horse power and greater
weight, in general travel fewer miles per gallon of combustible. Hence,
we observe a plane that is downward sloping in both the \emph{weight}
and \emph{horse power} directions. Suppose now we wanted to know impact
of \texttt{hp} on \texttt{mpg} \emph{in isolation}, so as if we could
ask

\begin{tip}
Keeping the value of \(wt\) fixed for a certain car, what would be the
impact on \(mpg\) be if we were to increase \textbf{only} its \(hp\)?
Put differently, keeping \textbf{all else equal}, what's the impact of
changing \(hp\) on \(mpg\)?
\end{tip}

 We ask this kind of question all the time in econometrics. In figure
\ref{fig:plane3D-reg} you clearly see that both explanatory variables
have a negative impact on the outcome of interest: as one increases
either the horse power or the weight of a car, one finds that miles per
gallon decreases. What is kind of hard to read off is \emph{how
negative} an impact each variable has in isolation.

As a matter of fact, the kind of question asked here is so common that
it has got its own name: we'd say ``\emph{ceteris paribus}, what is the
impact of \texttt{hp} on \texttt{mpg}?''. \emph{ceteris paribus} is
latin and means \emph{the others equal}, i.e.~all other variables fixed.
In terms of our model in \eqref{eq:abline2d}, we want to know the
following quantity:

\[
\frac{\partial mpg_i}{\partial hp_i} = \beta_1 \label{eq:abline2d-deriv}
\] This means: \emph{keeping all other variables fixed, what is the
effect of \texttt{hp} on \texttt{mpg}?}. In calculus, the answer to this
is provided by the \emph{partial derivative} as shown in
\eqref{eq:abline2d-deriv}. We call the value of coefficient \(\beta_1\)
therefore also the \emph{partial effect} of \texttt{hp} on \texttt{mpg}.
In terms of our dataset, we use \texttt{R} to run the following
\textbf{multiple regression}:

\begin{verbatim}
## 
## Call:
## lm(formula = mpg ~ wt + hp, data = mtcars)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -3.941 -1.600 -0.182  1.050  5.854 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 37.22727    1.59879  23.285  < 2e-16 ***
## wt          -3.87783    0.63273  -6.129 1.12e-06 ***
## hp          -0.03177    0.00903  -3.519  0.00145 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.593 on 29 degrees of freedom
## Multiple R-squared:  0.8268, Adjusted R-squared:  0.8148 
## F-statistic: 69.21 on 2 and 29 DF,  p-value: 9.109e-12
\end{verbatim}

From this table you see that the coefficient on \texttt{wt} has value
-3.87783. You can interpret this as follows:

\begin{warning}
Holding all other variables fixed at their observed values - or
\emph{ceteris paribus} - a one unit increase in \(wt\) implies a
-3.87783 units change in \(mpg\). Similarly, one more \(hp\) horse power
implies a change in \(mpg\) of -0.03177 units, \emph{all else (i.e.
\(wt\)) equal}.
\end{warning}

\section{California Test Scores 2}\label{california-test-scores-2}

Let us extend our example of student test scores from chapter
\ref{linreg} by adding families' average income to our previous model:

\[
\text{testscr}_i = \beta_0 + \beta_1  \text{str}_i + \beta_2  \text{avginc}_i + \epsilon_i
\]

We can incoporate this new variable to our model by simply adding it to
our \texttt{formula}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(}\StringTok{"Ecdat"}\NormalTok{) }\CommentTok{# reload the data}
\NormalTok{fit_multivariate <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =} \StringTok{"testscr ~ str + avginc"}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ Caschool)}
\KeywordTok{summary}\NormalTok{(fit_multivariate)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = "testscr ~ str + avginc", data = Caschool)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -39.608  -9.052   0.707   9.259  31.898 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 638.72915    7.44908  85.746   <2e-16 ***
## str          -0.64874    0.35440  -1.831   0.0679 .  
## avginc        1.83911    0.09279  19.821   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 13.35 on 417 degrees of freedom
## Multiple R-squared:  0.5115, Adjusted R-squared:  0.5091 
## F-statistic: 218.3 on 2 and 417 DF,  p-value: < 2.2e-16
\end{verbatim}

Although it is quite cumbersome and not typical to visualize
multivariate regressions, we can still do this with 2 explanatory
variables using a \emph{regression (2-dimensional) plane}
{[}Interactive!{]}.

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/3D-Plotly-1} 

}

\caption{Californa Test Scores vs student/teach ratio and avg income.}\label{fig:3D-Plotly}
\end{figure}

While you explore this plot, ask yourself the following question: if you
could only choose one of the two explanatory variables in our model
(that is, either \(str\) or \(avginc\)) to predict the value of a given
school's average test score, which one would you choose? Why? Discuss
this with your classmates.

\section{Interactions}\label{mreg-interactions}

Interactions allow that the \emph{ceteris paribus} effect of a certain
regressor, \texttt{str} say, depends also on the value of yet another
regressor, \texttt{avginc} for example. To measure such an effect, we
would reformulate our model like this:

\[
\text{testscr}_i = \beta_0 + \beta_1  \text{str}_i + \beta_2  \text{avginc}_i + \beta_3 (\text{str}_i \times  \text{avginc}_i)+ \epsilon_i \label{eq:caschool-inter}
\]

The inclusion of the \emph{product} of \texttt{str} and \texttt{avginc}
amounts to having different slopes with respect to \texttt{str} for
different values of \texttt{avginc} (and vice versa). This is easy to
see if we take the partial derivative of \eqref{eq:caschool-inter} with
respect to \texttt{str}:

\[
\frac{\partial \text{testscr}_i}{\partial \text{str}_i} = \beta_1 + \beta_3 \text{avginc}_i \label{eq:caschool-inter-deriv}
\]

\begin{quote}
You should go back to equation \eqref{eq:abline2d-deriv} to remind
yourself of what a \emph{partial effect} was, and how exactly the
present \eqref{eq:caschool-inter-deriv} differs from what we saw there.
\end{quote}

Back in our \texttt{R} session, we can run the full interactions model
like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_inter =}\StringTok{ }\KeywordTok{lm}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ testscr }\OperatorTok{~}\StringTok{ }\NormalTok{str }\OperatorTok{+}\StringTok{ }\NormalTok{avginc }\OperatorTok{+}\StringTok{ }\NormalTok{str}\OperatorTok{*}\NormalTok{avginc, }\DataTypeTok{data =}\NormalTok{ Caschool)}
\CommentTok{# note that this would produce the same result:}
\CommentTok{# lm(formula = testscr ~ str*avginc, data = Caschool)}
\CommentTok{# R expands str*avginc for you in main effects + interactions}
\KeywordTok{summary}\NormalTok{(lm_inter)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = testscr ~ str + avginc + str * avginc, data = Caschool)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -41.346  -9.260   0.209   8.736  33.368 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 689.47473   14.40894  47.850  < 2e-16 ***
## str          -3.40957    0.75980  -4.487 9.34e-06 ***
## avginc       -1.62388    0.85214  -1.906   0.0574 .  
## str:avginc    0.18988    0.04646   4.087 5.24e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 13.1 on 416 degrees of freedom
## Multiple R-squared:  0.5303, Adjusted R-squared:  0.527 
## F-statistic: 156.6 on 3 and 416 DF,  p-value: < 2.2e-16
\end{verbatim}

We see here that the regression now estimates and additional coefficient
\(\beta_3\) for us. We observe also that the estimate of \(\beta_2\)
changes signs and becomes negative, while the interaction effect
\(\beta_3\) is positive. This means that an increase in \texttt{str}
reduces average student scores (more students per teacher make it harder
to teach effectively); that an increase in average district income in
isolation actually reduces scores; and that the interaction of both
increases scores (more students per teacher are actually a good thing
for student performance in richer areas).

Looking at our visualization may help understand this result better.
Figure \ref{fig:3D-Plotly-inter} shows a plane that is no longer
actually a \emph{plane}. It shows a curved surface. You can see that the
surface became more flexible in that we could kind of \emph{bend} it
more. Which model do you like better to explain this data? Discuss with
your neighbor and give some reasons for your choice (other than
``\ref{fig:3D-Plotly-inter} looks nicer'' ;-) ). In particular,
comparing both visualizations, can you explain why we observe this
strange inversion of coefficient signs?

\begin{figure}
\centering
\includegraphics{ScPoEconometrics_files/figure-latex/3D-Plotly-inter-1.pdf}
\caption{\label{fig:3D-Plotly-inter}Californa Test Scores vs student/teach
ratio and avg income plus interaction term}
\end{figure}

\chapter{Categorial Variables}\label{categorical-vars}

TODO: excluded category vs intercept?

Up until now, we have encountered only examples with \emph{continuous}
variables \(x\) and \(y\), that is, \(x,y \in \mathbb{R}\), so that a
typical observation could have been \((y_i,x_i) = (1.5,5.62)\). There
are many situations where it makes sense to think about the data in
terms of \emph{categories}, rather than continuous numbers. For example,
whether an observation \(i\) is \emph{male} or \emph{female}, whether a
pixel on a screen is \emph{black} or \emph{white}, and whether a good
was produced in \emph{France}, \emph{Germany}, \emph{Italy},
\emph{China} or \emph{Spain} are all categorical classifications of
data.

Probably the simplest type of categorical variable is the \emph{binary},
\emph{boolean}, or just \emph{dummy} variable. As the name suggests, it
can take on only two values, \texttt{0} and \texttt{1}, or \texttt{TRUE}
and \texttt{FALSE}. Even though this is an extremely parsimonious way of
encoding that, it is a very powerful tool that allows us to represent
that a certain observation \(i\) \textbf{is a member} of a certain
category \(j\). For example, we could have a variable called
\texttt{is.male} that is \texttt{TRUE} whenever \(i\) is male, and
\texttt{FALSE} otherwise. A common way to represent this is with the
so-called \emph{indicator function} \(\mathbf{1}[\text{condition}]\),

\begin{align*}
\text{is.male}_i &= \mathbf{1}[\text{sex}_i==\text{male}], \\
\end{align*}

which would just mean

\begin{align*}
\mathbf{1}[\text{sex}_i==\text{male}] &= \begin{cases}
                    1 & \text{if }i\text{ is male} \\
                    0 & \text{if }i\text{ is female}. \\
                 \end{cases}
\end{align*}

Notice the use of \texttt{x\ ==\ y} to represent the relationship
\emph{\texttt{x} is equal \texttt{y}}, which is (very!) different from
\texttt{x\ =\ y} meaning \emph{assign \texttt{y} to \texttt{x}}.

In terms of a regression formulation, this is our model when our
regressor is binary:

\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i,x_i\in\{0,1\} \label{eq:zero-one-reg}
\]

Let's run that regression here:

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ x, data = dta)
## 
## Coefficients:
## (Intercept)            x  
##       1.889        3.756
\end{verbatim}

We have seen in the \texttt{app} launched via

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{launchApp}\NormalTok{(}\StringTok{"reg_dummy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

that this regression simplifies to the straight line connecting the
mean, or the \emph{expected value} of \(y\) when \(x=0\), i.e.
\(E[y|x=0]\), to the mean when \(x=1\), i.e. \(E[y|x=1]\). It is useful
to remember that the \emph{unconditional mean} of \(y\), i.e. \(E[y]\),
is going to be the result of regressing \(y\) only on an intercept,
illustrated by the red line. The red line will always lie in between
both conditional means. Let's just refresh our memory by replicating the
graph from the \texttt{app} here in figure \ref{fig:x-zero-one}:

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/x-zero-one-1} 

}

\caption{regressing $y \in \mathbb{R}$ on $x \in \{0,1\}$. The red line is $E[y]$}\label{fig:x-zero-one}
\end{figure}

Now suppose for a moment that in fact

\[
x_i = \begin{cases}
          1 & \text{if }i\text{ is male} \\
            0 & \text{if }i\text{ is female}. \\
   \end{cases}
\] and that \(y_i\) is a measure of \(i\)'s annual labor income. The
dummy variable version of the above regression is just

\[
y_i = \beta_0 + \alpha \text{is.male}_i + \varepsilon_i \label{eq:dummy-reg}
\] where

\begin{align*}
\text{is.male}_i &= \mathbf{1}[x_i==1], \\
\end{align*}

and the resulting estimates of \(\beta_1\) and \(\alpha\) are in fact
the same. Here we see the estimates from \eqref{eq:dummy-reg}:

\begin{verbatim}
## 
## Call:
## lm(formula = y ~ is.male, data = dta)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.40227 -0.50683 -0.09763  0.66287  1.53463 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   1.8888     0.2617   7.217 1.03e-06 ***
## is.male1      3.7558     0.3902   9.626 1.60e-08 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.868 on 18 degrees of freedom
## Multiple R-squared:  0.8374, Adjusted R-squared:  0.8283 
## F-statistic: 92.67 on 1 and 18 DF,  p-value: 1.599e-08
\end{verbatim}

It is interesting to note that the estimate for \(\alpha = 3.7558\) (and
\(\beta_1 = 3.7558\)!) is the same as the difference in conditional
means:

\[E[y|x=1] - E[y|x=0]=3.7558.\]

\section{\texorpdfstring{Categorical Variables in \texttt{R}:
\texttt{factor}}{Categorical Variables in R: factor}}\label{categorical-variables-in-r-factor}

\texttt{R} has extensive support for categorical variables built-in. The
relevant data type representing a categorical variable is called
\texttt{factor}. We encountered them as basic data types in section
\ref{data-types} already, but it is worth repeating this here. We have
seen that a factor \emph{categorizes} a usually small number of numeric
values by \emph{labels}, as in this example which is similar to what I
used to create regressor \texttt{is.male} for the above regression:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{is.male =}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{,}\OtherTok{TRUE}\NormalTok{))}
\NormalTok{is.male}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE TRUE  TRUE  FALSE
## Levels: FALSE TRUE
\end{verbatim}

You can see the result is a vector object of type \texttt{factor} with 4
entries, whereby \texttt{0} is represented as \texttt{FALSE} and
\texttt{1} as \texttt{TRUE}. An other example could be if we wanted to
record a variable \emph{sex} instead, and we could do

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sex =}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"female"}\NormalTok{,}\StringTok{"male"}\NormalTok{))}
\NormalTok{sex}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] female male   male   female
## Levels: female male
\end{verbatim}

You can see that this is almost identical, just the \emph{labels} are
different.

\subsection{More Levels}\label{more-levels}

We can go \emph{binary} categorical variables such as \texttt{TRUE} vs
\texttt{FALSE}. For example, suppose that \(x\) measures educational
attainment, i.e.~it is now something like
\(x_i \in \{\text{high school,some college,BA,MSc}\}\). In \texttt{R}
parlance, \emph{high school, some college, BA, MSc} are the
\textbf{levels of factor \(x\)}. A straightforward extension of the
above would dictate to create one dummy variable for each category (or
level), like

\begin{align*}
\text{has.HS}_i &= \mathbf{1}[x_i==\text{high school}] \\
\text{has.someCol}_i &= \mathbf{1}[x_i==\text{some college}] \\
\text{has.BA}_i &= \mathbf{1}[x_i==\text{BA}] \\
\text{has.MSc}_i &= \mathbf{1}[x_i==\text{MSc}] 
\end{align*}

but you can see that this is cumbersome. There is a better solution for
us available:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{factor}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{),}\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"HS"}\NormalTok{,}\StringTok{"someCol"}\NormalTok{,}\StringTok{"BA"}\NormalTok{,}\StringTok{"MSc"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] HS      HS      someCol MSc     BA      MSc    
## Levels: HS someCol BA MSc
\end{verbatim}

Notice here that \texttt{R} will apply the labels in increasing order
the way you supplied it (i.e.~a numerical value \texttt{4} will
correspond to ``MSc'', no matter the ordering in \texttt{x}.)

\subsection{\texorpdfstring{\texttt{factor} and
\texttt{lm()}}{factor and lm()}}\label{factor-and-lm}

The above developed \texttt{factor} terminology fits neatly into
\texttt{R}'s linear model fitting framework. Let us illustrate the
simplest use by way of example.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(Ecdat)  }\CommentTok{# need to load this library}
\KeywordTok{data}\NormalTok{(}\StringTok{"Wages"}\NormalTok{)   }\CommentTok{# from Ecdat}
\KeywordTok{str}\NormalTok{(Wages)   }\CommentTok{# let's examine this dataset!}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 'data.frame':    4165 obs. of  12 variables:
##  $ exp    : int  3 4 5 6 7 8 9 30 31 32 ...
##  $ wks    : int  32 43 40 39 42 35 32 34 27 33 ...
##  $ bluecol: Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 2 2 2 ...
##  $ ind    : int  0 0 0 0 1 1 1 0 0 1 ...
##  $ south  : Factor w/ 2 levels "no","yes": 2 2 2 2 2 2 2 1 1 1 ...
##  $ smsa   : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ married: Factor w/ 2 levels "no","yes": 2 2 2 2 2 2 2 2 2 2 ...
##  $ sex    : Factor w/ 2 levels "female","male": 2 2 2 2 2 2 2 2 2 2 ...
##  $ union  : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 2 ...
##  $ ed     : int  9 9 9 9 9 9 9 11 11 11 ...
##  $ black  : Factor w/ 2 levels "no","yes": 1 1 1 1 1 1 1 1 1 1 ...
##  $ lwage  : num  5.56 5.72 6 6 6.06 ...
\end{verbatim}

Assume that this is a single cross section for wages of US workers. The
main outcome variable is \texttt{lwage} which stands for \emph{logarithm
of wage}. Let's initially say that a workers wage depends only on his
\emph{experience}, measured in the number of years he/she worked
full-time:

\[
\ln w_i = \beta_0 + \beta_1 exp_i + \varepsilon_i \label{eq:wage-exp}
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_w =}\StringTok{ }\KeywordTok{lm}\NormalTok{(lwage }\OperatorTok{~}\StringTok{ }\NormalTok{exp, }\DataTypeTok{data =}\NormalTok{ Wages)}
\KeywordTok{summary}\NormalTok{(lm_w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lwage ~ exp, data = Wages)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.30153 -0.29144  0.02307  0.27927  1.97171 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 6.5014318  0.0144657  449.44   <2e-16 ***
## exp         0.0088101  0.0006378   13.81   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4513 on 4163 degrees of freedom
## Multiple R-squared:  0.04383,    Adjusted R-squared:  0.0436 
## F-statistic: 190.8 on 1 and 4163 DF,  p-value: < 2.2e-16
\end{verbatim}

We see from this that an additional year of full-time work experience
will increase the mean of \(\ln w\) by 0.0088. Given the log
transformation on wages, we can just exponentiate that to get an
estimated effect on the (geometric!) mean of wages as
\(\exp(\hat{\beta}_1) = 1.0088491\). This means that hourly wages
increase by roughly \(100 * (\exp(\hat{\beta}_1)-1) = 0.88\) percent
with an additional year of experience. We can verify the positive
relationship in figure \ref{fig:wage-plot}.

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/wage-plot-1} 

}

\caption{log wage vs experience. Red line shows the regression.}\label{fig:wage-plot}
\end{figure}

Now let's investigate whether this relationship different for men and
women.

\[
\ln w_i = \beta_0 + \beta_1 exp_i + \beta_2 sex_i + \varepsilon_i \label{eq:wage-sex}
\]

We can do this easily by using the \texttt{update} function as follows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_sex =}\StringTok{ }\KeywordTok{update}\NormalTok{(lm_w, . }\OperatorTok{~}\StringTok{ }\NormalTok{. }\OperatorTok{+}\StringTok{ }\NormalTok{sex)  }\CommentTok{# update lm_w with same LHS, same RHS, but add sex to it}
\KeywordTok{summary}\NormalTok{(lm_sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lwage ~ exp + sex, data = Wages)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.87081 -0.26688  0.01733  0.26336  1.90325 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 6.1257661  0.0223319  274.31   <2e-16 ***
## exp         0.0076134  0.0006082   12.52   <2e-16 ***
## sexmale     0.4501101  0.0210974   21.34   <2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4286 on 4162 degrees of freedom
## Multiple R-squared:  0.1381, Adjusted R-squared:  0.1377 
## F-statistic: 333.4 on 2 and 4162 DF,  p-value: < 2.2e-16
\end{verbatim}

What's going on here? Remember from above that \texttt{sex} is a
\texttt{factor} with 2 levels \emph{female} and \emph{male}. We see in
the above output that \texttt{R} included a regressor called
\texttt{sexmale} \(=\mathbf{1}[sex_i=="male"]\). This is a combination
of the variable name \texttt{sex} and the level which was included in
the regression. In other words, \texttt{R} chooses a \emph{reference
category} (by default the first of all levels by order of appearance),
which is excluded - here this is \texttt{sex=="female"}. The
interpretation is that \(\beta_2\) measures the effect of being male
\emph{relative} to being female. \texttt{R} automatically creates a
dummy variable for each potential level, excluding the first category.
In particular, if \texttt{sex} had a third category
\texttt{dont\ want\ to\ say}, there would be an additional regressor
called \texttt{sexdontwanttosay}.

\begin{figure}

{\centering \includegraphics{ScPoEconometrics_files/figure-latex/wage-plot2-1} 

}

\caption{log wage vs experience with different intercepts by sex}\label{fig:wage-plot2}
\end{figure}

Figure \ref{fig:wage-plot2} illustrates this. You can see that both male
and female have the same upward sloping regression line. But you can
also see that there is a parallel downward shift from male to female
line. The estimate of \(\beta_2 = 0.45\) is the size of the downward
shift.

\section{Saturated Models: Main Effects and
Interactions}\label{saturated-models-main-effects-and-interactions}

You can see above that we \emph{restricted} male and female to have the
same slope with repect to years of experience. This may or may not be a
good assumption. Thankfully, the dummy variable regression machinery
allows for a quick solution to this - so-called \emph{interaction}
effects. As already introduced in chapter \ref{mreg-interactions},
interactions allow that the \emph{ceteris paribus} effect of a certain
regressor, \texttt{exp} say, depends also on the value of yet another
regressor, \texttt{sex} for example. Suppose then we would like to see
whether male and female not only have different intercepts, but also
different slopes with respect to \texttt{exp} in figure
\ref{fig:wage-plot2}. Therefore we formulate this version of our model:

\[
\ln w_i = \beta_0 + \beta_1 exp_i + \beta_2 sex_i + \beta_3 (sex_i \times exp_i) + \varepsilon_i \label{eq:wage-sex-inter}
\]

The inclusion of the \emph{product} of \texttt{exp} and \texttt{sex}
amounts to having different slopes for different categories in
\texttt{sex}. This is easy to see if we take the partial derivative of
\eqref{eq:wage-sex-inter} with respect to \texttt{sex}:

\[
\frac{\partial \ln w_i}{\partial sex_i} = \beta_2 + \beta_3 exp_i \label{eq:wage-sex-inter-deriv}
\]

Back in our \texttt{R} session, we can run the full interactions model
like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_inter =}\StringTok{ }\KeywordTok{lm}\NormalTok{(lwage }\OperatorTok{~}\StringTok{ }\NormalTok{exp}\OperatorTok{*}\NormalTok{sex, }\DataTypeTok{data =}\NormalTok{ Wages)}
\KeywordTok{summary}\NormalTok{(lm_inter)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lwage ~ exp * sex, data = Wages)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.82137 -0.26797  0.01781  0.26231  1.90757 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept) 6.169017   0.038165 161.643  < 2e-16 ***
## exp         0.005071   0.001918   2.644  0.00822 ** 
## sexmale     0.401116   0.040917   9.803  < 2e-16 ***
## exp:sexmale 0.002826   0.002022   1.397  0.16236    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4285 on 4161 degrees of freedom
## Multiple R-squared:  0.1385, Adjusted R-squared:  0.1379 
## F-statistic:   223 on 3 and 4161 DF,  p-value: < 2.2e-16
\end{verbatim}

You can see here that \texttt{R} automatically expands \texttt{exp*sex}
to include both \emph{main effects}, i.e. \texttt{exp} and \texttt{sex}
as single regressors as before, and their interaction, denoted by
\texttt{exp:sexmale}. It turns out that in this example, the estimate
for the interaction is not statistically significant, i.e.~we cannot
reject the null hypothesis that \(\beta_3 = 0\). (If, for some reason,
you wanted to include only the interaction, you could supply directly
\texttt{formula\ =\ lwage\ \textasciitilde{}\ exp:sex} to \texttt{lm},
although this would be a rather difficult to interpret model.)

We call a model like \eqref{eq:wage-sex-inter} a \emph{saturated model},
because it includes all main effects and possible interactions. What our
little exercise showed us was that with the sample of data at hand, we
cannot actually claim that there exists a differential slope for male
and female, so the model with main effects only may be more appropriate
here.

To finally illustrate the limits of interpretability when including
interactions, suppose we run the fully saturated model for \texttt{sex},
\texttt{smsa}, \texttt{union} and \texttt{bluecol}, including all main
and all interaction effects:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_full =}\StringTok{ }\KeywordTok{lm}\NormalTok{(lwage }\OperatorTok{~}\StringTok{ }\NormalTok{sex}\OperatorTok{*}\NormalTok{smsa}\OperatorTok{*}\NormalTok{union}\OperatorTok{*}\NormalTok{bluecol,}\DataTypeTok{data=}\NormalTok{Wages)}
\KeywordTok{summary}\NormalTok{(lm_full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lwage ~ sex * smsa * union * bluecol, data = Wages)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.95214 -0.23409 -0.01681  0.25317  1.90450 
## 
## Coefficients:
##                                     Estimate Std. Error t value Pr(>|t|)
## (Intercept)                          6.12378    0.06300  97.198  < 2e-16
## sexmale                              0.67057    0.06577  10.195  < 2e-16
## smsayes                              0.33424    0.06872   4.864 1.19e-06
## unionyes                             0.84284    0.16866   4.997 6.06e-07
## bluecolyes                          -0.34016    0.08423  -4.039 5.47e-05
## sexmale:smsayes                     -0.15917    0.07226  -2.203 0.027670
## sexmale:unionyes                    -0.92893    0.17816  -5.214 1.94e-07
## smsayes:unionyes                    -0.83927    0.17979  -4.668 3.14e-06
## sexmale:bluecolyes                  -0.15046    0.08820  -1.706 0.088100
## smsayes:bluecolyes                  -0.12471    0.09727  -1.282 0.199882
## unionyes:bluecolyes                 -0.31819    0.22924  -1.388 0.165208
## sexmale:smsayes:unionyes             0.72672    0.19060   3.813 0.000139
## sexmale:smsayes:bluecolyes           0.25860    0.10327   2.504 0.012318
## sexmale:unionyes:bluecolyes          0.71906    0.23772   3.025 0.002503
## smsayes:unionyes:bluecolyes          0.50057    0.24862   2.013 0.044137
## sexmale:smsayes:unionyes:bluecolyes -0.58330    0.25899  -2.252 0.024361
##                                        
## (Intercept)                         ***
## sexmale                             ***
## smsayes                             ***
## unionyes                            ***
## bluecolyes                          ***
## sexmale:smsayes                     *  
## sexmale:unionyes                    ***
## smsayes:unionyes                    ***
## sexmale:bluecolyes                  .  
## smsayes:bluecolyes                     
## unionyes:bluecolyes                    
## sexmale:smsayes:unionyes            ***
## sexmale:smsayes:bluecolyes          *  
## sexmale:unionyes:bluecolyes         ** 
## smsayes:unionyes:bluecolyes         *  
## sexmale:smsayes:unionyes:bluecolyes *  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3832 on 4149 degrees of freedom
## Multiple R-squared:  0.3129, Adjusted R-squared:  0.3105 
## F-statistic:   126 on 15 and 4149 DF,  p-value: < 2.2e-16
\end{verbatim}

The main effects remain clear to interpret: being a blue collar worker,
for example, reduces average wages by 34\% relative to white collar
workers. One-way interactions are still ok to interpret as well:
\texttt{sexmale:bluecolyes} indicates in addition to a wage premium over
females of 0.67, and a penalty of being blue collar of -0.34,
\textbf{male} blue collar workers suffer an additional wage loss of
-0.15. All of this is relative to the base category, which are female
white collar workers who don't live in an smsa and are not union
members. If we now add a third or even a fourth interaction, this
becomes much harder to interpret, and in fact we rarely see such
interactions in applied work.

\chapter{Quantile Regression}\label{quantreg}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  before you were modelling the mean. the average link
\item
  now what happens to \textbf{outliers}? how robust is the mean to that
\item
  what about the entire distribution of this?
\end{enumerate}

\chapter{Panel Data}\label{panel-data}

\section{fixed effects}\label{fixed-effects}

\section{DiD}\label{did}

\section{RDD}\label{rdd}

\section{Example}\label{example}

\begin{itemize}
\tightlist
\item
  scanner data on breakfast cereals, \((Q_{it},D_{it})\)
\item
  why does D vary with Q
\item
  pos relation ship
\item
  don't observe the group identity!
\item
  unobserved het alpha is correlated with Q
\item
  within group estimator
\item
  what if you don't have panel data?
\end{itemize}

\chapter{Instrumental Variables}\label{IV}

\begin{itemize}
\tightlist
\item
  Measurement error
\item
  Omitted Variable Bias
\item
  Reverse Causality / Simultaneity Bias
\end{itemize}

are all called \emph{endogeneity} problems.

\section{Simultaneity Bias}\label{simultaneity-bias}

\begin{itemize}
\tightlist
\item
  Detroit has a large police force
\item
  Detroit has a high crime rate
\item
  Omaha has a small police force
\item
  Omana has a small crime rate
\end{itemize}

Do large police forces \textbf{cause} high crime rates?

Absurd! Absurd? How could we use data to tell?

We have the problem that large police forces and high crime rates covary
positively in the data, and for obvious reasons: Cities want to protect
their citizens and therefore respond to increased crime with increased
police. Using mathematical symbols, we have the following \emph{system
of linear equations}, i.e.~two equations which are \textbf{jointly
determined}:

\begin{align*}
\text{crime}_{it} &= f(\text{police}_{it}) \\
\text{police}_{it}&= g(\text{crime}_{it} )
\end{align*}

We need a factor that is outside this circular system, affecting
\textbf{only} the size of the police force, but not the actual crime
rate. Such a factor is called an \emph{instrumental variable}.

\chapter{Logit and Probit}\label{logit-probit}

\chapter{Principal Component Analysis}\label{pca}

\chapter{Notes}\label{notes}

this creates a library for the used R packages.

In order to install that package, you need to do

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{require}\NormalTok{(devtools))\{}
  \KeywordTok{install.packages}\NormalTok{(}\StringTok{"devtools"}\NormalTok{)}
\NormalTok{\}}
\KeywordTok{library}\NormalTok{(devtools)}
\KeywordTok{install_github}\NormalTok{(}\StringTok{"floswald/ScPoEconometrics"}\NormalTok{)  }
\end{Highlighting}
\end{Shaded}

\section{Book usage}\label{book-usage}

You can label chapter and section titles using \texttt{\{\#label\}}
after them, e.g., we can reference Chapter \ref{intro}. If you do not
manually label them, there will be automatic labels anyway, e.g.,
Chapter \ref{linreg}.

Figures and tables with captions will be placed in \texttt{figure} and
\texttt{table} environments, respectively.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mar =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, .}\DecValTok{1}\NormalTok{, .}\DecValTok{1}\NormalTok{))}
\KeywordTok{plot}\NormalTok{(pressure, }\DataTypeTok{type =} \StringTok{'b'}\NormalTok{, }\DataTypeTok{pch =} \DecValTok{19}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{ScPoEconometrics_files/figure-latex/nice-fig-1} 

}

\caption{Here is a nice figure!}\label{fig:nice-fig}
\end{figure}

Reference a figure by its code chunk label with the \texttt{fig:}
prefix, e.g., see Figure \ref{fig:nice-fig}. Similarly, you can
reference tables generated from \texttt{knitr::kable()}, e.g., see Table
\ref{tab:nice-tab}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
  \KeywordTok{head}\NormalTok{(iris, }\DecValTok{20}\NormalTok{), }\DataTypeTok{caption =} \StringTok{'Here is a nice table!'}\NormalTok{,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nice-tab}Here is a nice table!}
\centering
\begin{tabular}[t]{rrrrl}
\toprule
Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\
\midrule
5.1 & 3.5 & 1.4 & 0.2 & setosa\\
4.9 & 3.0 & 1.4 & 0.2 & setosa\\
4.7 & 3.2 & 1.3 & 0.2 & setosa\\
4.6 & 3.1 & 1.5 & 0.2 & setosa\\
5.0 & 3.6 & 1.4 & 0.2 & setosa\\
\addlinespace
5.4 & 3.9 & 1.7 & 0.4 & setosa\\
4.6 & 3.4 & 1.4 & 0.3 & setosa\\
5.0 & 3.4 & 1.5 & 0.2 & setosa\\
4.4 & 2.9 & 1.4 & 0.2 & setosa\\
4.9 & 3.1 & 1.5 & 0.1 & setosa\\
\addlinespace
5.4 & 3.7 & 1.5 & 0.2 & setosa\\
4.8 & 3.4 & 1.6 & 0.2 & setosa\\
4.8 & 3.0 & 1.4 & 0.1 & setosa\\
4.3 & 3.0 & 1.1 & 0.1 & setosa\\
5.8 & 4.0 & 1.2 & 0.2 & setosa\\
\addlinespace
5.7 & 4.4 & 1.5 & 0.4 & setosa\\
5.4 & 3.9 & 1.3 & 0.4 & setosa\\
5.1 & 3.5 & 1.4 & 0.3 & setosa\\
5.7 & 3.8 & 1.7 & 0.3 & setosa\\
5.1 & 3.8 & 1.5 & 0.3 & setosa\\
\bottomrule
\end{tabular}
\end{table}

You can write citations, too. For example, we are using the
\textbf{bookdown} package \citep{R-bookdown} in this sample book, which
was built on top of R Markdown and \textbf{knitr} \citep{xie2015}.

\chapter{\texorpdfstring{Advanced
\texttt{R}}{Advanced R}}\label{R-advanced}

This chapter continues with some advanced usage examples from chapter
\ref{R-intro}

\section{More Vectorization}\label{more-vectorization}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{y =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{100}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{+}\StringTok{ }\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  3  5  7  9 10 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{+}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  3  5  7  9 10 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{>}\StringTok{ }\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{>}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OperatorTok{+}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in x + y: longer object length is not a multiple of shorter object
## length
\end{verbatim}

\begin{verbatim}
##   [1]   2   5   8  11  13  15   8  11  14  17  19  21  14  17  20  23  25
##  [18]  27  20  23  26  29  31  33  26  29  32  35  37  39  32  35  38  41
##  [35]  43  45  38  41  44  47  49  51  44  47  50  53  55  57  50  53  56
##  [52]  59  61  63  56  59  62  65  67  69  62  65  68  71  73  75  68  71
##  [69]  74  77  79  81  74  77  80  83  85  87  80  83  86  89  91  93  86
##  [86]  89  92  95  97  99  92  95  98 101 103 105  98 101 104 107
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 100
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(y) }\OperatorTok{/}\StringTok{ }\KeywordTok{length}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16.66667
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(x }\OperatorTok{+}\StringTok{ }\NormalTok{y) }\OperatorTok{-}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in x + y: longer object length is not a multiple of shorter object
## length
\end{verbatim}

\begin{verbatim}
##   [1] 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8
##  [36] 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7
##  [71] 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7 8 9 1 3 5 7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y =}\StringTok{ }\DecValTok{1}\OperatorTok{:}\DecValTok{60}
\NormalTok{x }\OperatorTok{+}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  2  5  8 11 13 15  8 11 14 17 19 21 14 17 20 23 25 27 20 23 26 29 31
## [24] 33 26 29 32 35 37 39 32 35 38 41 43 45 38 41 44 47 49 51 44 47 50 53
## [47] 55 57 50 53 56 59 61 63 56 59 62 65 67 69
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{length}\NormalTok{(y) }\OperatorTok{/}\StringTok{ }\KeywordTok{length}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rep}\NormalTok{(x, }\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  2  5  8 11 13 15  8 11 14 17 19 21 14 17 20 23 25 27 20 23 26 29 31
## [24] 33 26 29 32 35 37 39 32 35 38 41 43 45 38 41 44 47 49 51 44 47 50 53
## [47] 55 57 50 53 56 59 61 63 56 59 62 65 67 69
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(x }\OperatorTok{+}\StringTok{ }\NormalTok{y }\OperatorTok{==}\StringTok{ }\KeywordTok{rep}\NormalTok{(x, }\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{identical}\NormalTok{(x }\OperatorTok{+}\StringTok{ }\NormalTok{y, }\KeywordTok{rep}\NormalTok{(x, }\DecValTok{10}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# ?any}
\CommentTok{# ?all.equal}
\end{Highlighting}
\end{Shaded}

\section{Calculations with Vectors and
Matrices}\label{calculations-with-vectors-and-matrices}

Certain operations in \texttt{R}, for example \texttt{\%*\%} have
different behavior on vectors and matrices. To illustrate this, we will
first create two vectors.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_vec =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{b_vec =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that these are indeed vectors. They are not matrices.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\KeywordTok{is.vector}\NormalTok{(a_vec), }\KeywordTok{is.vector}\NormalTok{(b_vec))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{c}\NormalTok{(}\KeywordTok{is.matrix}\NormalTok{(a_vec), }\KeywordTok{is.matrix}\NormalTok{(b_vec))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE FALSE
\end{verbatim}

When this is the case, the \texttt{\%*\%} operator is used to calculate
the \textbf{dot product}, also know as the \textbf{inner product} of the
two vectors.

The dot product of vectors
\(\boldsymbol{a} = \lbrack a_1, a_2, \cdots a_n \rbrack\) and
\(\boldsymbol{b} = \lbrack b_1, b_2, \cdots b_n \rbrack\) is defined to
be

\[
\boldsymbol{a} \cdot \boldsymbol{b} = \sum_{i = 1}^{n} a_i b_i = a_1 b_1 + a_2 b_2 + \cdots a_n b_n.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_vec }\OperatorTok{%*%}\StringTok{ }\NormalTok{b_vec }\CommentTok{# inner product}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]   12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a_vec }\OperatorTok{%o%}\StringTok{ }\NormalTok{b_vec }\CommentTok{# outer product}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    2    2    2
## [2,]    4    4    4
## [3,]    6    6    6
\end{verbatim}

The \texttt{\%o\%} operator is used to calculate the \textbf{outer
product} of the two vectors.

When vectors are coerced to become matrices, they are column vectors. So
a vector of length \(n\) becomes an \(n \times 1\) matrix after
coercion.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.matrix}\NormalTok{(a_vec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    1
## [2,]    2
## [3,]    3
\end{verbatim}

If we use the \texttt{\%*\%} operator on matrices, \texttt{\%*\%} again
performs the expected matrix multiplication. So you might expect the
following to produce an error, because the dimensions are incorrect.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.matrix}\NormalTok{(a_vec) }\OperatorTok{%*%}\StringTok{ }\NormalTok{b_vec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    2    2    2
## [2,]    4    4    4
## [3,]    6    6    6
\end{verbatim}

At face value this is a \(3 \times 1\) matrix, multiplied by a
\(3 \times 1\) matrix. However, when \texttt{b\_vec} is automatically
coerced to be a matrix, \texttt{R} decided to make it a ``row vector'',
a \(1 \times 3\) matrix, so that the multiplication has conformable
dimensions.

If we had coerced both, then \texttt{R} would produce an error.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{as.matrix}\NormalTok{(a_vec) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(b_vec)}
\end{Highlighting}
\end{Shaded}

Another way to calculate a \emph{dot product} is with the
\texttt{crossprod()} function. Given two vectors, the
\texttt{crossprod()} function calculates their dot product. The function
has a rather misleading name.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{crossprod}\NormalTok{(a_vec, b_vec)  }\CommentTok{# inner product}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]   12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tcrossprod}\NormalTok{(a_vec, b_vec)  }\CommentTok{# outer product}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    2    2    2
## [2,]    4    4    4
## [3,]    6    6    6
\end{verbatim}

These functions could be very useful later. When used with matrices
\(X\) and \(Y\) as arguments, it calculates

\[
X^\top Y.
\]

When dealing with linear models, the calculation

\[
X^\top X
\]

is used repeatedly.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{C_mat =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{), }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{D_mat =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is useful both as a shortcut for a frequent calculation and as a
more efficient implementation than using \texttt{t()} and
\texttt{\%*\%}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{crossprod}\NormalTok{(C_mat, D_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    6    6    6
## [2,]   14   14   14
## [3,]   22   22   22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(C_mat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{D_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    6    6    6
## [2,]   14   14   14
## [3,]   22   22   22
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all.equal}\NormalTok{(}\KeywordTok{crossprod}\NormalTok{(C_mat, D_mat), }\KeywordTok{t}\NormalTok{(C_mat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{D_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{crossprod}\NormalTok{(C_mat, C_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    5   11   17
## [2,]   11   25   39
## [3,]   17   39   61
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(C_mat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{C_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    5   11   17
## [2,]   11   25   39
## [3,]   17   39   61
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all.equal}\NormalTok{(}\KeywordTok{crossprod}\NormalTok{(C_mat, C_mat), }\KeywordTok{t}\NormalTok{(C_mat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{C_mat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\section{Matrices}\label{matrices-1}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Z =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{2}\NormalTok{, }\OperatorTok{-}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\OperatorTok{-}\DecValTok{2}\NormalTok{, }\OperatorTok{-}\DecValTok{3}\NormalTok{, }\OperatorTok{-}\DecValTok{2}\NormalTok{, }\DecValTok{16}\NormalTok{), }\DecValTok{3}\NormalTok{, }\DataTypeTok{byrow =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    9    2   -3
## [2,]    2    4   -2
## [3,]   -3   -2   16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{solve}\NormalTok{(Z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]        [,2]       [,3]
## [1,]  0.12931034 -0.05603448 0.01724138
## [2,] -0.05603448  0.29094828 0.02586207
## [3,]  0.01724138  0.02586207 0.06896552
\end{verbatim}

To verify that \texttt{solve(Z)} returns the inverse, we multiply it by
\texttt{Z}. We would expect this to return the identity matrix, however
we see that this is not the case due to some computational issues.
However, \texttt{R} also has the \texttt{all.equal()} function which
checks for equality, with some small tolerance which accounts for some
computational issues. The \texttt{identical()} function is used to check
for exact equality.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{solve}\NormalTok{(Z) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]          [,2]         [,3]
## [1,] 1.000000e+00 -6.245005e-17 0.000000e+00
## [2,] 8.326673e-17  1.000000e+00 5.551115e-17
## [3,] 2.775558e-17  0.000000e+00 1.000000e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{diag}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    0    0
## [2,]    0    1    0
## [3,]    0    0    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all.equal}\NormalTok{(}\KeywordTok{solve}\NormalTok{(Z) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Z, }\KeywordTok{diag}\NormalTok{(}\DecValTok{3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\texttt{R} has a number of matrix specific functions for obtaining
dimension and summary information.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3]
## [1,]    1    3    5
## [2,]    2    4    6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dim}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowSums}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  9 12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colSums}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  3  7 11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rowMeans}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{colMeans}\NormalTok{(X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.5 3.5 5.5
\end{verbatim}

The \texttt{diag()} function can be used in a number of ways. We can
extract the diagonal of a matrix.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{diag}\NormalTok{(Z)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  9  4 16
\end{verbatim}

Or create a matrix with specified elements on the diagonal. (And
\texttt{0} on the off-diagonals.)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{diag}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    2    0    0    0
## [3,]    0    0    3    0    0
## [4,]    0    0    0    4    0
## [5,]    0    0    0    0    5
\end{verbatim}

Or, lastly, create a square matrix of a certain dimension with
\texttt{1} for every element of the diagonal and \texttt{0} for the
off-diagonals.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{diag}\NormalTok{(}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4] [,5]
## [1,]    1    0    0    0    0
## [2,]    0    1    0    0    0
## [3,]    0    0    1    0    0
## [4,]    0    0    0    1    0
## [5,]    0    0    0    0    1
\end{verbatim}

\bibliography{book.bib,packages.bib}


\end{document}
