# To Be Done Chapters

The following topics could be part of a future version of this course.

## Quantile Regression

1. before you were modelling the mean. the average link
1. now what happens to **outliers**? how robust is the mean to that
1. what about the entire distribution of this?

## Panel Data

### fixed effects

### DiD

### RDD


### Example

* scanner data on breakfast cereals, $(Q_{it},D_{it})$
* why does D vary with Q
* pos relation ship 
* don't observe the group identity!
* unobserved het alpha is correlated with Q
* within group estimator
* what if you don't have panel data?

## Logit and Probit

## Principal Component Analysis


## General Notes

this creates a library for the used R packages.

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown','ScPoEconometrics','shiny','learnr','datasauRus','webshot','AER'
), 'packages.bib')
```

Packages used:

* **bookdown** [@R-bookdown]
* **shiny** [@R-shiny]
* **learnr** [@R-learnr]
* **datasauRus** [@R-datasauRus]
* **webshot** [@R-webshot]
* **AER** [@R-AER]
* **knitr** [@xie2015]
* **ScPoEconometrics** [@R-ScPoEconometrics]
* **Ecdat** [@R-Ecdat]
* **Ecfun** [@R-Ecfun]
* **R** [@R-base]
* **dplyr** [@R-dplyr]
* **ggplot2** [@R-ggplot2]
* **reshape2** [@R-reshape2]
* **bindrcpp** [@R-bindrcpp]
* **mvtnorm** [@R-mvtnorm]
* **plotly** [@R-plotly]
* **readr** [@R-readr]
* **readxl** [@R-readxl]
* **tidyr** [@R-tidyr]
* **readr** [@R-readr]



## Inference via Bootstrap

We will now take the ideas from the previous section and illustrate them using one single powerful idea. Instead of relying on some *population distribution* from which our samples of data have been drawn, we can regard the sampling distribution itself as the population distribution, and take samples *from* it. Our discussion in the previous section *relied* on a tight connection between sampling and population distribution - how else could we have inferred anything about the population from looking at our sample? We will take this idea to its extreme now and look *only* at the sampling distribution. This idea is a *resampling* technique, commonly referred to as the *Bootstrap*.

```{block type = "warning"}
**Bootstrapping** is a test or metric that relies on *resampling with replacement*. It allows estimation of the sampling distribution of almost any statistic using random sampling methods.
```

### How does the Bootstrap work?

This best to show with an example. Suppose we had stored our `R n` measurements of students heights from figure \@ref(fig:heightdata) above in the variable `height`

```{r}
head(height)
```

and let's suppose we want to figure out the distribution of the sample mean $\bar{height}$ here. We will now compute the mean of `height` repeatedly, each time collecting the result in a vector:

```{r}
r = c()
R = 200
for (ib in 1:R){
  bs = sample(height,size = 10,replace = TRUE)  # bootstrap sample
  r = c(r,mean(bs))  # add to results vector
}
```

How are `r R` means we have computed distributed? Do they all have the same value? Different? How?

```{r hists-x,echo = FALSE,fig.cap="The Distribution of 200 means of `height`, where each version was obtained by resampling from `height` with replacement. The red line indicates the *true* mean from the original sample of `height`."}
hist(r,main = "Histogram of Means of Height",xlab = "Mean of Height")
abline(v = mean(height),col = "red",lw=2)
```

Well, this is very similar to a normal distribution, isn't it?^[In particular, notice that is *not* the same histogram as the one in figure \@ref(fig:heightdata) above. Here we see the *means* of height, whereas above we plotted the raw data values.] You should remember that above, for example in figure \@ref(fig:cifig), we had derived a *theoretical* sampling distribution. Relying on statistical theory, we learned that a certain test statistic will be distributed according to a certain distribution (students's t, or normal, for instance), and that we could use that knowledge to construct confidence intervals and hypothesis tests. Well, what you are seeing in figure \@ref(fig:hists-x) is the bootstrapped counterpart to that theoretical distribution. It's the *simulated proof* that the sampling distribution of the mean is indeed the normal distribution. The advantage here is that we did not need to rely on *any* theory at all, just simple resampling.

### Bootstrapped Confidence Intervals

Let's redo what we did above with the bootstrap. We will use the brilliant [infer](https://github.com/tidymodels/infer) package to have some fun with this.

```{r}
library(infer)
hdf = data.frame(height)   # needs a data.frame
boot <- hdf %>%
   specify(response = height) %>%   # specify repsonse
   generate(reps = 1000, type = "bootstrap") %>%   # generate BS samples
   calculate(stat = "mean")   # calculate statistic of interest
( percentile_ci <- get_ci(boot) )   # get CI
```

You note that this is reasonably close to the confidence interval about our sample mean we obtained above, which was $$\left[`r round(xbar - qt(0.975,df=n-1)* s/sqrt(n),3)` , `r round(xbar + qt(0.975,df=n-1)* s/sqrt(n),3)` \right]$$

What is really cool is the visualization:

```{r boot-ci, fig.cap="Simulate Distribution under Null Hypothesis together with a 95% confidence region"}
visualize(boot) +
  shade_confidence_interval(endpoints = percentile_ci) + theme_bw()
```


In figure \@ref(fig:boot-ci) we see that each value of a sample mean within the green shaded area would lie within a 95% confidence region about the location of the true *population* mean. 

We can also repeat our hypothesis test from above with the help of the bootstrap. The hypothesis were

\begin{align}
H_0:& \mu = `r mu`\\
H_1:& \mu > `r mu`.
\end{align}


```{r H0-height, fig.cap = "One sided hypothesis test with bootstrap."}
H0_height <- hdf %>%
   specify(response = height) %>%   # specify repsonse
   hypothesize(null = "point", mu = 167) %>%  # spell out H0
   generate(reps = 1000, type = "bootstrap") %>%   # generate BS samples
   calculate(stat = "mean")   # calculate statistic of interest

visualize(H0_height) +
  shade_p_value(obs_stat = xbar, direction = "right") + theme_bw()
```

In figure \@ref(fig:H0-height) we see the simulated distribution under the Null, i.e. the one where indeed $\mu = `r mu`$. The red vertical line is the value of our calculated test statistic, which was `r xbar`. The shaded area shows is the corresponding level of significance that we would have to adopt, would we want to reject H0 on the grounds of having observed `\bar{x} = r xbar`. The size of the red-shaded area is *p-value* of this test. It's easy to compute from this object via

```{r}
pval = H0_height %>%
  get_p_value(obs_stat = xbar, direction = "right")
pval
```

This means that had we adopt a significance level of $\alpha = `r pval`$, we would (just!) been able to reject the Null hypthesis. Now you remember that $\alpha$ is the probability of a Type 1 Error. So, we would have to be happy to make a wrong decision (i.e. to reject when in fact we should not) in about `r round(pval,2)`% of all cases. So, as above, we probably conclude that this is pretty weak evidence against H0, and we cannot reject it based on this evidence.

It's illustrative to reason about how this picture changes as we change the hypothesized value. Suppose we change our hypothesis to 

\begin{align}
H_0:& \mu = 164\\
H_1:& \mu > 164.
\end{align}

```{r H0-height2, fig.cap = "One sided hypothesis test with bootstrap and different hypothesis."}
H0_height <- hdf %>%
   specify(response = height) %>%   # specify repsonse
   hypothesize(null = "point", mu = 164) %>%  # spell out H0
   generate(reps = 1000, type = "bootstrap") %>%   # generate BS samples
   calculate(stat = "mean")   # calculate statistic of interest

visualize(H0_height) +
  shade_p_value(obs_stat = xbar, direction = "right") + theme_bw()
```


The concept is astonishingly simple. It's best to illustrate with an example from the [ungeviz](https://github.com/wilkelab/ungeviz) package.^[this is based on `help(bootstrapper,package = "ungeviz")`] Here is a dataset:

```{r}
set.seed(1)
n = 10  # data points
x = rnorm(n)
df <- data.frame(x,y = x + 0.5*rnorm(n))
plot(y~x,data=df)
grid()
```

Now we are going to randomly choose rows of this dataframe, `n` at a time, but with replacement. One way to achieve this is via

```{r, eval = FALSE}
dplyr::sample_n(df, size = n, replace = TRUE)
```

which would generate one reshuffled sample of `df`. We repeat this for $R$ draws, and each time we calculate the statistic we are interested in. The mean of `x`, mean of `y`, whatever. Let's compute the OLS slope coefficient instead, just another statistic, and let's just take a small number of draws, $R=9$:

```{r ungeviz-demo,echo = FALSE,fig.height = 8}
library(ungeviz)
bs <- bootstrapper(9)
p <- ggplot(df, aes(x, y)) +
geom_point(shape = 21, size = 6, fill = "white") +
geom_text(label = "0", hjust = 0.5, vjust = 0.5, size = 10/.pt) +
geom_point(data = bs, aes(group = .row), shape = 21, size = 6, fill = "blue") +
geom_text(
data = bs, aes(label = .copies, group = .row),
hjust = 0.5, vjust = 0.5, size = 10/.pt, color = "white"
) +
geom_smooth(data = bs, method = "lm", se = FALSE, color = "red") +
ggtitle("Bootstrap demonstration") +
theme_bw()
p + facet_wrap(~.draw)
```



