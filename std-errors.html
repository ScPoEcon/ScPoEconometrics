<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 6 Regression Inference | Introduction to Econometrics with R</title>
  <meta name="description" content="SciencesPo UG Econometrics online textbook. Almost no Maths." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 6 Regression Inference | Introduction to Econometrics with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://scpoecon.github.io/ScPoEconometrics/" />
  
  <meta property="og:description" content="SciencesPo UG Econometrics online textbook. Almost no Maths." />
  <meta name="github-repo" content="ScPoEcon/ScPoEconometrics" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Regression Inference | Introduction to Econometrics with R" />
  
  <meta name="twitter:description" content="SciencesPo UG Econometrics online textbook. Almost no Maths." />
  

<meta name="author" content="Florian Oswald, Jean-Marc Robin and Vincent Viers" />


<meta name="date" content="2019-11-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="favicon.gif" type="image/x-icon" />
<link rel="prev" href="categorical-vars.html"/>
<link rel="next" href="causality.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.49.4/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.49.4/plotly-latest.min.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-41584331-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-41584331-4');
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">ScPo 2nd Year Econometrics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Syllabus</a></li>
<li class="chapter" data-level="1" data-path="R-intro.html"><a href="R-intro.html"><i class="fa fa-check"></i><b>1</b> Introduction to <code>R</code></a><ul>
<li class="chapter" data-level="1.1" data-path="R-intro.html"><a href="R-intro.html#getting-started"><i class="fa fa-check"></i><b>1.1</b> Getting Started</a></li>
<li class="chapter" data-level="1.2" data-path="R-intro.html"><a href="R-intro.html#starting-r-and-rstudio"><i class="fa fa-check"></i><b>1.2</b> Starting R and RStudio</a></li>
<li class="chapter" data-level="1.3" data-path="R-intro.html"><a href="R-intro.html#basic-calculations"><i class="fa fa-check"></i><b>1.3</b> Basic Calculations</a></li>
<li class="chapter" data-level="1.4" data-path="R-intro.html"><a href="R-intro.html#getting-help"><i class="fa fa-check"></i><b>1.4</b> Getting Help</a></li>
<li class="chapter" data-level="1.5" data-path="R-intro.html"><a href="R-intro.html#installing-packages"><i class="fa fa-check"></i><b>1.5</b> Installing Packages</a></li>
<li class="chapter" data-level="1.6" data-path="R-intro.html"><a href="R-intro.html#code-output"><i class="fa fa-check"></i><b>1.6</b> <code>Code</code> vs Output in this Book</a></li>
<li class="chapter" data-level="1.7" data-path="R-intro.html"><a href="R-intro.html#install-package"><i class="fa fa-check"></i><b>1.7</b> <code>ScPoEconometrics</code> Package</a></li>
<li class="chapter" data-level="1.8" data-path="R-intro.html"><a href="R-intro.html#data-types"><i class="fa fa-check"></i><b>1.8</b> Data Types</a></li>
<li class="chapter" data-level="1.9" data-path="R-intro.html"><a href="R-intro.html#data-structures"><i class="fa fa-check"></i><b>1.9</b> Data Structures</a></li>
<li class="chapter" data-level="1.10" data-path="R-intro.html"><a href="R-intro.html#dataframes"><i class="fa fa-check"></i><b>1.10</b> Data Frames</a></li>
<li class="chapter" data-level="1.11" data-path="R-intro.html"><a href="R-intro.html#programming-basics"><i class="fa fa-check"></i><b>1.11</b> Programming Basics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="sum.html"><a href="sum.html"><i class="fa fa-check"></i><b>2</b> Working With Data</a><ul>
<li class="chapter" data-level="2.1" data-path="sum.html"><a href="sum.html#summary-statistics"><i class="fa fa-check"></i><b>2.1</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.2" data-path="sum.html"><a href="sum.html#plotting"><i class="fa fa-check"></i><b>2.2</b> Plotting</a></li>
<li class="chapter" data-level="2.3" data-path="sum.html"><a href="sum.html#summarize-two"><i class="fa fa-check"></i><b>2.3</b> Summarizing Two Variables</a></li>
<li class="chapter" data-level="2.4" data-path="sum.html"><a href="sum.html#the-tidyverse"><i class="fa fa-check"></i><b>2.4</b> The <code>tidyverse</code></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linreg.html"><a href="linreg.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="linreg.html"><a href="linreg.html#how-are-x-and-y-related"><i class="fa fa-check"></i><b>3.1</b> How are <code>x</code> and <code>y</code> related?</a></li>
<li class="chapter" data-level="3.2" data-path="linreg.html"><a href="linreg.html#OLS"><i class="fa fa-check"></i><b>3.2</b> Ordinary Least Squares (OLS) Estimator</a></li>
<li class="chapter" data-level="3.3" data-path="linreg.html"><a href="linreg.html#pred-resids"><i class="fa fa-check"></i><b>3.3</b> Predictions and Residuals</a></li>
<li class="chapter" data-level="3.4" data-path="linreg.html"><a href="linreg.html#correlation-covariance-and-linearity"><i class="fa fa-check"></i><b>3.4</b> Correlation, Covariance and Linearity</a></li>
<li class="chapter" data-level="3.5" data-path="linreg.html"><a href="linreg.html#analysing-vary"><i class="fa fa-check"></i><b>3.5</b> Analysing <span class="math inline">\(Var(y)\)</span></a></li>
<li class="chapter" data-level="3.6" data-path="linreg.html"><a href="linreg.html#assessing-the-goodness-of-fit"><i class="fa fa-check"></i><b>3.6</b> Assessing the <em>Goodness of Fit</em></a></li>
<li class="chapter" data-level="3.7" data-path="linreg.html"><a href="linreg.html#an-example-a-log-wage-equation"><i class="fa fa-check"></i><b>3.7</b> An Example: A Log Wage Equation</a></li>
<li class="chapter" data-level="3.8" data-path="linreg.html"><a href="linreg.html#scaling-regressions"><i class="fa fa-check"></i><b>3.8</b> Scaling Regressions</a></li>
<li class="chapter" data-level="3.9" data-path="linreg.html"><a href="linreg.html#a-particular-rescaling-the-log-transform"><i class="fa fa-check"></i><b>3.9</b> A Particular Rescaling: The <span class="math inline">\(\log\)</span> Transform</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="multiple-reg.html"><a href="multiple-reg.html"><i class="fa fa-check"></i><b>4</b> Multiple Regression</a><ul>
<li class="chapter" data-level="4.1" data-path="multiple-reg.html"><a href="multiple-reg.html#ceteris"><i class="fa fa-check"></i><b>4.1</b> All Else Equal</a></li>
<li class="chapter" data-level="4.2" data-path="multiple-reg.html"><a href="multiple-reg.html#multicol"><i class="fa fa-check"></i><b>4.2</b> Multicolinearity</a></li>
<li class="chapter" data-level="4.3" data-path="multiple-reg.html"><a href="multiple-reg.html#log-wage-equation"><i class="fa fa-check"></i><b>4.3</b> Log Wage Equation</a></li>
<li class="chapter" data-level="4.4" data-path="multiple-reg.html"><a href="multiple-reg.html#make-preds"><i class="fa fa-check"></i><b>4.4</b> How To Make Predictions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="categorical-vars.html"><a href="categorical-vars.html"><i class="fa fa-check"></i><b>5</b> Categorial Variables</a><ul>
<li class="chapter" data-level="5.1" data-path="categorical-vars.html"><a href="categorical-vars.html#the-binary-regressor-case"><i class="fa fa-check"></i><b>5.1</b> The Binary Regressor Case</a></li>
<li class="chapter" data-level="5.2" data-path="categorical-vars.html"><a href="categorical-vars.html#dummy-and-continuous-variables"><i class="fa fa-check"></i><b>5.2</b> Dummy and Continuous Variables</a></li>
<li class="chapter" data-level="5.3" data-path="categorical-vars.html"><a href="categorical-vars.html#categorical-variables-in-r-factor"><i class="fa fa-check"></i><b>5.3</b> Categorical Variables in <code>R</code>: <code>factor</code></a></li>
<li class="chapter" data-level="5.4" data-path="categorical-vars.html"><a href="categorical-vars.html#interactions"><i class="fa fa-check"></i><b>5.4</b> Interactions</a></li>
<li class="chapter" data-level="5.5" data-path="categorical-vars.html"><a href="categorical-vars.html#unobserved-individual-heterogeneity"><i class="fa fa-check"></i><b>5.5</b> (Unobserved) Individual Heterogeneity</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="std-errors.html"><a href="std-errors.html"><i class="fa fa-check"></i><b>6</b> Regression Inference</a><ul>
<li class="chapter" data-level="6.1" data-path="std-errors.html"><a href="std-errors.html#sampling"><i class="fa fa-check"></i><b>6.1</b> Sampling</a></li>
<li class="chapter" data-level="6.2" data-path="std-errors.html"><a href="std-errors.html#taking-eleven-samples-from-the-population"><i class="fa fa-check"></i><b>6.2</b> Taking Eleven Samples From The Population</a></li>
<li class="chapter" data-level="6.3" data-path="std-errors.html"><a href="std-errors.html#handover-to-moderndive"><i class="fa fa-check"></i><b>6.3</b> Handover to <code>Moderndive</code></a></li>
<li class="chapter" data-level="6.4" data-path="std-errors.html"><a href="std-errors.html#uncertainty-in-regression-estimates"><i class="fa fa-check"></i><b>6.4</b> Uncertainty in Regression Estimates</a></li>
<li class="chapter" data-level="6.5" data-path="std-errors.html"><a href="std-errors.html#what-is-true-what-are-statistical-models"><i class="fa fa-check"></i><b>6.5</b> What is <em>true</em>? What are Statistical Models?</a></li>
<li class="chapter" data-level="6.6" data-path="std-errors.html"><a href="std-errors.html#class-reg"><i class="fa fa-check"></i><b>6.6</b> The Classical Regression Model (CRM)</a></li>
<li class="chapter" data-level="6.7" data-path="std-errors.html"><a href="std-errors.html#se-theory"><i class="fa fa-check"></i><b>6.7</b> Standard Errors in Theory</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>7</b> Causality</a><ul>
<li class="chapter" data-level="7.1" data-path="causality.html"><a href="causality.html#dags"><i class="fa fa-check"></i><b>7.1</b> Directed Acyclical Graphs (DAG)</a></li>
<li class="chapter" data-level="7.2" data-path="causality.html"><a href="causality.html#smoking-in-a-dag"><i class="fa fa-check"></i><b>7.2</b> Smoking in a DAG</a></li>
<li class="chapter" data-level="7.3" data-path="causality.html"><a href="causality.html#rct"><i class="fa fa-check"></i><b>7.3</b> Randomized Control Trials (RCT) Primer</a></li>
<li class="chapter" data-level="7.4" data-path="causality.html"><a href="causality.html#rubin"><i class="fa fa-check"></i><b>7.4</b> The Potential Outcomes Model</a></li>
<li class="chapter" data-level="7.5" data-path="causality.html"><a href="causality.html#omitted-variable-bias-and-dags"><i class="fa fa-check"></i><b>7.5</b> Omitted Variable Bias and DAGs</a></li>
<li class="chapter" data-level="7.6" data-path="causality.html"><a href="causality.html#star-experiment"><i class="fa fa-check"></i><b>7.6</b> STAR Experiment</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="STAR.html"><a href="STAR.html"><i class="fa fa-check"></i><b>8</b> STAR Experiment</a><ul>
<li class="chapter" data-level="8.1" data-path="STAR.html"><a href="STAR.html#the-star-experiment"><i class="fa fa-check"></i><b>8.1</b> The STAR Experiment</a></li>
<li class="chapter" data-level="8.2" data-path="STAR.html"><a href="STAR.html#po-as-regression"><i class="fa fa-check"></i><b>8.2</b> PO as Regression</a></li>
<li class="chapter" data-level="8.3" data-path="STAR.html"><a href="STAR.html#implementing-star"><i class="fa fa-check"></i><b>8.3</b> Implementing STAR</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="RDD.html"><a href="RDD.html"><i class="fa fa-check"></i><b>9</b> Regression Discontinuity Design</a><ul>
<li class="chapter" data-level="9.1" data-path="RDD.html"><a href="RDD.html#rdd-setup"><i class="fa fa-check"></i><b>9.1</b> RDD Setup</a></li>
<li class="chapter" data-level="9.2" data-path="RDD.html"><a href="RDD.html#clicking-on-heavens-door"><i class="fa fa-check"></i><b>9.2</b> Clicking on Heaven’s Door</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="projects.html"><a href="projects.html"><i class="fa fa-check"></i><b>10</b> Projects</a><ul>
<li class="chapter" data-level="10.1" data-path="projects.html"><a href="projects.html#trade-exercise"><i class="fa fa-check"></i><b>10.1</b> Trade Exercise</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Econometrics with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="std-errors" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Regression Inference</h1>
<p>In this chapter we want to investigate uncertainty in regression estimates. We want to understand what the precise meaning of the <code>Std. Error</code> column in a typical regression table is telling us. In terms of a picture, we want to understand better the meaning of the shaded area as in this one here:</p>
<div class="figure" style="text-align: center"><span id="fig:confint"></span>
<img src="ScPoEconometrics_files/figure-html/confint-1.png" alt="Confidence bands around a regression line." width="672" />
<p class="caption">
Figure 6.1: Confidence bands around a regression line.
</p>
</div>
<p>In order to fully understand this, we need to go back and make sure we have a good grasp of <em>sampling</em>. Let’s do this first.</p>
<div id="sampling" class="section level2">
<h2><span class="header-section-number">6.1</span> Sampling</h2>
<p>In class we were confronted with a jar of Tricolore Fusilli pasta as picture in figure <a href="std-errors.html#fig:pasta1">6.2</a>.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> We asked ourselves a question which, secretly, many of you had asked themselves at one point in their lives, namely:</p>
<div class="tip">
<p>
What is the proportion of <strong>green</strong> Fusilli in a pack of Tricolore Fusilli?
</p>
</div>
<p><br></p>
<p>Well, it’s time to find out.</p>
<div class="figure" style="text-align: center"><span id="fig:pasta1"></span>
<img src="images/pasta1.JPG" alt="A glass jar filled with Fusilli pasta in three different colors." width="90%" />
<p class="caption">
Figure 6.2: A glass jar filled with Fusilli pasta in three different colors.
</p>
</div>
<p>Let’s call the fusilly in this jar our <em>study population</em>, i.e. the set of units about which we want to learn something. There are several approaches to address the question of how big a proportion in the population the green Fusilli make up. One obvious solution is to enumerate all Fusilli according to their color, and compute their proportion in the entire population. It works perfectly well as a solution, but is a long and arduous process, see figures <a href="std-errors.html#fig:pasta2">6.3</a> and <a href="std-errors.html#fig:pasta3">6.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:pasta2"></span>
<img src="images/pasta2.JPG" alt="Manually separating Fusilli by their color is very costly in terms of effort and cost." width="90%" />
<p class="caption">
Figure 6.3: Manually separating Fusilli by their color is very costly in terms of effort and cost.
</p>
</div>
<p>Additionally, you may draw worried looks from the people around you, while you are doing it. Maybe this is not the right way to approach this task?<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<div class="figure" style="text-align: center"><span id="fig:pasta3"></span>
<img src="images/pasta3.JPG" alt="Heaps of Fusilli pasta ready to be counted." width="90%" />
<p class="caption">
Figure 6.4: Heaps of Fusilli pasta ready to be counted.
</p>
</div>
<div id="taking-one-sample-from-the-population" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Taking One Sample From the Population</h3>
<p>We started by randomly grabbing a handful of Fusilli from the jar and by letting drop exactly <span class="math inline">\(N=20\)</span> into a paper coffee cup, pictured in <a href="std-errors.html#fig:pasta5">6.5</a>. We call <span class="math inline">\(N\)</span> the <em>sample size</em>. The count and corresponding proportions of each color in this first sample are shown in the following table:</p>
<table>
<thead>
<tr class="header">
<th align="center">Color</th>
<th align="center">Count</th>
<th align="center">Proportion</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Red</td>
<td align="center">7</td>
<td align="center">0.35</td>
</tr>
<tr class="even">
<td align="center">Green</td>
<td align="center">5</td>
<td align="center">0.25</td>
</tr>
<tr class="odd">
<td align="center">White</td>
<td align="center">8</td>
<td align="center">0.4</td>
</tr>
</tbody>
</table>
<p>So far, so good. We have our first <em>estimate of the population proportion of green Fusilli in the overall population</em>: 0.25. Notice that taking a sample of <span class="math inline">\(N=20\)</span> was <em>much</em> quicker and <em>much less painful</em> than performing the full count (i.e. the <em>census</em>) of Fusilli performed above.</p>
<div class="figure" style="text-align: center"><span id="fig:pasta5"></span>
<img src="images/pasta5.JPG" alt="Taking one sample of 20 Fusilli from the jar." width="90%" />
<p class="caption">
Figure 6.5: Taking one sample of 20 Fusilli from the jar.
</p>
</div>
<p>Then, we put my sample back into the jar, and we reshuffled the Fusilli. Had we taken <em>another</em> sample, again of <span class="math inline">\(N=20\)</span>, would we again have gotten 7 Red, 5 Green, and 8 White, just as in the first sample? Maybe, but maybe not. Suppose we had carried on for several times drawing samples of 20 and counting the colors: Would we also have observed 5 green Fusilli? Definitely not. We would have noted some degree of <em>variability</em> in the proportions computed from our samples. The <em>sample proportions</em> in this case are an example of a <em>sample statistic</em>.</p>
<div class="note">
<p>
<strong>Sampling Variation</strong> refers to the fact that if we <em>randomly</em> take samples from a wider population, the <em>random</em> composition of each sample will imply that we obtain statistics that vary - they take on potentially different values in each sample.
</p>
</div>
<p>Let’s see how this story evolved as we started taking more samples at a time.</p>
</div>
</div>
<div id="taking-eleven-samples-from-the-population" class="section level2">
<h2><span class="header-section-number">6.2</span> Taking Eleven Samples From The Population</h2>
<p>We formed teams of two students in class who would each in turn take samples from the jar (the population) of size <span class="math inline">\(N=20\)</span>, as before. Each team computed the proportion of green Fusilli they had in their sample, and we wrote this data down in a table on the board. Then, we drew a histogram which showed how many samples had fallen into which bins.</p>
<div class="figure" style="text-align: center"><span id="fig:pasta6"></span>
<img src="images/pasta6.JPG" alt="Taking eleven samples of 20 Fusilli each from the jar, and plotting the histogram of obtained sample proportions of Green Fusilli." width="90%" />
<p class="caption">
Figure 6.6: Taking eleven samples of 20 Fusilli each from the jar, and plotting the histogram of obtained sample proportions of Green Fusilli.
</p>
</div>
<p>We looked at the histogram in figure <a href="std-errors.html#fig:pasta6">6.6</a> and we noted several things:</p>
<ol style="list-style-type: decimal">
<li>The largest proportions where 0.3 green</li>
<li>The smallest proportion was 0.15 green.</li>
<li>Most samples found a proportion of 0.25 green fusilli.</li>
<li>We did think that this looked <em>suspiciouly</em> like a <strong>normal distribution</strong>.</li>
</ol>
<p>We collected the sample data into a data.frame:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pasta_samples &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">group =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">11</span>, <span class="dt">replicate =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">11</span>, <span class="dt">prop_green =</span> <span class="kw">c</span>(<span class="fl">0.3</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.3</span>,<span class="fl">0.15</span>,<span class="fl">0.3</span>,<span class="fl">0.25</span>,<span class="fl">0.25</span>,<span class="fl">0.2</span>,<span class="fl">0.25</span>,<span class="fl">0.2</span>))
pasta_samples</code></pre></div>
<pre><code>#OUT&gt;    group replicate prop_green
#OUT&gt; 1      1         1       0.30
#OUT&gt; 2      2         2       0.25
#OUT&gt; 3      3         3       0.25
#OUT&gt; 4      4         4       0.30
#OUT&gt; 5      5         5       0.15
#OUT&gt; 6      6         6       0.30
#OUT&gt; 7      7         7       0.25
#OUT&gt; 8      8         8       0.25
#OUT&gt; 9      9         9       0.20
#OUT&gt; 10    10        10       0.25
#OUT&gt; 11    11        11       0.20</code></pre>
<p>This produces an associated histogram which looks very much like the one we draws onto the board:</p>
<p><img src="ScPoEconometrics_files/figure-html/pasta-hist-1.png" width="672" style="display: block; margin: auto;" /></p>
<div id="recap" class="section level3">
<h3><span class="header-section-number">6.2.1</span> Recap</h3>
<p>Let’s recaptiulate what we just did. We wanted to know what proportion of Fusilli in the glass jar in figure <a href="std-errors.html#fig:pasta1">6.2</a> are green. We acknowledged that an exclusive count, or a census, is a costly and cumbersome exercise, which in most circumstances we will try to avoid. In order to make some progress nonetheless, we took a <em>random sample</em> from the full population in the jar: we randomly selected 20 Fusilli, and looked at the proportion of green ones in there. We found a proportion of 0.25.</p>
<p>After replacing the Fusilli from the first sample in the jar, we asked ourselves if, upon drawing a <em>new</em> sample of 20 Fusilli, we should expect to see the same outcome - and we concluded: maybe, but maybe not. In short, we discovered some random variation from sample to sample. We called this <strong>sampling variation</strong>.</p>
<p>The purpose of this little activity was three-fold:</p>
<ol style="list-style-type: decimal">
<li>To understand that random samples differ and that there is sampling variation.</li>
<li>To understand that bigger samples will yield smaller sampling variation.</li>
<li>To illustrate that the sampling distribution of <em>any</em> statistic (i.e. not only the sample proportion as in our case) computed from a random sample converges to a normal distribution as the sample size increases.</li>
</ol>
<div class="note">
<p>
The value of this exercise consisted in making <strong>you</strong> perform the sampling activity yourself. We will now hand over to the brilliant <strong>moderndive</strong> package, which will further develop this chapter.
</p>
</div>
</div>
</div>
<div id="handover-to-moderndive" class="section level2">
<h2><span class="header-section-number">6.3</span> Handover to <code>Moderndive</code></h2>
<div class="figure" style="text-align: center"><span id="fig:handover"></span>
<img src="images/transition.png" alt="The Moderndive package used red and white balls instead of fusilli pasta." width="90%" />
<p class="caption">
Figure 6.7: The Moderndive package used red and white balls instead of fusilli pasta.
</p>
</div>
<p>The sampling activity in <code>moderndive</code> was performed with red and white balls instead of green fusilli pasta. The rest is identical. We will now read sections <a href="https://moderndive.com/7-sampling.html#sampling-simulation">7.2</a> and <a href="https://moderndive.com/7-sampling.html#sampling-framework">7.3</a> in their book, as well as <a href="https://moderndive.com/8-confidence-intervals.html">chapter 8 on confidence intervals adn bootstrapping</a>, and <a href="https://moderndive.com/9-hypothesis-testing.html">chapter 9 on hypothesis testing</a>.</p>
</div>
<div id="uncertainty-in-regression-estimates" class="section level2">
<h2><span class="header-section-number">6.4</span> Uncertainty in Regression Estimates</h2>
<p>In the previous chapters we have seen how the OLS method can produce estimates about intercept and slope coefficients from data. You have seen this method at work in <code>R</code> by using the <code>lm</code> function as well. It is now time to introduce the notion that given that <span class="math inline">\(b_0\)</span>, <span class="math inline">\(b_1\)</span> and <span class="math inline">\(b_2\)</span> are <em>estimates</em> of some unkown <em>population parameters</em>, there is some degree of <strong>uncertainty</strong> about their values. An other way to say this is that we want some indication about the <em>precision</em> of those estimates. The underlying issue that the data we have at hand are usually <em>samples</em> from a larger population.</p>
<div class="note">
<center>
How <em>confident</em> should we be about the estimated values <span class="math inline"><span class="math inline">\(b\)</span></span>?
</center>
</div>
<p><br></p>
</div>
<div id="what-is-true-what-are-statistical-models" class="section level2">
<h2><span class="header-section-number">6.5</span> What is <em>true</em>? What are Statistical Models?</h2>
<p>A <strong>statistical model</strong> is simply a set of assumptions about how some data have been generated. As such, it models the data-generating process (DGP), as we have it in mind. Once we define a DGP, we could simulate data from it and see how this compares to the data we observe in the real world. Or, we could change the parameters of the DGP so as to understand how the real world data <em>would</em> change, could we (or some policy) change the corresponding parameters in reality. Let us now consider one particular statistical model, which in fact we have seen so many times already.</p>
</div>
<div id="class-reg" class="section level2">
<h2><span class="header-section-number">6.6</span> The Classical Regression Model (CRM)</h2>
<p>Let’s bring back our simple model <a href="linreg.html#eq:abline">(3.3)</a> to explain this concept.</p>
<span class="math display" id="eq:abline-5">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i \tag{6.1}
\end{equation}\]</span>
<p>The smallest set of assumptions used to define the <em>classical regression model</em> as in <a href="std-errors.html#eq:abline-5">(6.1)</a> are the following:</p>
<ol style="list-style-type: decimal">
<li>The data are <strong>not linearly dependent</strong>: Each variable provides new information for the outcome, and it cannot be replicated as a linear combination of other variables. We have seen this in section <a href="multiple-reg.html#multicol">4.2</a>. In the particular case of one regressor, as here, we require that <span class="math inline">\(x\)</span> exhibit some variation in the data, i.e. <span class="math inline">\(Var(x)\neq 0\)</span>.</li>
<li>The mean of the residuals conditional on <span class="math inline">\(x\)</span> should be zero, <span class="math inline">\(E[\varepsilon|x] = 0\)</span>. Notice that this also means that <span class="math inline">\(Cov(\varepsilon,x) = 0\)</span>, i.e. that the errors and our explanatory variable(s) should be <em>uncorrelated</em>. It is said that <span class="math inline">\(x\)</span> should be <strong>strictly exogenous</strong> to the model.</li>
</ol>
<p>These assumptions are necessary to successfully (and correctly!) run an OLS regression. They are often supplemented with an additional set of assumptions, which help with certain aspects of the exposition, but are not strictly necessary:</p>
<ol start="3" style="list-style-type: decimal">
<li>The data are drawn from a <strong>random sample</strong> of size <span class="math inline">\(n\)</span>: observation <span class="math inline">\((x_i,y_i)\)</span> comes from the exact same distribution, and is independent of observation <span class="math inline">\((x_j,y_j)\)</span>, for all <span class="math inline">\(i\neq j\)</span>.</li>
<li>The variance of the error term <span class="math inline">\(\varepsilon\)</span> is the same for each value of <span class="math inline">\(x\)</span>: <span class="math inline">\(Var(\varepsilon|x) = \sigma^2\)</span>. This property is called <strong>homoskedasticity</strong>.</li>
<li>The error is normally distributed, i.e. <span class="math inline">\(\varepsilon \sim \mathcal{N}(0,\sigma^2)\)</span></li>
</ol>
<p>Invoking assumption 5. in particular defines what is commonly called the <em>normal</em> linear regression model.</p>
<div id="b-is-not-beta" class="section level3">
<h3><span class="header-section-number">6.6.1</span> <span class="math inline">\(b\)</span> is not <span class="math inline">\(\beta\)</span>!</h3>
<p>Let’s talk about the small but important modifications we applied to model <a href="linreg.html#eq:abline">(3.3)</a> to end up at <a href="std-errors.html#eq:abline-5">(6.1)</a> above:</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> and intercept and slope parameters</li>
<li><span class="math inline">\(\varepsilon\)</span> is the error term.</li>
</ul>
<p>First, we <em>assumed</em> that <a href="std-errors.html#eq:abline-5">(6.1)</a> is the correct represenation of the DGP. With that assumption in place, the values <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are the <em>true parameter values</em> which generated the data. Notice that <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are potentially different from <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> in <a href="linreg.html#eq:abline">(3.3)</a> for a given sample of data - they could in practice be very close to each other, but <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> are <em>estimates</em> of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. And, crucially, those estimates are generated from a sample of data. Now, the fact that our data <span class="math inline">\(\{y_i,x_i\}_{i=1}^N\)</span> are a sample from a larger population, means that there will be <em>sampling variation</em> in our estimates - exactly like in the case of the sample mean estimating the population average as mentioned above. One particular sample of data will generate one particular set of estimates <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, whereas another sample of data will generate estimates which will in general be different - by <em>how much</em> those estimates differ across samples is the question in this chapter. In general, the more observations we have the greater the precision of our estimates, hence, the closer the estimates from different samples will lie together.</p>
</div>
<div id="violating-the-assumptions-of-the-crm" class="section level3">
<h3><span class="header-section-number">6.6.2</span> Violating the Assumptions of the CRM</h3>
<p>It’s interesting to consider in which circumstances we might violate those assumptions. Let’s give an example for each of them:</p>
<ol style="list-style-type: decimal">
<li><p>No Perfect Collinearity. We have seen that a perfect collinearity makes it impossible to compute to OLS coefficients. Remember the example about adding <code>wtplus = wt + 1</code> to the <code>mtcars</code> dataset? Here it is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
mtcars <span class="op">%&gt;%</span>
<span class="kw">mutate</span>(<span class="dt">wtplus =</span> wt <span class="op">+</span><span class="st"> </span><span class="dv">1</span>) <span class="op">%&gt;%</span>
<span class="kw">lm</span>(mpg <span class="op">~</span><span class="st"> </span>wt <span class="op">+</span><span class="st"> </span>wtplus, <span class="dt">data =</span> .)</code></pre></div>
<pre><code>#OUT&gt; 
#OUT&gt; Call:
#OUT&gt; lm(formula = mpg ~ wt + wtplus, data = .)
#OUT&gt; 
#OUT&gt; Coefficients:
#OUT&gt; (Intercept)           wt       wtplus  
#OUT&gt;      37.285       -5.344           NA</code></pre>
That the coefficient on <code>wtplus</code> is <code>NA</code> is the result of the direct linear dependence. (Notice that creating <code>wtplus2 = (wt + 1)^2</code>) would work, since that is not linear!)</li>
<li>Conditional Mean of errors is zero, <span class="math inline">\(E[\varepsilon|x] = 0\)</span>. Going back to our running example in figure <a href="std-errors.html#fig:confint">6.1</a> about wages and education: Suppose that each individual <span class="math inline">\(i\)</span> in our data something like <em>innate ability</em>, something we might wish to measure with an IQ-test, however imperfecty. Let’s call it <span class="math inline">\(a_i\)</span>. It seems reasonable to think that high <span class="math inline">\(a_i\)</span> will go together with high wages. At the same time, people with high <span class="math inline">\(a_i\)</span> will find studying for exams and school work much less burdensome than others, hence they might select into obtaining more years of schooling. The problem? Well, there is no <span class="math inline">\(a_i\)</span> in our regression equation - most of time we don’t have a good measure of it to start with. So it’s an <em>unobserved variable</em>, and as such, it is part of the error term <span class="math inline">\(\varepsilon\)</span> in our model. We will attribute to <code>educ</code> part of the effect on wages that is actually <em>caused</em> by ability <span class="math inline">\(a_i\)</span>! Sometimes we may be able to reason about whether our estimate on <code>educ</code> is too high or too low, but we will never know it’s true value. We don’t get the <em>ceteris paribus</em> effect (the true partial derivative of <code>educ</code> on <code>lwage</code>). Technically, the assumption <span class="math inline">\(E[\varepsilon|x] = 0\)</span> implies that <span class="math inline">\(Cov(\varepsilon,x) = 0\)</span>, so that’s the part that is violated.</li>
<li>Data from Random Sample. One common concern here is that the observations in the data could have been <em>selected</em> in a particular fashion, which would make it less representative of the underlying population. Suppose we had ended up with individuals only from the richest neighborhood of town; Our interpretation the impact of education on wages might not be valid for other areas.</li>
<li>Homoskedasticity. For correct inference (below!), we want to know whether the variance of <span class="math inline">\(\varepsilon\)</span> varies with our explanatory variable <span class="math inline">\(x\)</span>, or not. Here is a typical example where it does: <img src="ScPoEconometrics_files/figure-html/unnamed-chunk-172-1.png" width="672" style="display: block; margin: auto;" /> As income increases, not all people increase their food consumption in an equal way. So <span class="math inline">\(Var(\varepsilon|x)\)</span> will vary with the value of <span class="math inline">\(x\)</span>, hence it won’t be equal to the constant <span class="math inline">\(\sigma^2\)</span>.</li>
<li><p>If the distribution of <span class="math inline">\(\varepsilon\)</span> is not normal, it is more cumbersome to derive theoretical results about inference.</p></li>
</ol>
</div>
</div>
<div id="se-theory" class="section level2">
<h2><span class="header-section-number">6.7</span> Standard Errors in Theory</h2>
<p>The standard deviation of the OLS parameters is generally called <em>standard error</em>. As such, it is just the square root of the parameter’s variance. Under assumptions 1. through 4. above we can define the formula for the variance of our slope coefficient in the context of our single regressor model <a href="std-errors.html#eq:abline-5">(6.1)</a> as follows:</p>
<span class="math display" id="eq:var-ols">\[\begin{equation}
Var(b_1|x_i) = \frac{\sigma^2}{\sum_i^N (x_i - \bar{x})^2}  \tag{6.2}
\end{equation}\]</span>
<p>In pratice, we don’t know the theoretical variance of <span class="math inline">\(\varepsilon\)</span>, i.e. <span class="math inline">\(\sigma^2\)</span>, but we form an estimate about it from our sample of data. A widely used estimate uses the already encountered SSR (sum of squared residuals), and is denoted <span class="math inline">\(s^2\)</span>:</p>
<p><span class="math display">\[
s^2 = \frac{SSR}{n-p} = \frac{\sum_{i=1}^n (y_i - b_0 - b_1 x_i)^2}{n-p} =  \frac{\sum_{i=1}^n e_i^2}{n-p}
\]</span> where <span class="math inline">\(n-p\)</span> are the <em>degrees of freedom</em> available in this estimation. <span class="math inline">\(p\)</span> is the number of parameters we wish to estimate (here: 1). So, the variance formula would become</p>
<span class="math display" id="eq:var-ols2">\[\begin{equation}
Var(b_1|x_i) = \frac{SSR}{(n-p)\sum_i^N (x_i - \bar{x})^2}  \tag{6.3}
\end{equation}\]</span>
<p>We most of the time work directly with the <em>standard error</em> of a coefficient, hence we define</p>
<span class="math display" id="eq:SE-ols2">\[\begin{equation}
SE(b_1) = \sqrt{Var(b_1|x_i)} = \sqrt{\frac{SSR}{(n-p)\sum_i^N (x_i - \bar{x})^2}}  \tag{6.4}
\end{equation}\]</span>
<p>You can clearly see that, as <span class="math inline">\(n\)</span> increases, the denominator increases, and therefore variance and standard error of the estimate will decrease.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="6">
<li id="fn6"><p>This part is largely based on <a href="https://moderndive.com/7-sampling.html">moderndive</a>, to which I am giving full credit hereby. Thanks for this great idea.<a href="std-errors.html#fnref6">↩</a></p></li>
<li id="fn7"><p>Regardless of the worried onlookers, I did what I had to do and I carried on to count the green pile. I know exactly how many greens are in there now! I then computed the weight of 20 Fusilli (5g), and backed out the number of Fusilli in the other piles. I will declare those numbers as the <em>true numbers</em>. (Sceptics are free to recount.)<a href="std-errors.html#fnref7">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="categorical-vars.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="causality.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ScPoEcon/ScPoEconometrics/edit/master/06-StdErrors.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ScPoEconometrics.pdf", "ScPoEconometrics.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
